<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Arthur Turrell</title>
<link>https://www.aeturrell.com/atom.html</link>
<atom:link href="https://www.aeturrell.com/atom.xml" rel="self" type="application/rss+xml"/>
<description>{{&lt; meta description-meta &gt;}}</description>
<generator>quarto-1.6.39</generator>
<lastBuildDate>Thu, 28 Aug 2025 23:00:00 GMT</lastBuildDate>
<item>
  <title>Media mentions of opposition politicians in the UK</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/media-mentions/</link>
  <description><![CDATA[ 





<p>You hear a lot of people claiming that Nigel Farage gets an undue amount of coverage given the number of MPs in his Reform UK party.</p>
<p>I wondered if that was true, so I ran a query against <a href="https://www.gdeltproject.org/">GDELT</a> (Global Database of Events, Language and Tone). GDELT monitors mentions of specific people across broadcast, print, and web news.</p>
<p>And…. it is!</p>
<p><img src="https://www.aeturrell.com/blog/posts/media-mentions/mentions_chart_22de8.svg" class="img-fluid"></p>
<p>You often hear this criticism levelled specifically at the BBC, so I did a cut just for that. And it’s true there too.</p>
<p><img src="https://www.aeturrell.com/blog/posts/media-mentions/mentions_chart_d7b1c.svg" class="img-fluid"></p>
<section id="technical-appendix" class="level2">
<h2 class="anchored" data-anchor-id="technical-appendix">Technical Appendix</h2>
<p>I used BigQuery and the GDELT gkg_partitioned database to get the data. The SQL query is below. The lines are smoothed with <strong>statsmodels</strong>’ <code>lowess</code> function (Locally Weighted Scatterplot Smoothing).</p>
<p>The SQL query is below.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">SELECT</span> </span>
<span id="cb1-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">EXTRACT</span>(<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">YEAR</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> PARSE_DATETIME(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'%Y%m%d%H%M%S'</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">CAST</span>(<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">DATE</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">AS</span> STRING))) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">as</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Year</span>,</span>
<span id="cb1-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">EXTRACT</span>(<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">MONTH</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> PARSE_DATETIME(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'%Y%m%d%H%M%S'</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">CAST</span>(<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">DATE</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">AS</span> STRING))) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">as</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Month</span>,</span>
<span id="cb1-4">  REGEXP_EXTRACT(DocumentIdentifier, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'^(https?://[^/]+)'</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">as</span> Truncated_URL,</span>
<span id="cb1-5">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">CASE</span> </span>
<span id="cb1-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WHEN</span> REGEXP_CONTAINS(Persons, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(?i)nigel.farage'</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">THEN</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Nigel Farage'</span></span>
<span id="cb1-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WHEN</span> REGEXP_CONTAINS(Persons, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(?i)ed.davey'</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">THEN</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ed Davey'</span></span>
<span id="cb1-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WHEN</span> REGEXP_CONTAINS(Persons, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(?i)kemi.badenoch'</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">THEN</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Kemi Badenoch'</span></span>
<span id="cb1-9">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">END</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">as</span> Person_Mentioned,</span>
<span id="cb1-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">COUNT</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">as</span> Mentions</span>
<span id="cb1-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> `gdelt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>bq.gdeltv2.gkg_partitioned`</span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WHERE</span> </span>
<span id="cb1-13">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">DATE</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20240101000000</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-- Adjust date range as needed</span></span>
<span id="cb1-14">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">AND</span> DocumentIdentifier <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">IS</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">NOT</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">NULL</span></span>
<span id="cb1-15">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">AND</span> (</span>
<span id="cb1-16">    REGEXP_CONTAINS(Persons, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(?i)nigel.farage'</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">OR</span></span>
<span id="cb1-17">    REGEXP_CONTAINS(Persons, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(?i)ed.davey'</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">OR</span></span>
<span id="cb1-18">    REGEXP_CONTAINS(Persons, r<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(?i)kemi.badenoch'</span>)</span>
<span id="cb1-19">  )</span>
<span id="cb1-20"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">GROUP</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">BY</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Year</span>, <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Month</span>, Truncated_URL, Person_Mentioned</span>
<span id="cb1-21"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ORDER</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">BY</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Year</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">DESC</span>, <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Month</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">DESC</span>, Mentions <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">DESC</span>, Truncated_URL</span></code></pre></div>


</section>

 ]]></description>
  <category>politics</category>
  <category>text analysis</category>
  <category>visualisation</category>
  <guid>https://www.aeturrell.com/blog/posts/media-mentions/</guid>
  <pubDate>Thu, 28 Aug 2025 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/media-mentions/mentions_chart_22de8.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>A re-imagining of how to produce statistics</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/future-of-statistics/</link>
  <description><![CDATA[ 





<p>National statistics matter: they have a direct bearing on everything from government targets, to funding formulae, to the focus of the media, to the UK’s debt. But there have been many high-profile errors in the nation’s numbers recently, and that’s a cause for concern. Furthermore, the recent <a href="https://www.gov.uk/government/publications/independent-review-of-the-performance-and-culture-of-the-office-for-national-statistics/independent-review-by-sir-robert-devereux-kcb-june-2025">Devereux</a> and <a href="https://www.ft.com/content/a342f058-1b20-4706-8b62-d408bbf88c22">Public Administration and Constitutional Affairs Committee</a> (PACAC) reviews have found deep, systemic flaws in the UK’s current approach.</p>
<p>I’m a <a href="https://rss.org.uk/policy-campaigns/policy-groups/education-policy-advisory-group/rss-william-guy-lecturers/upcoming-william-guy-lecturers-2025-26/">Royal Statistical Society William Guy Lecturer</a> for 2025-2026, and my topic is “Economic statistics and stupidly smart AI.” With my William Guy Lectureship hat on, I’ve been thinking a lot about how innovation could help with the production of statistics.</p>
<p><strong>If we were to start from scratch, what would a statistical institute designed for the world of today—and tomorrow—look like?</strong> How would you rebuild for the era of AI and data science and cloud, take on board the best practices in management, and ensure the right talent was in place to deliver for the nation?</p>
<p>This blog post is my attempt at answering these questions and giving a rough blueprint for a different model for producing statistics. Please note that these are very much my personal views.</p>
<section id="introduction" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="background" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="background">Background</h3>
<p>National statistics are critical infrastructure—essential for decisions that will determine the success of the country. However, the current means of their production has been under pressure. To name a few, there have been recent high-profile errors in <a href="https://www.ft.com/content/61679d49-2b87-45ef-8fa2-1b76e393aed4">trade</a>, <a href="https://www.ons.gov.uk/economy/economicoutputandproductivity/productivitymeasures/datasets/internationalcomparisonsofproductivityfirstestimates">productivity</a><sup>1</sup>, <a href="https://www.ft.com/content/a33e505a-b504-46a9-ba08-e1efd8831a69">GDP</a>, <a href="https://www.ons.gov.uk/news/statementsandletters/errorsidentifiedinonsonlinetimeusesurveyotusdata">time use</a>, <a href="https://www.ons.gov.uk/economy/governmentpublicsectorandtaxes/researchanddevelopmentexpenditure/articles/comparisonofonsbusinessenterpriseresearchanddevelopmentstatisticswithhmrcresearchanddevelopmenttaxcreditstatistics/2022-09-29">innovation</a><sup>2</sup>, <a href="https://www.ft.com/content/41a07d42-2518-4ec9-9220-943268c93bb5">migration</a>, <a href="https://osr.statisticsauthority.gov.uk/publication/review-of-statistics-on-gender-identity-based-on-data-collected-as-part-of-the-2021-england-and-wales-census-final-report/">census</a>, <a href="https://www.ft.com/content/197bb24b-01fd-44b1-9ac7-f70ccf987825">health</a> and <a href="https://www.ft.com/content/7d3de81f-b845-490b-804f-af0aa4f76fe3">labour market figures</a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;The materials accompanying the <a href="https://www.ons.gov.uk/economy/economicoutputandproductivity/productivitymeasures/datasets/internationalcomparisonsofproductivityfirstestimates">productivity revision</a> said “the previous version suggested that the UK’s average output per hour worked growth rate was 5.0% during the coronavirus (COVID-19) period of 2020 and 2021. The corrected version shows that the UK’s average output per hour growth rate was -0.3% over this period…. the previous version suggested that the UK output per hour worked in 2021 (excluding Japan) had the fastest growth of the G7 countries. This has now been corrected to the second slowest. The previous version also suggested that in 2020 the UK had a fall of 12%, which is now corrected to a 1.2% increase.”</p></div><div id="fn2"><p><sup>2</sup>&nbsp;“…the value of expenditure on R&amp;D performed by UK businesses according to ONS’ BERD survey were £15.0 billion, £15.6 billion, and £16.1 billion higher in 2018, 2019 and 2020 respectively than previously estimated.”</p></div></div><p>The media has noticed—here are some recent headlines:</p>
<ul>
<li><a href="https://www.telegraph.co.uk/news/2025/05/21/office-for-national-statistics-can-no-longer-be-trusted/">Why the UK’s official statistics can no longer be trusted</a>, Daily Telegraph, 2025/05/21.</li>
<li><a href="https://www.ft.com/content/f2ef0740-6420-400f-8a78-abc02936aaa9">Faulty data leaves Britain in the dark: The quality of ONS governance and critical statistics needs fixing</a>, Financial Times, 2025/04/05.</li>
<li><a href="https://www.theguardian.com/uk-news/2025/mar/21/troubled-uk-statistics-agency-warns-of-errors-in-its-growth-figures">Troubled UK statistics agency warns of errors in its growth figures</a>, The Guardian, 2025/03/21.</li>
<li><a href="https://www.instituteforgovernment.org.uk/comment/office-national-statistics-fix-data-problems">The Office for National Statistics must change to fix its data problems</a>, Institute for Government, 2025/03/12.</li>
</ul>
<p>It is not all bleak: there have been incredible developments in UK statistics in recent years. The Covid Infection Survey was a triumph. Though it’s early days, <a href="https://datasciencecampus.ons.gov.uk/estimating-geographical-retail-markets-from-card-spending-data/">card data shows promise</a>. The use of scanner data for inflation is perhaps the strongest contemporary example.<sup>3</sup> Scanner data are created as consumers purchase goods at a supermarket checkout (or online), and they give the product name, volume, and price paid. This is a giant leap compared to field agents travelling around supermarkets with clipboards, who were able to only record the price, and then only for a much smaller number of products. Scanner data make consumer price inflation (CPI) more accurate, give more information on price changes across the economy, and allow more analysis of what products are driving price rises. The adoption of scanner data was an extremely significant step forward for how inflation is measured in the UK.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Though the UK <a href="https://www.insee.fr/en/information/5014725?sommaire=5014796">wasn’t the first</a>: others who have adopted scanner data include the Netherlands (2002), Norway (2005), Switzerland (2008), Sweden (2012), Belgium (2015), Denmark (2016), Iceland (2016), Luxembourg and Italy (2018).</p></div><div id="fn4"><p><sup>4</sup>&nbsp;This particular example shows that, with the right conditions, substantial improvements in statistics are possible.</p></div></div><p>It’s also fair to say that there have been headwinds in producing good statistics too: one enormous challenge stems from the long-running issue of declining response rates that has afflicted most national statistical agencies <span class="citation" data-cites="stedman_end_2019">(Stedman et al. 2019)</span>.</p>
<p>However, many other issues have come from copy-and-paste errors or the use of spreadsheets, and could have been avoided. The two reviews from 2025, Devereux and PACAC, follow many others<sup>5</sup> and one recurring theme is that the problems with UK statistics go beyond declining response rates.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Turnbull-King 1999, Allsopp 2004, Smith 2006, Smith 2014, Johnson 2015, Bean 2016, and Lievesley 2024.</p></div></div><p>So I thought it would be fun to imagine what a greenfield design for producing the best quality statistics possible would look like.</p>
</section>
<section id="imagining-better" class="level3">
<h3 class="anchored" data-anchor-id="imagining-better">Imagining better</h3>
<p>Why is a better way of doing statistics easy to imagine? We just have much better tools across technology and organisational science to bring to bear on the production of quantitative outputs than we have ever had before, and they should give us huge optimism that there’s a different path here.</p>
<p>Data science, big data, AI, cloud services, better algorithms, faster hardware, innovations in the management of technical and data-heavy organisations; all could fundamentally change and improve how statistics are produced and delivered <span class="citation" data-cites="turrell2025cuttingcomplexitydatascience">(Turrell 2025)</span>. Studies have suggested that in regular organisations, the use of data science and big data can improve productivity by as much as 7% <span class="citation" data-cites="brynjolfsson_strength_2011 muller_effect_2018">(Brynjolfsson, Hitt, and Kim 2011; Müller, Fay, and vom Brocke 2018)</span>. That number should surely be higher for tasks that are solely about the collection, processing, and publication of data.</p>
<p>Also, the management of data-first organisations has been the subject of a great deal of improvement and innovation—with firms like <a href="https://www.amazon.co.uk/Working-Backwards-Insights-Stories-Secrets/dp/1529033829">Amazon</a>, Google, <a href="https://handbook.gitlab.com/handbook/company/culture/all-remote/asynchronous/">GitLab</a>, and more developing ways of working that are suited to the kinds of tasks that statistical production also requires: everything from asynchronous working, to a small and highly skilled workforce, to technical career paths, to “single-threaded” leadership. The management and organisational strategies that have been developed in these frontier firms are part of the reason for their success, and there is every reason to think that other data-centred organisations would benefit from trying them.</p>
<p>Let’s now look at some concrete ideas for what to do differently across technology and capital, people and skills, and management.</p>
</section>
</section>
<section id="technology-and-capital" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="technology-and-capital">Technology and capital</h2>
<p>Prof Bart van Ark, managing director of the Productivity Institute, asseses that around one-third of the UK’s productivity ‘puzzle’ is a result of low capital per worker. The UK’s capital per hour worked lags behind Italy and the Czech Republic <span class="citation" data-cites="allas_uks_2025">(Allas and Zenghelis 2025)</span>. If you were redesigning the production of statistics from scratch, you’d want to ensure that top quality technology and capital were in place.</p>
<section id="use-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="use-of-ai">Use of AI</h3>
<p>AI is just a tool, so I almost didn’t honour it with its own section. However, it’s where some of the most exciting developments could emerge. Here are a few ways it could help:</p>
<ul>
<li>detecting mistakes in survey responses. Machine learning and large language models could significantly increase the rate at which this kind of data error is caught.</li>
<li>flagging outliers. (Similarly to above.)</li>
<li>interview transcription—even when the language is not English!</li>
<li>translation to official taxonomies from free text fields <span class="citation" data-cites="turrell20226 soria2025empirical">(Turrell et al. 2022; Soria 2025)</span>. This is currently a burdensome process with much manual labour, but large language models can be targeted to, as an example, turn respondents’ written job description into official Standard Occupational Classification categories.</li>
<li>imputation of missing responses in early estimates. Machine learning excels at matrix completion, and that would be more sophisticated than what is commonly used today (eg ratio implementation.)</li>
<li><em>conducting</em> survey interviews. Yep, you read that right! See <span class="citation" data-cites="geiecke2024conversations">Geiecke and Jaravel (2024)</span>.</li>
<li>computer vision can extract data from satellite imagery for, say, building starts: Statistics Canada and the US’ Census Bureau are both compiling more accurate, more timely statistics using satellite data <span class="citation" data-cites="erman_use_2022">(Erman et al. 2022)</span></li>
<li>similarly, computer vision can be applied to street scenes to assess the cleanliness and desirability of high streets</li>
<li>accessibility enhancement: AI can automatically generate alternative text for visual content, create audio descriptions, and translate content into multiple languages.</li>
<li>natural language processing can assess news articles for the softer indicators of sentimentn that often lead harder indicators <span class="citation" data-cites="kalamara2022making">(Kalamara et al. 2022)</span></li>
<li>making statistics more accessible to the general public. Large language model-based <a href="https://www.llamaindex.ai/">retrieval augmented generation</a> is able to answer users’ questions based only on certified information, and can link back to its sources. This would allow for a fundamental shift in how people discover and consume statistics. It would also potentially reduce the number of ad hoc requests. My former colleague Andy Banks led <a href="https://datasciencecampus.ons.gov.uk/using-large-language-models-llms-to-improve-website-search-experience-with-statschat/">a project demonstrating the principle</a> already.</li>
<li>help with coding via tools such as GitHub Copilot, Claude Code, and Gemini CLI.</li>
<li>drafting articles that are simply summaries of data updates.</li>
</ul>
</section>
<section id="computing-and-data-infrastructure" class="level3">
<h3 class="anchored" data-anchor-id="computing-and-data-infrastructure">Computing and data infrastructure</h3>
<p>Hardware based on Unix, which is well-suited to data and code, would be available to staff for local development. High performing hardware saves labour, so is cost effective, but it’s also necessary to run large language models and other AI locally—allowing you to quickly try out ideas. Recognising that people’s time is usually the biggest cost in an organisation, top-end laptops would be a no-brainer.</p>
<p>The new automated pipelines would be based on secure cloud services, capitalising on the falling cost, increasing functionality, and scalability of the cloud. These products have <a href="https://aws.amazon.com/managed-workflows-for-apache-airflow/sla/">typical service level agreements</a> of 99.9% uptime. As far as possible, the cloud infrastructure used would be service provider agnostic to prevent vendor lock-in and to keep costs competitive. The architecture and services used would follow the “infrastructure-as-code” principle, which means that it can be programmatically deployed, and easily re-deployed, including—at least in principle—via a different vendor. <a href="https://developer.hashicorp.com/terraform">Terraform</a> and related technologies will be used for this.</p>
<p>The data architecture used would be be a ‘data lakehouse’. This combines the ability to work with unstructured data and structured data in databases with a data catalogue and other metadata, including version histories, all of which is useful and goes beyond a simple database. Some options are <a href="https://aws.amazon.com/sagemaker/lakehouse/">Amazon Sagemaker Lakehouse</a>, <a href="https://cloud.google.com/blog/products/data-analytics/extending-the-google-data-cloud-lakehouse-architecture">Google’s open lakehouse</a>, and <a href="https://www.databricks.com/product/data-lakehouse">Databricks Lakehouse</a>. For local development and prototyping, it’s possible to use <a href="https://ducklake.select/">DuckLake</a>.</p>
</section>
<section id="code" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="code">Code</h3>
<p>The computer code used would of course be under version control, and subject to ongoing quality checks, some automatic (eg unit and integration tests.) Tools like <a href="https://sqlfluff.com/">SQLFluff</a> and <a href="https://docs.astral.sh/ruff/">Ruff</a> can flag and even auto-correct some problems in database queries and code respectively, while other tools such as <a href="https://pre-commit.com/">pre-commit</a> and <a href="https://aeturrell.github.io/panoptipy/">panoptipy</a><sup>6</sup> provide ways to flag <em>potential</em> issues to both developers and managers. Of course, this code would be under version control. There’s even a maximalist approach where the code to produce statistics is open source too, so that problems can be found more quickly by more eyeballs.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Full disclosure: I wrote this package! It’s still in beta, but you can get the gist already.</p></div></div><p>The code would mainly be Python and SQL, for many reasons.</p>
<p>Python’s dominance in data science reflects several compelling advantages that make it the natural choice for modern analytical work. The language benefits from <a href="https://www.tiobe.com/tiobe-index/">vast popularity</a> across <a href="https://pypl.github.io/PYPL.html">multiple measures</a>, creating substantial positive network externalities, eg rapid bug discovery, the ability of large language models to write it well, and the sheer volume of available free and open source packages that are on <a href="https://pypi.org/">PyPI</a>. Major conferences like NeurIPS and ICML predominantly feature Python-based research, as do <a href="https://mlcontests.com/state-of-machine-learning-competitions-2024">machine learning competitions</a>.</p>
<p>Python is widely taught and used. It’s <a href="https://www.bcs.org/policy-and-influence/education/bcs-landscape-review-computing-qualifications-in-the-uk/england-computer-science-gcse-as-and-a-levels/">taught in some UK and US high schools</a>, both state and <a href="https://www.isc.co.uk/media-enquiries/isc-blogs/python-becomes-a-modern-language-for-putney-high-school-s-next-generation-of-digital-nomads/">private</a>, meaning that the future pipeline of talent is assured. In the professional sphere, <a href="https://www.kdnuggets.com/2019/05/poll-top-data-science-machine-learning-platforms.html">data scientists in the private sector predominantly work in Python and SQL</a>, with this share growing over time. Beyond the academy, firms that sponsor and support Python include <a href="https://www.python.org/psf/sponsors/">Microsoft, Google, Meta, and Bloomberg</a>. Even <a href="https://www.infoworld.com/article/3668252/rstudio-changes-name-to-posit-expands-focus-to-include-python-and-vs-code.html">RStudio’s rebranding to ‘Posit’</a> reflects a strategic pivot toward Python support.</p>
<p>Cloud infrastructure considerations are increasingly crucial: services like <a href="https://cloud.google.com/run">Google Cloud Run</a> and <a href="https://learn.microsoft.com/en-GB/azure/azure-functions/supported-languages?tabs=isolated-process%2Cv4&amp;pivots=programming-language-csharp">Azure Functions</a> support Python natively.</p>
<p>Just as Python is dominant in the space of analytical code, SQL dominates in database languages. SQL complements Python perfectly, offering flexibility, simplicity compared to distributed databases, wide adoption, and impressive scalability (as demonstrated by Google BigQuery’s massive-scale SQL operations).</p>
<p>Using Python and SQL means being able to piggy-back on the wider innovations in these languages, and being able to attract staff for whom statistical production may not be their only ever job.</p>
</section>
<section id="sec-pipelines" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-pipelines">Automated data pipelines based on code and focused on quality</h3>
<p>Data pipelines—from ingestion to prepared outputs—would be automated, with both automated and human checks throughout.</p>
<p>This would begin with data acquisition. Insofar as is possible, data could be programmatically read in from <a href="https://aeturrell.com/blog/posts/the-prize-with-apis/the-prize-with-apis.html">application programming interfaces</a> (APIs) rather than sourced manually. This may not always be possible depending on the data source. But if the data are coming from, say, a survey, the information can still be acquired initially through digital means and validated at the very first stage. Surveys that are panels could be pre-populated with known answers to try and limit the fall off in responses due to “survey fatique.”</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/future-of-statistics/survey_pipeline_dag.svg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="margin-caption">A schematic of the directed acyclic graph that a data orchestration tool would run.</figcaption>
</figure>
</div>
<p>The progression of data through a pipeline would be run by the data orchestration tools that are fairly common in production grade data science applications. Data orchestration tools schedule, monitor, and catch errors or issues in the processing of data by computer code. Orchestration flows can be triggered on on a schedule or according to an event, for example if a new file lands in a folder. They ensure that data are transformed, cleaned, and delivered efficiently and accurately. Orchestration tools can handle large volumes of data, support various data formats and programming languages, and can make it easier for organisations to monitor their entire estate of processes. Some popular data orchestration tools include <a href="https://airflow.apache.org/">Apache Airflow</a> (first generation) and <a href="https://docs.dagster.io/">Dagster</a> and <a href="https://docs.prefect.io/v3/get-started/index">Prefect</a> (both second generation, with more advanced features). All of these are free and open source. For hosting of orchestration pipelines, <a href="https://cloud.google.com/composer/docs/composer-3/composer-overview">Google Cloud Composer</a> and <a href="https://aws.amazon.com/managed-workflows-for-apache-airflow/">Amazon Managed Workflows for Airflow</a> are both managed Airflow instances that can be configured using a dedicated API or using <a href="https://developer.hashicorp.com/terraform">Terraform</a>.</p>
<p>As data are passed around the workflows, they can be subject to checks that will raise a red flag should a problem be detected. “Type checking” would flag any issues with the format of the data. This can be achieved with data validation tools such as <a href="https://greatexpectations.io/">Great Expectations</a>, <a href="https://pandera.readthedocs.io/">Pandera</a>, and (for unstructured data) <a href="https://docs.pydantic.dev/">Pydantic</a>. Data validation and plausibility checks could look to see whether the data are consistent with historical and other contextual information too—this helps ensure that implausible values are caught early, including at the aggregate level.</p>
<p>Once data and pipelines are in the cloud and automated, it becomes possible to do data lineage tracking. This would allow one to understand how data change from landing, through processing and transformation, and to reports, applications, and statistics. Such lineage tracking can trace an error’s origin, highlight inconsistencies across processes, and show what the downstream consequences of an error might be at the start of a pipeline. Data lineage tracking also enables sensitivity analysis, so that producers can ask questions like, “What would the statistic look like if this or that data point were incorrect?” This gives a sense of whether the overall numbers are driven by one or two responses that, if incorrect, could make the final numbers misleading.</p>
<p>Any changes to critical production-of-stats code would be subject to review, and to tests that would show how the output statistic would change subject to the code change.</p>
<p>At the end of the pipeline, the single source of truth on the final output would be an API, and data available in the traditional way (ie where it could be downloaded manually from a webpage) would be built on top of that API—ensuring that these sources were consistent and that the statistics could be accessed programmatically by others. APIs are the bedrock of online services and are already provided by a wide range of public sector organisations such as <a href="https://api.tfl.gov.uk/">Transport for London</a> (TfL), the Federal Reserve Bank of St Louis’ statistical service <a href="https://fred.stlouisfed.org/">FRED</a>, the <a href="https://datahelpdesk.worldbank.org/knowledgebase/articles/889386-developer-information-overview">World Bank</a>, and the <a href="https://www.oecd.org/en/data/insights/data-explainers/2024/09/api.html">OECD</a>. They are powerful because they allow for integration of downstream services: analysts using the statistics could write their own automated pipelines that directly consume relevant data feeds and businesses could use the data in services they provide (much as CityMapper does with the TfL API.)</p>
<p>Internally, dashboards of KPIs of the quality of statistics and code, and the numbers of manual and programmatic downloads of statistics, and other relevant pipeline data would be produced and displayed as part of the process—more on that in the management section!</p>
</section>
</section>
<section id="labour" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="labour">Skills and labour</h2>
<p>Recognising how technology is <a href="https://www.ft.com/content/8e730692-fd9c-45b1-84dc-7ea16429c5c6">changing the demands on workforces</a>, and the high costs of co-ordination of lots of people, you’d probably want to go for a leaner, more highly skilled and better paid workforce than has hitherto been the case. Fewer, more expert staff can be more agile and make risk-reward trade-offs more succesfully.</p>
<p>Fundamentally, the production of statistics is a technocratic endeavour, and you would want a workforce that reflects this: you’d want them to be highly skilled in relevant technical subject areas; for example, data science, statistics, and economics. The level of knowledge that you would want to see staff demonstrate in these areas would be high—so high that, like those similarly technocratic institutions, central banks, you would want to have a dedicated career offering for people with PhDs in relevant topics and you would make space for them to do research on how to make the statistics better.</p>
<p>To ensure that the workforce did meet these criteria, and to reflect that the use of code, data, and AI would be foundational to the tasks, you might want to require technical staff (most staff) to pass a coding test in Python and SQL.</p>
<p>Inevitably, going for a highly skilled workforce would mean needing to offer high salaries too—though pay would not need to be as high as in the private sector because access to the best data in the country would be a strong draw for economists, data scientists, and statisticians alike, and public service is a great motivator for many. To ensure that the overall budget remained sensible, one would have to have a smaller workforce however.</p>
<p>Getting the right skills is the most important part of any endeavour, and where you site your statistical production should reflect this: it’s got to be where the people you want to work with are. Ideally, you would use a cost-benefit analysis of different locations and look at whether they could supply suitable labour at reasonable cost. A place with a thick labour market for highly educated graduates and post-graduates, but not too high a cost of living, is most likely to deliver this.</p>
<p>Once highly skilled labour is acquired, it would need to be cultivated and retained. Ongoing investment in human capital is all the more necessary in a world where AI means work is changing rapidly. Beyond that, there would need to be a compelling career offering for those who can bring value not just via managerial and organisational skills, but also via technical knowledge, ability to innovate, and professional leadership. Therefore, it would be essential to have technical career paths on offer. Technical career paths are common in frontier technology firms that require somewhat similar skills: Google has a complete parallel technical career ladder for roles up to and including Senior Vice President; Amazon, Meta, AirBnB, Uber, Apple, and Microsoft have similar pathways. This approach is not unprecedented in the public sector.</p>
<p>One advantage of having research skills would be to invigorate innovation. One (extremely imperfect) metric of innovation in statistics is how many research papers are published by national statistical organisations. As you can see in Figure&nbsp;1, world-leading institutes like Statistics Netherlands and Statistics Canada fare well on this measure.</p>
<div id="fig-research" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-research-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.aeturrell.com/blog/posts/future-of-statistics/mean_papers_per_year.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-research-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A crude measure of innovation for selected institutions. INSEE is the French statistical agency. The Federal Reserve Bank of St Louis publishes a wide range of statistics through its <a href="https://fred.stlouisfed.org/">Federal Reserve Economic Statistics website</a>. Data from SCOPUS.
</figcaption>
</figure>
</div>
<p>It is not just highly skilled technical workers that will be required: management and leadership must also be highly skilled in their crafts. It almost goes without saying that poor leadership and bad management practices can undermine any endeavour, no matter how good the rest of the people working on it may be. Therefore, as well as seeking highly skilled technical staff, it is important that senior leadership have vision, the pragmatism to deliver, and the ability to implement the best practices in management. <a href="https://www.productivity.ac.uk/news/do-managers-matter/">Firms with better management practices have higher labour productivity</a>; why should we expect the production of statistics to be any different? And the benefits are significant: moving from the median to the 75th percentile of the distribution of management practices scores increases productivity by 11%. On the topic of management practices…</p>
</section>
<section id="management-practices-culture-and-organisation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="management-practices-culture-and-organisation">Management practices, culture, and organisation</h2>
<p>The best practices for culture, organisation, and management would need to be used to deliver the best possible statistics. Drawing from sources like <a href="https://www.productivity.ac.uk/news/do-managers-matter/">Do managers matter?</a> and the techniques implemented at Amazon and others, the following innovations would be used:</p>
<ul>
<li><p>A culture of continuous improvement <em>within</em> existing teams. No hiving off improvement work to be done in a different department or team—innovation is everyone’s job! Those improvements can be encouraged, monitored, and celebrated through KPIs…</p></li>
<li><p>The use of Key Performance Indicators (KPIs) for tracking progress and for making key management decisions (eg around prioritisation.) These should be available through the whole organisation, and will help hold people to account for the statistics they are producing.</p></li>
<li><p>Small, highly autonomous teams<sup>7</sup> responsible for elements within the vertically integrated product-structure. Small teams operating with high autonomy within guardrails can help tackle co-ordination costs, remove the need for wide consensus (which leads to inaction), and prevents the diffusion of accountability. It is also much more empowering, which is strongly linked to job satisfaction.</p></li>
<li><p>The use of targets that are stretching, tracked, and reviewed.</p></li>
<li><p>Strict, rapid, and effective performance management.</p></li>
<li><p>An organisational structure that reflects products and outputs rather than functional areas. This means that an entire production pipeline, from survey to final published statistics, will be owned by one area that can be held accountable for it. This is a contrast to having surveys in one department, technology in another, HR another, and statistics processing another. Functional models struggle to ensure aligned incentives. For example, if you have someone responsible for IT they are typically incentivised to minimise how much is spent on technology and to de-risk that technology as much as possible. However, another person who is responsible for processing statistics has quite different incentives: they want analysis to be done quickly (so prefer more expensive IT) and they are willing to take on some risk to get the job done. It can be hard for an organisation to solve this trade-off effectively, especially if these two people have reporting lines that only meet in the head of the organisation, who will have many other concerns on their plate. Instead, a product-oriented structure sees much of technology, HR, etc., embedded right next to the coal face.</p></li>
<li><p>Similarly, “single-threaded” leadership, which means a single person is ultimately responsible for getting a product out. This leader is incentivised to make the optimal trade-off on risk and spend versus delivery. There is clear accountability in this model. Single-threaded means that leaders have end-to-end accountability for outcomes, decision bottlenecks are removed, and everyone under that leader is aligned on the goal.</p></li>
<li><p>Kanban boards for management of work tasks, wherein everyone in the team knows what is happening, and a large number of routine updates are no longer necessary</p></li>
<li><p>Asynchronous working patterns, such as status updates being automatic rather than through meetings (as above.) Synchronous meetings would be reserved for bilaterals and low-latency collaboration on complex issues. Documentation would be used obsessively for code, processes, decisions, and actions (this also lowers initial onboarding costs.) In particular, the documentation and code that processes data in a part of the pipeline will sit together and automated checks will ensure that they do not diverge (a common practice in high end software development.)</p></li>
<li><p>Proposals to be discussed by committees in prose, not PowerPoint, in the form of notes with a page limit. Meetings would start with “silent time” so that everyone gets on the same page (literally) and can have a constructive discussion.</p></li>
<li><p>Decisions counter-signed by all, and the reason for the decision documented.</p></li>
<li><p><a href="https://www.aboutamazon.com/news/workplace/an-insider-look-at-amazons-culture-and-processes">“working backwards”</a> for new products</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Disagree_and_commit">“disagree and commit”</a>, to avoid consensus bias</p></li>
<li><p>a single source of truth for all information</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Usually defined as those that can be fed with two pizzas.</p></div></div></section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Our current statistical infrastructure is creaking dangerously. Could this crisis present an opportunity? We now have the tools—AI, cloud computing, modern data science, and battle-tested management practices from the world’s most successful tech companies—to build anew.</p>
<p>Starting from scratch would mean <strong>putting technology first</strong>: automated pipelines running on secure cloud infrastructure, with AI catching errors that humans might miss, and APIs making statistics as accessible as checking the weather on your phone. It would mean <strong>talent over scale</strong>: a smaller, highly skilled workforce of data scientists, statisticians, and economists who can programme this technology to produce the best stats possible. And it would mean <strong>innovation in management</strong>: product-focused teams with single-threaded leadership, clear KPIs, and the management practices that have made Amazon successful but applied to the considerably more important task of measuring the economy and more.</p>
<p>Here’s what should keep us all awake at night: we could be making billion-pound decisions based on statistics produced with clipboard-and-Excel methods while the tools to do this properly are sitting right there, proven and ready to deploy. The question isn’t whether we <em>can</em> rebuild our statistical infrastructure for the modern age—the question is whether we will—and whether it can happen before the next crisis in the nation’s numbers hits the headlines.</p>
<p>The blueprint exists. The technology works. The management practices are proven. And we <em>need</em> statistics fit for the choices that will shape Britain’s future: because a decision based on the wrong data is like a house built on sand.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-allas_uks_2025" class="csl-entry">
Allas, Tera, and Dimitri Zenghelis. 2025. <span>“The <span>UK</span>’s Capital Gap: A Short-Fall in the Trillions of Pounds That Will Take Decades to Bridge.”</span> <em>The Productivity Institute</em>, no. 55 (May).
</div>
<div id="ref-brynjolfsson_strength_2011" class="csl-entry">
Brynjolfsson, Erik, Lorin M. Hitt, and Heekyung Hellen Kim. 2011. <span>“Strength in <span>Numbers</span>: <span>How Does Data-Driven Decisionmaking Affect Firm Performance</span>?”</span> SSRN. Rochester, NY. <a href="https://doi.org/10.2139/ssrn.1819486">https://doi.org/10.2139/ssrn.1819486</a>.
</div>
<div id="ref-erman_use_2022" class="csl-entry">
Erman, Sevgui, Eric Rancourt, Yanick Beaucage, and Andre Loranger. 2022. <span>“The <span>Use</span> of <span>Data Science</span> in a <span>National Statistical Office</span>.”</span> <em>Harvard Data Science Review</em> 4 (4). <a href="https://doi.org/10.1162/99608f92.13e1d60e">https://doi.org/10.1162/99608f92.13e1d60e</a>.
</div>
<div id="ref-geiecke2024conversations" class="csl-entry">
Geiecke, Friedrich, and Xavier Jaravel. 2024. <span>“Conversations at Scale: Robust Ai-Led Interviews with a Simple Open-Source Platform.”</span> <em>Available at SSRN 4974382</em>.
</div>
<div id="ref-kalamara2022making" class="csl-entry">
Kalamara, Eleni, Arthur Turrell, Chris Redl, George Kapetanios, and Sujit Kapadia. 2022. <span>“Making Text Count: Economic Forecasting Using Newspaper Text.”</span> <em>Journal of Applied Econometrics</em> 37 (5): 896–919.
</div>
<div id="ref-muller_effect_2018" class="csl-entry">
Müller, Oliver, Maria Fay, and Jan vom Brocke. 2018. <span>“The <span>Effect</span> of <span>Big Data</span> and <span>Analytics</span> on <span>Firm Performance</span>: <span>An Econometric Analysis Considering Industry Characteristics</span>.”</span> <em>Journal of Management Information Systems</em> 35 (2): 488–509. <a href="https://doi.org/10.1080/07421222.2018.1451955">https://doi.org/10.1080/07421222.2018.1451955</a>.
</div>
<div id="ref-soria2025empirical" class="csl-entry">
Soria, Chris. 2025. <span>“An Empirical Investigation into the Utility of Large Language Models in Open-Ended Survey Data Categorization.”</span> <a href="https://doi.org/10.31235/osf.io/wv6tk_v2">https://doi.org/10.31235/osf.io/wv6tk_v2</a>.
</div>
<div id="ref-stedman_end_2019" class="csl-entry">
Stedman, Richard C., Nancy A. Connelly, Thomas A. Heberlein, Daniel J. Decker, and Shorna B. Allred. 2019. <span>“The <span>End</span> of the (<span>Research</span>) <span>World As We Know It</span>? <span>Understanding</span> and <span>Coping With Declining Response Rates</span> to <span>Mail Surveys</span>.”</span> <em>Society &amp; Natural Resources</em> 32 (10): 1139–54. <a href="https://doi.org/10.1080/08941920.2019.1587127">https://doi.org/10.1080/08941920.2019.1587127</a>.
</div>
<div id="ref-turrell2025cuttingcomplexitydatascience" class="csl-entry">
Turrell, Arthur. 2025. <span>“Cutting Through Complexity: How Data Science Can Help Policymakers Understand the World.”</span> <a href="https://arxiv.org/abs/2502.03010">https://arxiv.org/abs/2502.03010</a>.
</div>
<div id="ref-turrell20226" class="csl-entry">
Turrell, Arthur, Bradley Speigner, Jyldyz Djumalieva, David Copple, and James Thurgood. 2022. <span>“6. Transforming Naturally Occurring Text Data into Economic Statistics.”</span> In <em>Big Data for Twenty-First-Century Economic Statistics</em>, 173–208. University of Chicago Press.
</div>
</div></section></div> ]]></description>
  <category>statistics</category>
  <category>productivity</category>
  <category>public sector</category>
  <guid>https://www.aeturrell.com/blog/posts/future-of-statistics/</guid>
  <pubDate>Sat, 05 Jul 2025 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/future-of-statistics/survey_pipeline_dag.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Untangling spaghetti code with smartrappy</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/introducing-smartrappy/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/code/logos/smartrappy.svg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="margin-caption"><strong>smartrappy</strong> logo</figcaption>
</figure>
</div>
<p>If you’ve ever inherited responsibility for a messy Python codebase, or returned to your own code after a few months, and wondered “what on earth is going on here?”, you’re not alone. Understanding complex code dependencies, data flows, and how different parts of a project interact is a common challenge, especially with analytical pipelines that have gathered a bit of dust or changed substantially since you last used them.</p>
<p>Of course, ideally, it shouldn’t get to this stage: there <em>are</em> ways to auto-document <em>precisely</em> what’s happening in your code, eg via <a href="https://aeturrell.github.io/coding-for-economists/wrkflow-rap.html#make-for-reproducible-analytical-pipelines">a Makefile and Makefile2Dag</a>—see <a href="https://github.com/aeturrell/example-reproducible-research">a fully worked example here</a>—or using a <a href="https://aeturrell.github.io/coding-for-economists/data-advanced.html#data-orchestration">data orchestrator</a>. For everything else, there’s <a href="https://aeturrell.github.io/smartrappy/"><strong>smartrappy</strong></a>.</p>
<p><strong>smartrappy</strong><sup>1</sup> is designed to help you understand and visualise the dependencies in analytical Python projects that haven’t hit the heady heights of having auto-generated their own directed cyclic graph. Let’s be honest, that’s most projects. It’s important to say that <strong>smartrappy</strong> is just sniffing out relationships between code and data and other things in a project, and it does a fairly good job of that, but it’s not perfect and it certainly won’t find everything. For a lot of analytical Python code, though, it should give you a big boost in understanding what’s going on.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;smart + RAP (Reproducible Analytical Pipeline) + py. Get it? Get it?? Hilarious.</p></div></div><section id="what-does-smartrappy-do" class="level2">
<h2 class="anchored" data-anchor-id="what-does-smartrappy-do">What does smartrappy do?</h2>
<p><strong>smartrappy</strong> analyses a Python project and infers the directed acyclic graph (DAG) of code and data dependencies. It traces through your codebase to find (as best as it can):</p>
<ul>
<li>Which files are being read from or written to, including data files, databases, configuration files, and quarto files</li>
<li>When data files were last updated, or whether they exist on disk at all</li>
<li>What Python modules are being imported, including ones internal and external (ie packages) to the project</li>
<li>How these all connect together</li>
</ul>
<p>It then visualises these relationships, and quite beautifully I think: let’s take a look.</p>
<p>Here’s the default output, which appears in the console, from running on a test repo I put together. If you haven’t come across <code>uvx</code> it’s an <a href="https://docs.astral.sh/uv/">Astral uv</a> command that does a one-off install just to use a tool (ie without installing that tool in a permanent Python environment). I’m imagining that <strong>smartrappy</strong> gets used in this way.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uvx</span> smartrappy tests/test_set_two</span></code></pre></div>
<pre class="text"><code>File Operations, Database Operations, and Import Analysis
================================================================================

File: data/input.csv
Operation: READ
Referenced in:
  - tests/test_set_two/data_processing.py

File: data/processed.csv
Operation: READ/WRITE
Referenced in:
  - tests/test_set_two/data_processing.py
  - tests/test_set_two/visualisation.py

File: equation.tex
Operation: READ/WRITE
Referenced in:
  - tests/test_set_two/model_solver.py
  - tests/test_set_two/slides.qmd

File: output.png
Operation: READ/WRITE
Referenced in:
  - tests/test_set_two/slides.qmd
  - tests/test_set_two/visualisation.py

💽 Database Operations:

Database: mydatabase
Type: mssql
Operation: READ/WRITE
Referenced in:
  - tests/test_set_two/data_processing.py

Module Imports:

Script: data_processing.py
  - import numpy [external]
  - import pandas [external]
  - import pyodbc [external]

Script: model_solver.py
  - from pathlib → pathlib:Path [external]

Script: visualisation.py
  - import pyplot [external]
  - import pandas [external]
  - from data_processing → data_processing:process_data [internal]

Terminal Visualisation
📦 Project Dependencies
┗━━ 📰 slides.qmd
    ┣━━ 📄 equation.tex
    ┃   ┗━━ 📜 model_solver.py
    ┃       ┗━━ 📦 pathlib:Path
    ┗━━ 📄 output.png
        ┗━━ 📜 visualisation.py
            ┣━━ 📄 data/processed.csv
            ┃   ┗━━ 📜 data_processing.py
            ┃       ┣━━ 📄 data/input.csv
            ┃       ┣━━ 💽 mydatabase
            ┃       ┃   ┣━━ Type: mssql
            ┃       ┃   ┗━━ ↻ data_processing.py (circular)
            ┃       ┣━━ 📦 pandas
            ┃       ┣━━ 📦 numpy
            ┃       ┗━━ 📦 pyodbc
            ┣━━ 📦 pandas
            ┣━━ 📦 pyplot
            ┗━━ 🔧 data_processing:process_data</code></pre>
<p>This gives you the flow of data and dependencies across the project. But it’s not so easy to save this console output and it’s still not the clearest ever. We really want, either, something that we can take away and analyse or a bona fide visualisation.</p>
<p>The <code>--format json</code> option gives you the best of both. If you give no output path, then you get json in the console, like this:</p>
<pre class="text"><code>JSON Representation
================================================================================
{
  "nodes": [
    {
      "id": "quarto_document_1193520",
      "name": "slides.qmd",
      "type": "quarto_document",
      "metadata": {}
    },
    {
      "id": "data_file_15482117",
      "name": "output.png",
      "type": "data_file",
      "metadata": {
        "exists": false
      }
    },
    ....</code></pre>
<p>Or you can pipe JSON, or the other output formats, to a folder:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a JSON for onward analysis</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uvx</span> smartrappy /path/to/project <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--format</span> json <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output</span> path/to/output/folder</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a PDF visualisation using Graphviz—requires the Graphviz application to be installed</span></span>
<span id="cb4-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uvx</span> smartrappy /path/to/project <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--format</span> graphviz <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output</span> path/to/output/folder</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a Mermaid diagram for embedding in Markdown</span></span>
<span id="cb4-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uvx</span> smartrappy /path/to/project <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--format</span> mermaid <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output</span> path/to/output/folder</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate all formats at once</span></span>
<span id="cb4-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uvx</span> smartrappy /path/to/project <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--all-formats</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output</span> path/to/output/folder</span></code></pre></div>
<p>You can also use it programmatically in your Python code:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> smartrappy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> analyse_project</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> smartrappy.reporters <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ConsoleReporter, GraphvizReporter</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Analyse the project</span></span>
<span id="cb5-5">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> analyse_project(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/path/to/your/project"</span>)</span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate console report</span></span>
<span id="cb5-8">console_reporter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ConsoleReporter()</span>
<span id="cb5-9">console_reporter.generate_report(model)</span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate graphviz visualization</span></span>
<span id="cb5-12">graphviz_reporter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GraphvizReporter()</span>
<span id="cb5-13">graphviz_reporter.generate_report(model, output_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path/to/your/outputs"</span>)</span></code></pre></div>
<p>Although, as noted, there are better and more precise ways to auto-document your code’s DAG, this means you can build an auto-documentation of your DAG to your repo!</p>
</section>
<section id="visualisation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="visualisation">Visualisation</h2>
<p>The two ‘for keeps’ visualisation formats are mermaid and graphviz. Here’s the latter, converted from a PDF to an SVG image for this post, and generated with</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uvx</span> smartrappy path/to/project <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--format</span> graphviz <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--internal</span></span></code></pre></div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/introducing-smartrappy/smartrappy_viz.svg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Graphviz and <strong>smartrappy</strong> produced visualisation of a research project</figcaption>
</figure>
</div>
<p>The <code>--internal</code> flag just restricts the visualisation to internal-only code imports, so ignores, eg, <code>import pandas as pd</code>. The repo it was pointed at is a research project where the slides and paper are generated from Quarto .qmd files but the <code>paper.qmd</code> file has yet to be modified much from its default settings. That’s why it depends on a file that doesn’t actually exist; it’s just got a default import in there.<sup>2</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;As an aside, the research repo was originally generated from <a href="https://github.com/aeturrell/cookiecutter-research-project">this cookiecutter</a>, which you can read more about <a href="../../../blog/posts/ultra-modern-python-cookiecutters/index.html">here</a>. In fact, <strong>smartrappy</strong> was generated from a cookiecutter too—<a href="https://github.com/aeturrell/cookiecutter-python-package">this one</a>, which you can read about in <a href="../../../blog/posts/ultra-modern-python-cookiecutters/index.html">the same post</a>.</p></div></div><p>This might sound like a pretty elaborate solution for something that’s maybe only useful for extremely complex projects, but the reality is that analytical codebases that are messy and not carefully joined up are <em>much</em> more common than ones that are.</p>
</section>
<section id="why-smartrappy-is-useful" class="level2">
<h2 class="anchored" data-anchor-id="why-smartrappy-is-useful">Why smartrappy is useful</h2>
<p>Unlike most production software, analytical code often has a different structure and purpose. Rather than building a long-lived application, we’re often answering specific questions or generating regular reports. Data flows from files to processing scripts to outputs, and understanding this flow is critical.</p>
<p>The problem is that these analytical pipelines can grow organically over time:</p>
<ul>
<li>A new data source gets added</li>
<li>Someone introduces a new intermediate processing step</li>
<li>A report format changes, requiring new outputs</li>
<li>The project outlives the original authors, and new team members have to make sense of it all</li>
<li>The IT of the institution doesn’t support advanced orchestration, or Make, or other automation tools, so manual steps can creep in</li>
<li>Diverse teams (that have lots of benefits in other ways) don’t always have the right skills to build or maintain fully automated DAGs</li>
</ul>
<p>And, before long, what started as a simple pipeline resembles a plate of tangled spaghetti.</p>
<p>By mapping out the dependencies automatically in a “best endeavours” way, <strong>smartrappy</strong> helps to <em>understand legacy code more quickly</em> and <em>verify that a reproducible analytical pipeline (RAP) is connected as expected</em>.</p>
</section>
<section id="more-on-how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="more-on-how-it-works">More on how it works</h2>
<p><strong>smartrappy</strong> basically searches for common patterns found in data analysis projects. The fact that Python has a fairly powerful built-in library to parse Python code (<a href="https://docs.python.org/3/library/ast.html">ast</a> for abstract syntax trees), plus some text analysis, makes this package possible. <strong>smartrappy</strong> can detect:</p>
<ul>
<li>Basic file operations with Python’s built-in <code>open()</code> function</li>
<li>Pandas operations like <code>pd.read_csv()</code>, <code>df.to_csv()</code>, etc.</li>
<li>Matplotlib figure saving with <code>plt.savefig()</code></li>
<li>Database operations with SQLAlchemy, psycopg2, sqlite3, etc.</li>
<li>Latex tables and equations</li>
<li>Module imports, distinguishing between internal and external dependencies</li>
<li>Quarto documents (<code>.qmd</code> files), including with embedded Python code chunks, includes, and markdown images</li>
</ul>
<p>It’s not perfect—it won’t catch every possible way you might read or write data—but it covers the most common patterns you’ll find in analytical code.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>While smartrappy is quite useful, it’s important to understand its limitations:</p>
<ol type="1">
<li>It uses static code analysis, so it won’t catch some dynamic patterns like using <code>**kwargs</code> to pass filenames.</li>
<li>It might miss custom file access methods or unusual patterns.</li>
<li>There are some naive features, for example: all modules containing database access get flagged as having circular imports.</li>
<li>It will never be as accurate in exposing the DAG as making the code and the DAG <em>the same thing</em></li>
</ol>


</section>


 ]]></description>
  <category>python</category>
  <category>data science</category>
  <category>reproducibility</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://www.aeturrell.com/blog/posts/introducing-smartrappy/</guid>
  <pubDate>Mon, 21 Apr 2025 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/code/logos/smartrappy.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Efficiency in the public sector: analysis and operations</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/public-sector-analytical-efficiency/</link>
  <description><![CDATA[ 





<p>I’ve been thinking a lot about efficiency in the public sector recently. This post looks at ideas for increasing the efficiency of analysis and operations through automation, good coding practices, artificial intelligence, and, well, (meta-?) analysis. This is the second post in this series; see the <a href="../../../blog/posts/public-sector-communication-efficiency/index.html">previous post</a> for ideas on efficiency related to communication and co-ordination.</p>
<section id="what-is-meant-by-analysis-and-operations" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-is-meant-by-analysis-and-operations">What is meant by analysis and operations?</h2>
<p><strong>What does it mean to make analysis more efficient? It is to produce analysis faster, cheaper, better, or in higher volume.</strong> Automation is key to doing this. And I’m thinking here of both ad hoc analysis and production analysis (eg regularly published statistics). Before we hit the ideas, it might help to give examples of these two types of analysis.</p>
<p>A good example of ad hoc analysis would be if, say, a global event meant that a lot more analysis was suddenly required on trade and trade links, typically in the form of answers to one-off questions. With such ad hoc analysis, you don’t know the <em>specific</em> question in advance—but you might know that, from time-to-time, questions about trade links will arise. So to improve the productivity of analytical operations in this case, you would want analysts or data scientists or economists, whoever it is, to have longitudinal data on bilateral trade flows to hand, with their permissions to access it cleared ahead of time, the data cleaned, the data stored in a sensible format, and the data accessible to suitable analytical tools. Essentially, it’s about putting analysts in the best position to answer the questions in a timely way as they arise, maximising agility and minimising repeated effort for when the next question lands.</p>
<p>An example of regular analysis would be a pipeline that ends in a publication and which involves data ingestion, data checking, processing, and publication of data alongside a report that has a fairly consistent structure. Perhaps this process involves a lot of manual steps, like handovers, emails, someone staring at a spreadsheet, and someone having to serve requests for custom cuts of the data. Improving productivity might look like automating the end-to-end pipeline, cutting out the manual steps, and, finally, serving the data up via an API so that people can take whatever cuts they want. It’s again minimising effort.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/public-sector-analytical-efficiency/automated_stats.webp" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Automation can take many forms</figcaption>
</figure>
</div>
<p>Turning to operations now; in every public sector institution, there are thousands of actions that are repeated every day by most staff. Something as basic as turning on a laptop or checking a calendar. <strong>If some of the tasks that happen repeatedly can be sped up even a little, then there’s a large saving to be made</strong>. This does require <em>measuring</em> how fast those tasks are today and, to get an idea of what the return on investment (ROI) might be, it also requires one to have a counter-factual in mind of how fast they <em>could</em> be with that investment.</p>
<p>With that background out of the way, let’s move on to some ideas!</p>
</section>
<section id="operations" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="operations">Operations</h2>
<section id="more-productive-capital" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="more-productive-capital">More productive capital</h3>
<p>I touched on computer-task time savings in the context of better hardware in <a href="../../../blog/posts/bad-it/index.html">this post on the false economy of bad IT</a>. TL;DR it <em>always</em> makes sense to buy staff earning over the median UK salary a high-spec laptop if they lose more than 9 minutes a day due to a low- to mid-range laptop being slow or glitchy. As an aside, the UK has relatively low capital stock, as seen in Figure&nbsp;1 (chart by <a href="https://www.mckinsey.com/our-people/tera-allas">Tera Allas</a>).</p>
<div id="fig-capital" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-capital-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/capital_stock_uk.jpeg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-capital-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Capital is important for productivity, who would have guessed?
</figcaption>
</figure>
</div>
<p>There’s a whole class of repeated tasks that people do on computers that are slower than they could be because of the computer’s hardware or configuration. How can the productivity (loss) be definitively tested? One option is a log of the times when someone’s workflow was interrupted because, say, the computer was turning on, or froze, or was opening an application. Another would be to measure the time it takes to do similar tasks in a perfect reference situation, eg the same task on a high-spec laptop, and use the time that took as the counterfactual. Similarly, one could measure productivity<sup>1</sup> with one software package relative to another to more accurately assess which is better (a lot of software will be chosen for reasons that are orthogonal to productivity, for reasons I sketch out in <a href="../../../blog/posts/public-sector-communication-efficiency/index.html#have-someone-own-the-trade-off">this other post</a>.)</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;I very purposefully say ‘productivity’ and not just ‘time’ here because the most expensive input to the production function is usually peoples’ time, not the time it takes software to run. Which is why data science only reaches for C++ and Rust, which are slower to write code in but run faster, when it’s absolutely necessary.</p></div></div><p>Now you might say, “ah, but you haven’t done a fair test—that low- to mid-range institutional laptop has lots of important extra security on it that the high-end reference laptop doesn’t.” You’re right, ideally one would do a like for like comparison where you would only change one feature at a time. Pragmatically, though, I would see it as a feature, not a bug—use it as a way to see the overall trade-off that’s being made between security + cost vs productivity.</p>
<p>Regardless of how you do it, once bottlenecks in productive workflows have been identified and assessed, investment resources can focus on improving them in the order of biggest benefit.</p>
<p>A partial alternative to going high-spec is to allow Bring Your Own Device (BYOD). This allows the institution’s data and software to be accessed via the personal devices of staff, which may be faster and may be more suited to staff (by selection). There are security issues around this, and it may not be a equitable solution—more junior staff may not be able to afford the same tech as those at the top of the organisation. Still, if it doesn’t make sense to stump up for a high-spec laptop for everyone this can be a great second option. One particularly secure combination that will be relevant to many public sector institutions is Apple hardware + iOS as an operating system + Microsoft<sup>2</sup> software, which allows people to use corporate account Outlook, Teams, Sharepoint, etc, etc, on iPhone and iPad (including with a keyboard, as long as it’s an Apple one). My iPad has a processor that’s 40% faster than my work laptop’s, so BYOD is a game-changer. Of course, you can’t do everything from an iPad<sup>3</sup>—but you can certainly do a lot.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Throughout, I’ll be referring to whether something or another plays well with Microsoft software. This is not because I think the public sector <em>should</em> be using Microsoft for everything, far from it, but—as I like to say—‘nobody ever got fired for buying Microsoft’, and the reality is that it’s what most public sector institutions use. Key exceptions I’m aware of are the <a href="https://interoperable-europe.ec.europa.eu/collection/open-source-observatory-osor/document/munichs-long-history-open-source-public-administration">Munich government</a>, the <a href="https://en.wikipedia.org/wiki/GendBuntu">French Gendarmarie</a>, who both use custom versions of Linux as part of their own efficiency drives, high security areas of many governments, some national laboratories, and of course computationally intensive systems.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;For all practical purposes, you can’t code directly on an iPad in the way you would a laptop or desktop. Yet.</p></div></div></section>
<section id="free-and-open-source-software" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="free-and-open-source-software">Free and open source software</h3>
<p>Free and open source software (FOSS) definitely isn’t always more efficient, but my rule of thumb is <strong>if there is a widely-used and close free and open source substitute, it will be far more efficient to use that rather than proprietary software</strong>.</p>
<p>Let’s look at a really clear example: Matlab vs Python. The latter is free and open source, does <em>almost</em> everything the former does, does vastly more other things to boot, and can be used in a wider range of places. Now there are some tasks for which Python is <em>not</em> a close substitute, and they really do need Matlab. But for most people, leveraging the massive Python ecosystem is more efficient.</p>
<p>There are many examples where paying for proprietary software makes sense because there is no close FOSS substitute. I am a fan of Obsidian, the markdown-based note-taking app. One of the reasons I think it’s great is that you never lose control of your data or the format it’s in: all of your notes are just markdown files and the Obsidian app just gives a fancy way to edit and view that content. The Obsidian app happens to be free but it’s not open source. I would similarly say there’s no FOSS equivalent of the incredible integration of hardware and software that Apple has achieved with the Macbook. But, equally, there are plenty of areas where direct FOSS substitutes do exist.</p>
<p>In my view, the high efficiency of widely-used FOSS comes through a bunch of channels:</p>
<ul>
<li>The ‘F’ stands for free! Productivity is output per unit of input, so free is pretty good.<sup>4</sup></li>
<li>Widely-used open source software is less likely to have critical security flaws.<sup>5</sup></li>
<li>Again because it’s open source, you actually know what it’s doing!</li>
<li>Very much related to the above, and somewhat counter-intuitively, it’s more private. You can see for yourself if there’s a backdoor. A proprietary software vendor knows, at the very least, that you bought the software: a maintainer of a FOSS package may not even know you exist.</li>
<li>By dint of being free and widely used, there are many ideas for how to improve it, and guides on how to use it.</li>
<li>You don’t get locked in to a proprietary software provider who can subsequently ratchet up the price or drop support for a critical feature.</li>
<li>Missing a feature you’d like for your org in a specific library? If it’s reasonable and within-scope, you can probably get it added by the maintainers. Or your org can simply add it for themselves. <a href="https://www.bloomberg.com/company/values/tech-at-bloomberg/python/">Bloomberg</a> is a good example of a company who has gone heavily down this route.</li>
<li>There’s also a diversity, equality, and inclusion benefit. Lots of students, especially those from poorer backgrounds, can’t afford expensive proprietary software but can use FOSS instead (as a student, I used a version of <a href="https://www.libreoffice.org/">LibreOffice</a>). Those with more resources may have been able to use proprietary software before they start work, which gives them an edge when they land their first job; FOSS helps level the field. Similarly, if you’re trying to be a leading public sector institution and inspire other institutions around the world, you’ll go further if you use FOSS because it’s accessible in every country.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;I can hear you saying that some FOSS is harder to use. Linux being harder to use than Windows is a good example, although that one is <em>far</em> less true today given the rise of user-friendly Linux distributions like Ubuntu. But if a piece of software is <em>so</em> much harder to use, I would argue it isn’t a close substitute!</p></div><div id="fn5"><p><sup>5</sup>&nbsp;If it did have security issues, they probably—but not certainly—would have already been exploited and fixed <em>because</em> it’s open. Call it the weak open source security efficiency hypothesis.</p></div></div></section>
<section id="operational-efficiencies" class="level3">
<h3 class="anchored" data-anchor-id="operational-efficiencies">Operational efficiencies</h3>
<p>AKA process efficiency. Computer tasks aren’t the only area where one could find operational efficiencies. There’s a whole set of efficiency gains that most organisations could find in their standard processes too. One example is around the permissions required to access data or install certain software, etc. In most public sector organisations I’ve observed, these have to be separately approved for each individual within a team. But another model would be to use team-level permissions—if someone joins Team A, it is assumed they will need access to a set of data used by Team A. This eliminates a lot of tedious time for managees and managers in requesting and approving, respectively, permissions. In another post in this series, <a href="../../../blog/posts/public-sector-communication-efficiency/index.html#asynchronous-working">I wrote about how presuming access and openness within the organisation</a> could also provide a boost—in that case, no permissions are needed!</p>
<p>That’s just one example. But by analysing how staff have to spend their time to get things done, one could find many more—and again try to minimise them.</p>
</section>
</section>
<section id="data-for-analysis" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="data-for-analysis">Data for analysis</h2>
<p>Most public sector organisations, probably most organisations in general, have a legacy systems problem that makes analysing data (particularly big data) painful. There are also legitimate reasons why security is often tight around the analytical tools that most public sector orgs can use. Between these two, it can take analysts <em>orders of magnitude longer</em> to analyse data using an institutions’ systems than it would the same size dataset on their own laptop or cloud account or open system. Analysis would go faster and be able to do more if these datasets were available outside the security fence.</p>
<p>Additionally, there is strong evidence that releasing datasets into the wild has huge benefits (eg <a href="https://www.usgs.gov/news/featured-story/landsats-economic-value-increases-256-billion-2023">Landsat data being released for free by the US government was estimated to have generated 25 billion USD in 2023</a>). You can think of the economic narrative like this: data are an input into lots of potential public goods. People wouldn’t pay for the data directly to make those public goods, as they don’t capture enough of the benefit themselves—but make the data free, and their private capture is enough for them to put the work in and generate public goods worth way more than the total revenue obtained by directly charging for the upstream data.</p>
<p>The form of those public goods may be especially beneficial for public sector institutions. You can think of situations where the public sector doesn’t have enough resources to perform all of the analysis it would ideally have. But, with the data out there, others might do the analysis—co-opting others to help with the overall analytical mission! Those other analysts might just be in another government department. (More on this idea of sharing as an efficiency in <a href="../../../blog/posts/public-sector-communication-efficiency/index.html#publishing-analysis">the previous post in this series</a>.)</p>
<section id="releasing-real-data" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="releasing-real-data">Releasing real data</h3>
<p>The first and most simple response to these pressures and productivity-sapping systems is to simply publish the data publicly, at least for data that aren’t proprietary or sensitive. And perhaps we can all be a bit more radical about what is and is not sensitive. An obvious example is firm-level data: UK legislation currently prohibits the Office for National Statistics from publishing information on individual firms, even though Companies House, another part of the UK state, <em>does</em> publish information on individual firms’ balance sheets.</p>
<p>Having important data be available publicly means staff within an institution can use non-restricted tools to work with it, which would be a massive boost to productivity. It means that any public goods that are possible with it are much more likely to be created, unlocking the true value and, potentially, it means that more relevant analysis would be happening with it than otherwise would be the case. And, especially if the <a href="../../../blog/posts/the-prize-with-apis/the-prize-with-apis.html">data are released via an API</a><sup>6</sup>, it means no more FOI requests or emails from other institutions—people can self-serve the cuts of the data that they need. The substantial time that public sector analysts spend serving Freedom of Information (FOI) and inter-departmental requests for data would simply no longer be needed for any data that are published.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;It’s not that hard to build an API using modern cloud tools, by the way. Check out <a href="../../../blog/posts/build-a-cloud-api/build-a-cloud-api.html">this post</a> for an example.</p></div></div></section>
<section id="synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data">Synthetic data</h3>
<p>However, most datasets that are used within public sector institutions are proprietary or sensitive or both. They simply can’t be shared externally. But what if there was a way to share the data without sharing the data? Well, there is—it’s called <strong>synthetic data</strong>.</p>
<p>Synthetic data are artificially generated data that are made to resemble real-world data in some of their statistical properties but in a non-disclosive way. It has been used by the US Census Bureau. There are mathematical guarantees about how hard it is to reverse the process and get back to the original data (a bit like encryption.) And you can set how strong this encryption is, though there’s a trade-off with preserving aggregate statistical properties.</p>
<p>One way synthetic data could be beneficial is if it was released and people could still get accurate statistical aggregations from it. But I imagine that most institutions wouldn’t be super comfortable with this as some statistics will be accurate but others won’t be. You can imagine instead creating synthetic data with extremely strong protection and releasing that, and allowing people to develop with it. Once an analytical script developed on the synthetic data is ready, staff and even externals could submit it to be run on the sensitive data (on what is probably a more expensive computational setup.) The benefit of synthetic data is that the bottleneck around the sensitivities of the data and access to it via specialist secure platforms are removed for most of the development process (except the last stage.) From a science point of view, there are even some attractions to working blind to the actual results in this way—it’s a bit like pre-registering the analysis for a medical trial.</p>
<p>Of course, there is no free lunch—there is some work to do for the institutional data owner in generating and releasing the synthetic data, and to do it at scale probably needs cloud computing. And it’s not the easiest concept to explain to people who are less in the data science space either, so senior colleagues may struggle to understand the risks and benefits.</p>
<p>There are well-developed packages to work with synthetic data, for example to:</p>
<ul>
<li>generate synthetic data, eg <a href="https://github.com/sdv-dev/SDV">Synthetic Data Vault</a> and <a href="https://github.com/mostly-ai/mostlyai">Synthetic Data SDK</a></li>
<li>evaluate how close synthetically generated data are to the real underlying data, eg <a href="https://docs.sdv.dev/sdmetrics">SDmetrics</a></li>
<li>benchmark how quickly <a href="https://github.com/sdv-dev/SDGym">synthetic data are generated</a> according to different methods</li>
</ul>
<p>I was quite involved in synthetic data at the Office for National Statistics, running a team that tried to use it in practice. They did excellent work. If you’re really interested in using it in anger, you should reach out to ONS’ Data Science Campus. You can find a number of posts on the topic that are by my former colleagues <a href="https://datasciencecampus.ons.gov.uk/category/projects/synthetic-data-and-pets/">here</a>. They also have a recent data linkage package that uses synthetic data so that two public sector institutions can link data without seeing sensitive columns; you can find that <a href="https://github.com/datasciencecampus/pprl_toolkit">here</a>.</p>
</section>
<section id="fake-data" class="level3">
<h3 class="anchored" data-anchor-id="fake-data">Fake data</h3>
<p>Even if the risk appetite of your institution doesn’t extend to synthetic data, perhaps it would extend to entirely <strong>fake data</strong>? If you like this is an extreme form of synthetic data where the encryption cannot be reversed (as opposed to ‘cannot practically be reversed’ with synthetic data). Fake data have only the same data types (eg string) and forms (eg an email address) of original data but are otherwise completely and utterly made up. This means that fake data have all the benefits of synthetic data bar statistical aggregates being approximately similar to those that would have derived from the real data.</p>
<p>There are a number of packages that can generate fake data that are extensible and with which you can create schemas that produce an entire set of fake data in the style you want. For example, <a href="https://faker.readthedocs.io/">Faker</a>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> faker <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Faker</span>
<span id="cb1-2">fake <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Faker()</span>
<span id="cb1-3"></span>
<span id="cb1-4">fake.name()</span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 'Lucy Cechtelar'</span></span>
<span id="cb1-6"></span>
<span id="cb1-7">fake.address()</span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># '426 Jordy Lodge</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Cartwrightshire, SC 88120-6700'</span></span>
<span id="cb1-10"></span>
<span id="cb1-11">fake.text()</span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 'Sint velit eveniet. Rerum atque repellat voluptatem quia rerum. Numquam excepturi</span></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  beatae sint laudantium consequatur. Magni occaecati itaque sint et sit tempore. Nesciunt</span></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  amet quidem. Iusto deleniti cum autem ad quia aperiam.</span></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  A consectetur quos aliquam. In iste aliquid et aut similique suscipit. Consequatur qui</span></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  quaerat iste minus hic expedita. Consequuntur error magni et laboriosam. Aut aspernatur</span></span>
<span id="cb1-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  voluptatem sit aliquam. Dolores voluptatum est.</span></span>
<span id="cb1-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Aut molestias et maxime. Fugit autem facilis quos vero. Eius quibusdam possimus est.</span></span>
<span id="cb1-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Ea quaerat et quisquam. Deleniti sunt quam. Adipisci consequatur id in occaecati.</span></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Et sint et. Ut ducimus quod nemo ab voluptatum.'</span></span></code></pre></div>
<p>And <a href="https://mimesis.name/master/">Mimemsis</a>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mimesis <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Person</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mimesis.locales <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Locale</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mimesis.enums <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Gender</span>
<span id="cb2-4">person <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Person(Locale.EN)</span>
<span id="cb2-5"></span>
<span id="cb2-6">person.full_name(gender<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Gender.FEMALE)</span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output: 'Antonetta Garrison'</span></span>
<span id="cb2-8"></span>
<span id="cb2-9">person.full_name(gender<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Gender.MALE)</span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output: 'Jordon Hall'</span></span></code></pre></div>
</section>
</section>
<section id="reproducible-analytical-pipelines" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reproducible-analytical-pipelines">Reproducible analytical pipelines</h2>
<p>A reproducible analytical pipeline (RAP) is a series of steps that trigger one after the other to produce an analysis from data ingestion all the way to the end product. It’s a form of <em>automation</em>. To illustrate why there are big efficiency gains to be had with them, let’s first look at an end-to-end process that <em>doesn’t</em> use RAP.</p>
<section id="getting-a-bad-rap" class="level3">
<h3 class="anchored" data-anchor-id="getting-a-bad-rap">Getting a bad RAP</h3>
<p>Let’s take a high-stakes analytical pipeline that has lots of potential for improvement and efficiencies—but which is extremely common in the wider public sector. Imagine a process for publishing some key economic statistics that looks like this:</p>
<ol type="1">
<li>Statistical office publishes new data in an Excel file</li>
<li>An analyst downloads the file onto a network drive</li>
<li>Analyst checks the file by eye and copies specific cells into another Excel workbook that has the analysis</li>
<li>Analyst drags out the equations behind the cells to incorporate the new data</li>
<li>Values from the calculations get manually typed into a third spreadsheet, which also has a tab with sensitive data in</li>
<li>The results then get manually copied into a Word document for a report</li>
<li>The final calculations tab from the third spreadsheet is published externally, alongside the report</li>
</ol>
<p>Apart from being heavily manual, this process has multiple failure points:</p>
<ul>
<li>Perhaps there’s an earlier, unrevised version of the same file already on a network drive and that is used by mistake in step 3.</li>
<li>Excel messes with data—it <a href="https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates">changes dates and names, and data types</a></li>
<li>Excel doesn’t support larger datasets, so rows are missed</li>
<li>Manual copy-paste errors</li>
<li>Equations are different in different cells, and the analyst doesn’t notice because equations are hidden</li>
<li>Calculations break if someone adds/removes rows</li>
<li>Cannot see if there are changes in the calculations since last time the spreadsheet was run</li>
<li>Time consuming manual checks</li>
<li>Any mistake in step 1 means redoing all steps manually again</li>
<li>High risk of the sensitive data being published alongside the other data</li>
</ul>
<p>Perhaps you think this is all a bit implausible. Sadly, it isn’t! Here are some real-world examples of where Excel-based pipelines have gone wrong:</p>
<ul>
<li>On Thursday, 3rd August 2023, an FOI request was made to the Police Service of Northern Ireland (PSNI). It asked for the “number of officers at each rank and number of staff at each grade”. PSNI sent back not just the numbers of officers at each rank in the spreadsheet they returned but every employee’s initials, surname, and unit—even those working out of MI5’s Northern Irish headquarters. Sensitive information on <em>10,000 people</em> was released by mistake, because of an extra tab in the Excel file.</li>
<li>There’s the infamous case of the UK’s Covid Test and Trace programme. Civil servants were tracking cases in an Excel spreadsheet that was limited to 65,000 rows, and thus missed a bunch of infections, not to mention crucial links in the spread of the disease. Excel simply ran out of numbers. Work by economists Thiemo Fetzer and Thomas Graeber has shown that this <a href="https://www.medrxiv.org/content/10.1101/2020.12.10.20247080v1">probably led to an extra 125,000 COVID infections</a>.</li>
<li><a href="https://www.ft.com/content/57acfb54-6a62-46d6-b930-87b19c2ab2d3">Hans Peter Doskozil</a> was mistakenly announced as the new leader of Austria’s Social Democrats (SPÖ) because of a “technical error in the Excel list”.</li>
<li>One government department published a spreadsheet that still had a note in it that said “Reason for arrest data is dodgy so maybe we shouldn’t publish it.”</li>
<li>Mathematical models written in Excel are especially vulnerable to mistakes. In a paper that was highly influential, economists Carmen Reinhart and Ken Rogoff found that economic growth slows dramatically when the size of a country’s debt rises above 90% relative to GDP. But the formula in their spreadsheet column missed out some of the countries in their data. A <a href="https://www.ft.com/content/1c3bae3c-a6ce-11e2-95b1-00144feabdc0">student found the error</a>, and realised that removing it made the results less dramatic.</li>
<li>The Norwegian Soveign Wealth Fund’s 2023 <a href="https://www.ft.com/content/db864323-5b68-402b-8aa5-5c53a309acf1">Excel snafu</a> saw it miscalculate an index due to a “decimal error”. The mistake cost 92 million dollars.</li>
<li>Back in 2012, J.P. Morgan went even further and racked up <em>$6 billion of losses</em> in part due to a “value-at-risk” model being <a href="https://www.ft.com/content/80bc5046-6ed2-30ef-b31a-bcbeac55d8bb">manually copied and pasted</a> across spreadsheet cells.</li>
</ul>
<p>There are many more examples: you can find a list at the delightfully named <a href="https://eusprig.org/">European Spreadsheet Risks Interest Group</a>. Now, good reproducible analytical pipeline (RAP) practices cannot protect you from mistakes, but <strong>reproducible analytical pipelines can substantially lower the risk of errors while also saving time via automation</strong>.</p>
</section>
<section id="good-rap" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="good-rap">Good RAP</h3>
<p>What does a good RAP look like? There are a number of technologies and practices that can help create a RAP that avoids mistakes and saves tons of time and labour to boot. Some of these RAP technologies and practices are listed below in, roughly, the order in which they would be used in a data pipeline.</p>
<ul>
<li>Use an <a href="../../../blog/posts/the-prize-with-apis/the-prize-with-apis.html">API</a> to programmatically access the latest version of the data</li>
<li>Keep a copy of the raw, downloaded version of the data so that you can always come back to it. Use datetime versioning to keep track of download time.</li>
<li>Use <a href="../../../blog/posts/the-data-validation-landscape-in-2025/index.html">data validation</a> checks to ensure that the data looks how you expect it to on receipt</li>
<li>Use code to process the data, rather than Excel spreadsheets. And use code<sup>7</sup> that is:
<ul>
<li>under <a href="https://aeturrell.github.io/coding-for-economists/wrkflow-version-control.html">version control</a>, so that it is completely auditable and all changes are logged</li>
<li>is well-formatted and linted, perhaps by a tool such as <a href="https://astral.sh/ruff">Ruff</a>.</li>
<li>has <a href="https://pre-commit.com/">pre-commit</a> enabled with hooks that check for data, secrets, and other sensitive information submitted by mistake, and which auto-checks quality</li>
<li>has tests so that everyone feels assured the code is doing the right thing</li>
<li>subject to pull requests whenever it changes, so that multiple people sign off on important code</li>
<li>is tested, etc., using runners, eg GitHub Actions</li>
<li>is reproducible, including the set of packages and version of the language (eg via a <code>pyproject.toml</code> file and use of a tool like <a href="https://docs.astral.sh/uv/">uv</a>) and ideally for which the operating system is also reproducible too (eg via <a href="https://www.docker.com/">Docker</a>)</li>
</ul></li>
<li>Use a data orchestration tool to execute the entire code processing pipeline from start to finish. Some popular orchestration tools are <a href="https://airflow.apache.org/">Apache Airflow</a> (first generation) and <a href="https://docs.dagster.io/">Dagster</a> and <a href="https://docs.prefect.io/v3/get-started/index">Prefect</a> (both second generation). See below for an example of Prefect in action. Orchestration flows can be triggered on events, for example if a new file lands in a folder, or on a schedule. (An easier way in to execute-code-on-event for small, local problems is via packages such as <a href="https://pythonhosted.org/watchdog/index.html">watchdog</a> which watches for file changes and takes actions.)</li>
<li>If there is a big overhead to using big data systems, use <a href="https://duckdb.org/">DuckDB</a> for processing fairly large datasets locally (say, up to 1TB). Don’t like writing SQL queries? Don’t worry no-one does—but <a href="https://ibis-project.org/">there are packages that can help</a>.</li>
<li>Store the cleaned data or results in a database.</li>
<li>Use anomaly detection techniques, etc, on the created statistics to check that they are plausible. (With a human in the loop!)</li>
<li><a href="../../../blog/posts/build-a-cloud-api/build-a-cloud-api.html">Build an API</a> to disseminate the created statistics</li>
<li>Create the report using a tool which can reproduce the same charts via code each time, eg <a href="https://quarto.org/">Quarto</a>, which can execute code chunks and be used to produce Word documents, HTML pages, PDFs, and even websites. (I wrote a short guide <a href="https://aeturrell.github.io/coding-for-economists/wrkflow-quarto.html">here</a>.) Oh yeah, it does Powerpoints and Beamer presentations too.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Many of these code features are present in the <a href="https://github.com/aeturrell/cookiecutter-python-package">cookiecutter Python package</a>; blog on that available <a href="../../../blog/posts/ultra-modern-python-cookiecutters/index.html">here</a>.</p></div></div><p>Just as an aside, here’s how to orchestrate a simple data pipeline that runs every hour with Prefect:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Contents of flow.py</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Any</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> httpx</span>
<span id="cb3-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> prefect <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> flow, task <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prefect flow and task decorators</span></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span>(retries<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb3-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fetch_stats(github_repo: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]:</span>
<span id="cb3-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Task 1: Fetch the statistics for a GitHub repo"""</span></span>
<span id="cb3-10"></span>
<span id="cb3-11">    api_response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> httpx.get(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"https://api.github.com/repos/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>github_repo<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-12">    api_response.raise_for_status() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Force a retry if not a 2xx status code</span></span>
<span id="cb3-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> api_response.json()</span>
<span id="cb3-14"></span>
<span id="cb3-15"></span>
<span id="cb3-16"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@task</span></span>
<span id="cb3-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_stars(repo_stats: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>:</span>
<span id="cb3-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Task 2: Get the number of stars from GitHub repo statistics"""</span></span>
<span id="cb3-19"></span>
<span id="cb3-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> repo_stats[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'stargazers_count'</span>]</span>
<span id="cb3-21"></span>
<span id="cb3-22"></span>
<span id="cb3-23"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@flow</span>(log_prints<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-24"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> show_stars(github_repos: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>]):</span>
<span id="cb3-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Flow: Show the number of stars that GitHub repos have"""</span></span>
<span id="cb3-26"></span>
<span id="cb3-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> repo <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> github_repos:</span>
<span id="cb3-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Call Task 1</span></span>
<span id="cb3-29">        repo_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fetch_stats(repo)</span>
<span id="cb3-30"></span>
<span id="cb3-31">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Call Task 2</span></span>
<span id="cb3-32">        stars <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_stars(repo_stats)</span>
<span id="cb3-33"></span>
<span id="cb3-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the result</span></span>
<span id="cb3-35">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>repo<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stars<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> stars"</span>)</span>
<span id="cb3-36"></span>
<span id="cb3-37"></span>
<span id="cb3-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run the flow</span></span>
<span id="cb3-39"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb3-40">    show_stars([</span>
<span id="cb3-41">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PrefectHQ/prefect"</span>,</span>
<span id="cb3-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pydantic/pydantic"</span>,</span>
<span id="cb3-43">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"huggingface/transformers"</span></span>
<span id="cb3-44">    ])</span></code></pre></div>
<p>This flow can be executed on a schedule by running the below (assuming that you have already set up a worker pool—see the Prefect documentation for more):</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> prefect <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> flow</span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Source for the code to deploy (here, a GitHub repo)</span></span>
<span id="cb4-4">SOURCE_REPO<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://github.com/prefecthq/demos.git"</span></span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb4-7">    flow.from_source(</span>
<span id="cb4-8">        source<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>SOURCE_REPO,</span>
<span id="cb4-9">        entrypoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_workflow.py:show_stars"</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specific flow to run</span></span>
<span id="cb4-10">    ).deploy(</span>
<span id="cb4-11">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my-first-deployment"</span>,</span>
<span id="cb4-12">        parameters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{</span>
<span id="cb4-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"github_repos"</span>: [</span>
<span id="cb4-14">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PrefectHQ/prefect"</span>,</span>
<span id="cb4-15">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pydantic/pydantic"</span>,</span>
<span id="cb4-16">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"huggingface/transformers"</span></span>
<span id="cb4-17">            ]</span>
<span id="cb4-18">        },</span>
<span id="cb4-19">        work_pool_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my-work-pool"</span>,</span>
<span id="cb4-20">        cron<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0 * * * *"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run every hour</span></span>
<span id="cb4-21">    )</span></code></pre></div>
<p>I share this to show that automation of code doesn’t have to be super complicated—with the cloud, it’s achievable in a few lines!</p>
<p>There’s a lot in the list above. But doing all of the above not only massively reduces the risk of mistakes, it also makes it <em>far</em> easier to find mistakes when they do occur. And, the automation saves masses of time—allowing analysts to focus where they can add the most value.</p>
<p>You can find more on reproducibility and RAP <a href="https://aeturrell.github.io/coding-for-economists/wrkflow-rap.html">here</a> and <a href="https://analysisfunction.civilservice.gov.uk/support/reproducible-analytical-pipelines/">here</a>, and <a href="https://aeturrell.github.io/coding-for-economists/auto-research-outputs.html">here</a> in the context of research.</p>
<p>Finally, I realise that having people with the skills to do RAP to this standard is difficult and potentially expensive in itself. The market clearly recognises the benefits too, which is why data scientists are in such high demand! For me, overall, this is a much better way of doing things and even if the input costs are potentially higher, the output quality is likely to be <em>significantly</em> higher—so I contend that you still win out on productivity overall.</p>
</section>
</section>
<section id="technical-communication-and-code-documentation" class="level2">
<h2 class="anchored" data-anchor-id="technical-communication-and-code-documentation">Technical communication and code documentation</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This section is significantly more technical than the others and some readers may want to skip it and go straight to Model Behaviour.</p>
</div>
</div>
<p>I already covered the efficiencies that could be unlocked by <a href="../../../blog/posts/public-sector-communication-efficiency/index.html#asynchronous-working">obsessively using documentation</a> in a previous post on efficiency. Many of the same benefits apply from documenting code obsessively too. As a reminder, those benefits include faster onboarding, having a single source of truth, making it easy to avoid stale documentation, more auditability, less likelihood of (in this case) code being used incorrectly, and, if the documentation is shared, transparency.</p>
<p>However, there are some extra actions you can take with the documentation of code to squeeze every last drop of efficiency out of these benefits.</p>
<p>At a minimum, each code repository should have a markdown README file that sets out what it is about and how to use it.</p>
<p>The code itself should have sensible comments, and use informative variable, function, method, and class names. Functions, classes, and methods should have <a href="https://en.wikipedia.org/wiki/Docstring">docstrings</a> (comment blocks that say what the object does.) I tend to use the Google-style docstring conventions, defined in <a href="https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings">Google’s Python style guide</a>, but there are other docstring conventions around. Here’s an example of Google-style docstring on a function:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _create_unicode_hist(series: pd.Series) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> pd.Series:</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Return a histogram rendered in block unicode.</span></span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Given a pandas series of numerical values, returns a series with one</span></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    entry, the original series name, and a histogram made up of unicode</span></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    characters. However, note that the histogram is very approximate, partly</span></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    due to limitations in how unicode is displayed across systems.</span></span>
<span id="cb5-8"></span>
<span id="cb5-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        series (pd.Series): Numeric column of data frame for analysis</span></span>
<span id="cb5-11"></span>
<span id="cb5-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb5-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        pd.Series: Index of series name and entry with unicode histogram as</span></span>
<span id="cb5-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        a string, eg '▃▅█'</span></span>
<span id="cb5-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span></code></pre></div>
<p>It’s not just helpful for people looking at the innards of the code, it also helps if people are using functions and methods from the code in other code. If someone were to call <code>help(_create_unicode_hist)</code> then they would get the docstring back. In sophisticated development environments like Visual Studio Code, they would get a pop-up of this docstring even when just hovering their mouse over the function.</p>
<p>For critical code, you may want to consider having code <em>type annotations</em>, aka <em>type hints</em> too. The code example above has those: in this case <code>series</code> has type <code>pd.Series</code> and the function returns <code>pd.Series</code> too (this is what <code>-&gt; pd.Series</code> does.) Type hints are just that, hints to help people understand what types of object are supposed to be going into and out of modular parts of code like functions and methods. Because they are hints, they’re included in this section on documenting code—adding type hints helps others understand what’s supposed to happen.</p>
<p>If you’re really concerned about making sure the code is not used incorrectly, you can even enforce type hints, either at run time, so that if a user runs the code with the wrong data types an error is thrown, or at development time, so that the developer gets a warning that the internals of the code don’t adhere to the given type hints. <a href="https://typeguard.readthedocs.io/">typeguard</a> is a popular package for run-time type checking, while for development time (aka static) type checking, <a href="https://mypy-lang.org/">Mypy</a> and <a href="https://microsoft.github.io/pyright/">Microsoft’s Pyright</a> are the biggest libraries around.</p>
<p>But you can go further! You’ll notice that the type annotations are, in effect, repeated in both the docstring and in the function signature. This means they could say different things, which would be confusing to users. Have no fear, though, because <em>there’s a package for that</em> (there always is): <a href="https://jsh9.github.io/pydoclint/">Pydoclint</a> trawls through your docstrings and type annotations and tells you if they diverge.</p>
<p>But you can go even further! Let’s say you want to help people understand, practically, how to use a function, method, or class. Well, you can also add example code to docstrings. Here’s the format:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> skim(</span>
<span id="cb6-2">    df_in: Union[pd.DataFrame, pl.DataFrame],</span>
<span id="cb6-3">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb6-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Skim a pandas or polars dataframe and return visual summary statistics on it.</span></span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    skim is an alternative to pandas.DataFrame.describe(), quickly providing</span></span>
<span id="cb6-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    an overview of a data frame via a table displayed in the console. It produces a different set of summary</span></span>
<span id="cb6-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    functions based on the types of columns in the dataframe. You may get</span></span>
<span id="cb6-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    better results from ensuring that you set the datatypes in your dataframe</span></span>
<span id="cb6-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    you want before running skim.</span></span>
<span id="cb6-11"></span>
<span id="cb6-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Note that any unknown column types, or mixed column types, will not be</span></span>
<span id="cb6-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    processed.</span></span>
<span id="cb6-14"></span>
<span id="cb6-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb6-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        df_in (Union[pd.DataFrame, pl.DataFrame]): Dataframe to skim.</span></span>
<span id="cb6-17"></span>
<span id="cb6-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Raises:</span></span>
<span id="cb6-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        NotImplementedError: If the dataframe has a MultiIndex column structure.</span></span>
<span id="cb6-20"></span>
<span id="cb6-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Examples</span></span>
<span id="cb6-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    --------</span></span>
<span id="cb6-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Skim a dataframe</span></span>
<span id="cb6-24"></span>
<span id="cb6-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        &gt;&gt;&gt; df = pd.DataFrame(</span></span>
<span id="cb6-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                {</span></span>
<span id="cb6-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                'col1': ['Philip', 'Turanga', 'bob'],</span></span>
<span id="cb6-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                'col2': [50, 100, 70],</span></span>
<span id="cb6-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                'col3': [False, True, True]</span></span>
<span id="cb6-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                })</span></span>
<span id="cb6-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        &gt;&gt;&gt; df["col1"] = df["col1"].astype("string")</span></span>
<span id="cb6-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        &gt;&gt;&gt; skim(df)</span></span>
<span id="cb6-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span></code></pre></div>
<p>where you can add as many examples as you like.</p>
<p>Now this is helpful in itself because it guides users as to how to use a bit of code. But, again, what if the examples were written 2 years ago and the code has changed? <em>There’s a package for that!</em> Using a package called <a href="https://github.com/Erotemic/xdoctest">xdoctest</a> you can, you guessed it, test that any examples in your docstrings actually run and do what the docstring says they will do.</p>
<p>This is all very nice, but lots of people don’t want to go trawling through code. They want to read a glossy guide. The problem with guides, though, is that they’re often left to go stale while the code itself changes. You may have seen situations where there’s an Excel-based model and somewhere, floating around, a Word document explaining what that Excel model does. But who knows how much they are conjointly kept up to date?</p>
<p>Fortunately, there’s a way to build documentation that sits with your code, and is in lock-step with it. The technology is called <a href="https://quarto.org/">Quarto</a>, and it’s a flexible document publishing system (where “document” includes websites and slides!) Perhaps the greatest power of Quarto is that you can put chunks of code into the source that gets compiled into a document and, in that final product, the outputs from the code will appear too (and only the outputs if you wish.) This means you can create documentation with Quarto (in the form a Word document or website) and keep the source files for that documentation in exactly the same place as your code. <em>Even better</em>, you can include examples of using the code in the documentation and you know it will be <em>exactly</em> the same code as in your software, and that it will work—because if it doesn’t, the documentation simply won’t build!</p>
<p>But wait… you can go <em>even</em> further! You’ve spent all of this effort on lovely docstrings that tell people about how the modular parts of the code work and are meant to be used, and perhaps you even have examples in there too. What if you could automatically include all of that nice within-code documentation in your actual documentation? <em>There’s a package for that</em>! The massively underrated <a href="https://machow.github.io/quartodoc">Quartodoc</a> allows you to automatically pull docstrings from your code base and insert them into your documentation. It really is efficient, helpful, and a lot of fun too.</p>
<p>For an example of this self-documenting behaviour in action, check out the website for my package <a href="https://aeturrell.github.io/specification_curve/">Specification Curve</a> or for econometrics regression package <a href="https://py-econometrics.github.io/pyfixest/pyfixest.html">Pyfixest</a>. In both cases, the writing is interspersed with examples of running real code from the packages. For both websites, there’s a reference page where parts of the code are automatically documented using Quartodoc.</p>
<p>A lot of this is overkill for a lot of projects. But for complex analysis code on the critical path to a major publication that your institution produces? It’s a huge help and likely worth it.</p>
</section>
<section id="model-behaviour" class="level2">
<h2 class="anchored" data-anchor-id="model-behaviour">Model Behaviour</h2>
<p>When it comes to models, there are a lot of bad practices around. For me, the most worrying is that <em>most models are not versioned</em>. This means that if a decision was taken, or an analysis performed, with a model at time <img src="https://latex.codecogs.com/png.latex?T=t"> and it’s now time <img src="https://latex.codecogs.com/png.latex?T%3Et"> and the model is different, you’ve very little chance of getting back to the original model. Yes, this is true even if you’re using version control. That’s because a model is composed of three things: the code, the data, and (often) the random numbers used. You should version control code, and ideally you’d set the seed of your random numbers in that code too. But few people version data, so even if you have code and random numbers under control, you’ll need to version models.</p>
<p>Why does this matter for efficiency? Not knowing why some part of your analysis is why it is, and having to dig back through and do detective work, is very time-consuming when it is needed. And it happens fairly often with models. A classic example would be if you were asked to do a retrospective forecast evaluation—how did the model you used two years ago perform? Has performance degraded since then? Additionally, you can test whether changes you’ve made to the model’s algorithm are actually improving its performance. So <strong>investing in model versioning can reduce time costs further down the line</strong>.</p>
<p>A second part of model efficiency is continuous integration and continuous deployment. Enough has been written elsewhere about what these are that I’ll give the briefest summary of what they mean in this context. Continuous integration for models could involve automatically evaluating performance, or other metrics, when a new model is created. Continuous deployment would mean that when a new version of a model is ready, it automatically gets served up as an API.</p>
<p>The latter idea, that models get served up as an API, is really important for efficiency. Today, if I’m in department X and I want to use a model in department Y to get predictions, I have to email someone in department Y, get them the permissions for the data that will form the input and then the data itself, and persuade them to take time out of whatever else they were doing to run it! If the model is deployed, I skip all that, and can work asynchronously—I simply use my data to ping the API and get the prediction straight back into my analytical tool. There’s more about asynchronous working and its efficiency benefits <a href="../../../blog/posts/public-sector-communication-efficiency/index.html#asynchronous-working">here</a>.</p>
<p>There is a way to get most of these benefits pretty easily on the cloud using a <em>model registry</em>: a repository for privately storing models and their versions (from which those models can also be deployed.) I wrote at length about model registries <a href="../../../blog/posts/why-have-a-model-registry/index.html">here</a> and, rather than repeat myself here, I’ll defer the reader to that post for more information.</p>
</section>
<section id="artificial-intelligence-ai" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="artificial-intelligence-ai">Artificial Intelligence (AI)</h2>
<p>A former boss of mine, now even more heavily invested in the AI world than he was when we worked together, recently told me “don’t have an AI strategy, have a business strategy that makes use of AI.” It stuck with me, partly because there are so many AI strategies around, but mostly because he’s right: AI is a tool and not a business plan. We don’t have a keyboard strategy or an email strategy.<sup>8</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;Though now I think about it, perhaps there’d be some merit to the latter?</p></div></div><p>That said, AI is also quite new and people are still thinking through how it can be used to improve efficiency. So, in this section, I offer a few ideas around using AI to improve analysis and operations. (In the <a href="../../../blog/posts/public-sector-communication-efficiency/index.html">previous post in this series</a>, which covered communication and co-ordination, some AI uses also featured—for transcription, meeting summarisation and minutes, and for searching the stock of institutional knowledge.)</p>
<p>A huge one is as a coding aid. GitHub Copilot is the leader, and large-institution-friendly in the sense that it’s all owned by Microsoft. I’ve been hugely impressed by, for example, Claude 3.7 Sonnet, as a back-end model. Whether you’re a new developer and need a chat with an artificial coding expert, or an experienced developer who knows what they need and can prompt the AI in the right way, coding aids are a huge benefit—though they are not trivial to use and there is a learning curve. It’s also very possible that, in the near future, AI models will be able to look at issues and raise pull requests without intervention. Coding aids are also helpful in a world where data science talent is scarce. The prolific Simon Willison has written about <a href="https://simonwillison.net/2025/Mar/11/using-llms-for-code/">how he uses LLMs to help him write code</a>, and there are likely few guides as out there today as good as his.</p>
<p>Another area where AI is particularly helpful with efficiency is review and critique. As a manager, you do often end up saying the same kinds of things over and over again—whether that’s about a note, or code, or a presentation. What if I as a manager had a set of prompts that could precede content by staff in a large language model (LLM) query and which gave them a helpful first cut of what I would have said anyway? That means our time together as two humans reviewing the work can be focused on the less obvious, more subtle, and frankly more interesting questions and issues. A simpler way to do this is for the managee to just ask for a general review. If you do research, LLMs also do a reasonably good job of acting as practice reviewers.</p>
<p>One area of LLMs that is likely to grow is auto-analysis. Instead of me as an analyst having to come up with, say, SQL queries to explore the data, I just say to the LLM, start exploring these data and tell me about anything useful. It doesn’t have to be analysis, it could be coding some software up too. Quite a few models now have code execution capabilities, and consumer-facing products in this space will only grow over time. This is going to democratise who can do analysis, which is a good thing, and will be especially helpful for senior leaders who want to make quick queries.</p>
<p>I’m fairly sure I don’t believe it<sup>9</sup>, but the <a href="https://www.theintrinsicperspective.com/p/why-we-stopped-making-einsteins">theory that geniuses stopped appearing because we stopped educating a handful of people with uber-elite tutors</a> (aka aristocratic tutoring) has always stuck with me. However, you don’t have to believe in the hard form of this thesis to think that having an extremely good tutor who is available 24/7 would be helpful for learning. Well, let’s now imagine that everyone in the public sector can have access to the most knowledgeable (if not always the smartest) tutor on the planet! The possibilities for (self-)teaching using LLMs are strong. I’ve found that I can simply say, “write some questions to test me on X”, or “prepare a lesson on Y”, and get something very sensible.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;Many <a href="https://www.astralcodexten.com/p/contra-hoel-on-aristocratic-tutoring">others aren’t convinced either</a>.</p></div></div><p>My final category of ways that AI can immediately help with public sector efficiency is perhaps the most obvious one: improving analysis directly. I wrote a lot about the ways that data science more broadly can help with efficiency in my <a href="../../../blog/posts/data-science-with-impact/index.html">post on data science with impact</a>, so I’ll refer you to that to find out more what the possibilities are in this space. I also have a recent paper and book chapter out on this very question too, called <a href="../../../research/chapters/turrell-2025/index.html">“Cutting through Complexity: How Data Science Can Help Policymakers Understand the World”</a>, which is chock full of examples.</p>
</section>
<section id="automating-and-organising-the-office" class="level2">
<h2 class="anchored" data-anchor-id="automating-and-organising-the-office">Automating and organising the office</h2>
<section id="automation-with-code" class="level3">
<h3 class="anchored" data-anchor-id="automation-with-code">Automation with code</h3>
<p>On this blog, we like code, because it’s transparent, usually it’s FOSS, it’s auditable, and it’s reproducible. So, where possible, it’s best practice to automate with code. What kind of office tasks can be done with code?</p>
<p>In the private sector, tools like Slack—with their very powerful code integrations—seem to be more dominant. However, a lot of public sector organisations use Microsoft and its suite of office tools. These are, happily, scriptable with code. In particular, Microsoft has tools that aid with automating the use of its office software, including:</p>
<ul>
<li><a href="https://github.com/AzureAD/microsoft-authentication-library-for-python">Microsoft Authentication Library</a>, for authentication with Microsoft Azure Active Directory accounts (AAD) and Microsoft Accounts (MSA) using industry standard OAuth2 and OpenID Connect. Basically, this logs you in to Microsoft services when using code.</li>
<li><a href="https://learn.microsoft.com/en-us/graph/overview">Microsoft Graph API</a>, for interacting with cloud-based Microsoft software products (eg Outlook.) Although it’s an API, there is an associated front-end Python package too, called <a href="https://github.com/microsoftgraph/msgraph-sdk-python#readme">Microsoft Graph SDK</a>. There’s also an <a href="https://developer.microsoft.com/en-us/graph/graph-explorer">interactive Graph Explorer tool</a>.</li>
</ul>
<p>Third-parties have built other, simpler-to-use packages on top of these. A notable example is the <a href="https://github.com/vgrem/Office365-REST-Python-Client">Office365-REST-Python-Client</a>. That page has lots of examples but, just to give you a flavour, here’s how to send an email in code:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> office365.graph_client <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GraphClient</span>
<span id="cb7-2"></span>
<span id="cb7-3">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GraphClient(acquire_token_func)</span>
<span id="cb7-4"></span>
<span id="cb7-5">client.me.send_mail(</span>
<span id="cb7-6">    subject<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Meet for lunch?"</span>,</span>
<span id="cb7-7">    body<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The cafeteria is open."</span>,</span>
<span id="cb7-8">    to_recipients<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hungryfriend@microsoft.com"</span>]</span>
<span id="cb7-9">).execute_query()</span></code></pre></div>
<p>There’s support for doing operations with Outlook, Teams, OneDrive, Sharepoint, OneNote, and Planner (a task manager).</p>
<p>Perhaps a couple of examples would give you a sense of how this can be useful.</p>
<p>Imagine you have a RAP that produces a report, as discussed above. Great, you have a report, now what? Now you can use code to do that last step and email it out to stakeholders or put it in a Sharepoint folder.</p>
<p>Another example: like me, you work with your team on a Kanban board where code tasks are assigned to people. You could have a GitHub action set up so that each time a name is assigned to a card/issue on that Kanban, a task is also sent to that person’s Planner app.</p>
<p>One more example: people are always emailing documents to read. As noted in the previous post though, email is a bad way to communicate source information. Instead, you can have a code setup to watch a Sharepoint folder for any new documents dropped into it. When a new document arrives, the people who need to read the document get a notification that it’s there waiting for their review.</p>
<p>If you’re on Google Docs, there’s an <a href="https://developers.google.com/docs/api/reference/rest">API for that too</a>. And there are plenty of other office efficiency code tools not from the big tech firms. Here’s a fairly random selection:</p>
<ul>
<li>how about good quality, person-labelled transcripts of meetings? See this post on <a href="https://den.dev/blog/how-i-automated-podcast-transcription-with-local-ai/">how someone automated their podcast transcription process with local AI</a> (complete with diarization).</li>
<li>rooting out any <a href="https://github.com/butuzov/deadlinks">deadlinks</a></li>
<li>creating <a href="https://github.com/lincolnloop/python-qrcode">QR codes</a></li>
<li><a href="https://github.com/tebelorg/RPA-Python">Automation of generic interactions with your computer</a> (aka robotic process automation)</li>
<li>renaming, sorting, deleting, or moving hundreds of files at once (using tools like <a href="https://realpython.com/python-pathlib/">pathlib</a>, <a href="https://github.com/gorakhargosh/watchdog">watchdog</a>, and <a href="https://docs.python.org/3/library/shutil.html">shutil</a>)</li>
<li>Web-scraping, of course</li>
<li><a href="https://schedule.readthedocs.io/en/stable/">Scheduling tasks</a> to happen while your computer is running</li>
</ul>
<p>A quick example of the latter, scheduling, is:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> schedule</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> morning_task():</span>
<span id="cb8-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Good morning! Running your daily automation task..."</span>)</span>
<span id="cb8-6"></span>
<span id="cb8-7">schedule.every().day.at(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"08:00"</span>).do(morning_task)</span>
<span id="cb8-8"></span>
<span id="cb8-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>:</span>
<span id="cb8-10">    schedule.run_pending()</span>
<span id="cb8-11">    time.sleep(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span></code></pre></div>
<p>There are really incredible possibilities in this space.</p>
</section>
<section id="low-or-no-code-automation" class="level3">
<h3 class="anchored" data-anchor-id="low-or-no-code-automation">Low or no code automation</h3>
<p>There’s a huge barrier to automating with code, which is that most people in most organisations can’t code. Overall, for the reasons listed, code-based automation is to be preferred. However, we should not let the perfect be the enemy of the good and <strong>proprietary low or no code tools can democratise the ability to automate tasks</strong>. The most relevant example of such a tool in the public sector is Microsoft’s <a href="https://www.microsoft.com/en-gb/power-platform/products/power-automate">Power Automate</a>, which is described as “A comprehensive, end-to-end cloud automation platform powered by low code and AI.”</p>
<p>Power Automate is not free, but if your institution uses Microsoft then there’s a chance that you have access to it as part of a bundle. Power Automate’s stand out feature is that you can create automated flows simply by pointing and clicking (and sometimes filling in a few details.) For the automations it covers, it’s extremely convenient. Some examples of what can be automated include:</p>
<ul>
<li>Sending a customised email when a new file is added to a folder on Sharepoint</li>
<li>Scheduling a recurring message in a Teams chat</li>
<li>Saving an email to OneNote</li>
</ul>
<p>There are also ‘connectors’ that provide integrations with popular other services and software, including GitHub, Gmail, Slack, etc.</p>
<p>If you have the relevant Microsoft subscription, you can find example templates and connectors <a href="https://www.microsoft.com/en-us/power-platform/templates">here</a>.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this post, I’ve explored a range of ideas to boost efficiency in public sector analysis and operations. Investing in better technology, embracing open-source software, data sharing, and automating analytical processes has the potential to yield significant productivity improvements. The same goes for implementing reproducible analytical pipelines, maintaining comprehensive technical documentation, versioning models, strategically integrating AI tools, and automating routine office tasks.</p>
<p>These practices are likely to boost productivity by being, in some cases, cheaper. But the likely biggest contribution to productivity is in reducing errors, saving time, enabling more analysis, and increasing agility.</p>


</section>


 ]]></description>
  <category>productivity</category>
  <category>public sector</category>
  <category>work chat</category>
  <category>rap</category>
  <guid>https://www.aeturrell.com/blog/posts/public-sector-analytical-efficiency/</guid>
  <pubDate>Tue, 18 Mar 2025 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/public-sector-analytical-efficiency/automated_stats.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Efficiency in the public sector: communication and co-ordination</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/public-sector-communication-efficiency/</link>
  <description><![CDATA[ 





<p>I’ve been thinking a lot about efficiency in the public sector recently, particularly how we can improve it. In this post, I’ll focus on some ideas for improving communication and co-ordination between public sector workers.</p>
<p>Quick disclaimer: efficiency, in time or money, is not the only important factor. People’s well-being and satisfaction matter too. (It matters in itself but it’s also true that grumpy staff are not going to be well-motivated.) Most of the time there isn’t going to be a trade-off between efficiency and staff well-being as no-one likes wasting time but it’s always worth considering what the pursuit of efficiency in time and money might be costing elsewhere.</p>
<p><img src="https://www.aeturrell.com/blog/posts/public-sector-communication-efficiency/iso_city.webp" class="img-fluid"></p>
<section id="ideas-for-lowering-communication-and-co-ordination-costs" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="ideas-for-lowering-communication-and-co-ordination-costs">Ideas for lowering communication and co-ordination costs</h2>
<section id="publishing-analysis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="publishing-analysis">Publishing analysis</h3>
<p>A major source of inefficiency across the wider public sector is the co-ordination costs that result from having everyone involved in topic X try to keep in touch.<sup>1</sup> Across the whole public sector, there are often too many people working on X to get into a single room at the same time. So people resort to many bilateral conversations. With only <img src="https://latex.codecogs.com/png.latex?N"> people working on X across the whole of the public sector, one individual needs to have <img src="https://latex.codecogs.com/png.latex?N-1"> conversations to keep on top of what’s happening and, in total, if everyone does the same, there are <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BN%5E2-N%7D%7B2%7D"> co-ordination meetings happening. For as few as <img src="https://latex.codecogs.com/png.latex?N=30">, that means 435 meetings! I’m using an extreme case—surely <em>some</em> sub-groups of more than two people will meet. But the point stands that this is not at all efficient.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;In a perfect world, you would have very clean lines of responsibility for different topics. But topics that can be so cleanly separated from any other issue are the exception, if they exist at all.</p></div></div><p>An alternative is for public sector institutions to share as much as possible of their analysis across institutional lines, preferably by publishing it openly. You might think sharing it just within the public sector makes more sense but there are legal, technological, and co-ordination barriers to do this—again, you might end up having to do 100s of bilateral sharing agreements.</p>
<p>Of course there will be analysis that cannot be shared. Some questions, and definitely some answers, are inherently sensitive or disclosive. But not as many as most people in the public sector assume (I assert), and for those that aren’t, the benefits of release are substantial.</p>
<p>By the way, by ‘sharing analysis’, I don’t just mean sharing the end report, I mean sharing the data and code too.<sup>2</sup> This gets all the benefits that will be familiar to people who know about free and open source code, and data sharing<sup>3</sup>. Let me give you a specific example: over the last few years there have been a number of errors in UK official statistics, on <a href="https://www.ft.com/content/61679d49-2b87-45ef-8fa2-1b76e393aed4">trade</a> and on <a href="https://www.ft.com/content/95b425c1-7f09-3c14-b423-42da8fa30bfe">productivity</a>, and these are just two examples from the top of my head. I have this dream that the code that is used to create national statistics could be open-sourced, improving transparency, getting more eyes on fixing any errors, and allowing countries to adopt the best practices of the most innovation national statistical offices far more quickly. So the biggest benefit of all of this sharing is that you can co-opt others into improving your analysis! That’s very efficient!</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;One organisation, GitLab, has even <a href="https://about.gitlab.com/blog/our-handbook-is-open-source-heres-why/">open sourced</a> how they run their organisation.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;I’ll write more about the benefits of data sharing in another post.</p></div></div><p>So, where possible, I believe it makes sense to publish analysis for anyone to find. Then everyone who needs it can find it, benefit from it, and avoid duplicating it. This isn’t just a public good: the people who are able to find it and avoid duplicating it may well be people from your own institution in the future—I’ve <a href="../../../blog/posts/managing-public-sector-knowledge/managing-public-sector-knowledge.html">written before</a> about how the public sector is not good at maintaining the stock of knowledge, but making that knowledge accessible to the most powerful search engines in the world means it is far less likely to disappear or be inefficiently duplicated.</p>
<p>This share-what-you-can approach eliminates the need for lots of communication and co-ordination that would otherwise be costly.</p>
</section>
<section id="asynchronous-working" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="asynchronous-working">Asynchronous working</h3>
<p>As well as disseminating analysis and code widely, you can reduce within-org communication costs by opting for asynchronous ways of working. Those who have worked in organisations that span time zones will be familiar with this idea. GitLab has lots of <a href="https://handbook.gitlab.com/handbook/company/culture/all-remote/asynchronous/">good content on the idea of asynchronous working</a> as they are a 100% remote and international company.</p>
<p>Here’s an excerpt from their Handbook, itself a quote by <a href="https://codahale.com/">Coda Hale</a>:</p>
<div class="page-columns page-full"><blockquote class="blockquote">
<p>A significant source of failure demand<sup>4</sup> for meetings and status updates is the desire of organizational leaders to keep abreast of who’s doing what. This situational awareness is indeed important, but trying to maintain it by calling meetings, messaging people on Slack, and catching people on the hallways is a significant systemic drag on organizational productivity.</p>
<p>A better model for staying informed of developments as the organization scales is for groups to publish status updates as part of the regular cadence of their work. Leaders can asynchronously read these updates and, should the need arise, initiate additional, synchronous conversation to ask questions, provide feedback, etc.</p>
<p>Synchronous meetings should be reserved for low-latency collaboration on complex issues; likewise, collaboration should be reserved for synchronous meetings.</p>
</blockquote><div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Failure demand is the demand on a system or organisation that arises not from delivering work, but from failings of the system and excess co-ordination costs.</p></div></div></div>
<p>The fundamental idea here is that co-ordinating to be in the same meeting at the same time is more difficult, and may create bottlenecks, that are not present when communication is asynchronous. Another aspect is that there’s a “default to action” rather than a default to delay until a conversation can happen.</p>
<p>Asynchronous communication appeals to me because of my observation that the public sector has more meetings than perhaps would be ideal—and that as the ‘cost’ of convening large groups of people decreased due to the availability of virtual meetings in the pandemic, we all opted to ‘buy’ more of them (without an accompanying change in the volume of meetings the work actually requires).</p>
<p>As the GitLab Handbook notes, there are other benefits to asynchronous working:</p>
<ul>
<li>it is better for people who work part time or have unusual working hours</li>
<li>it tends to push people toward greater transparency, which can help junior staff feel more involved</li>
<li>it tends to push people to write down key decisions and actions so that a log of institutional knowledge is created (useful in general, but especially great for onboarding new staff.)</li>
</ul>
<p>So how can you actually get some of the productivity benefits of asynchronicity? A big part is mindset and (again, this line courtesy of the GitLab Handbook), the easiest way to shift into an asynchronous mindset is to ask: “How would I deliver this message, present this work, or move this project forward right now if no one else on my team or organisation were awake?” Here are some more specific ideas for implementing asynchronous working:</p>
<ul>
<li><strong>Default to sharing information</strong>, eg by using the most permissive classification available.</li>
<li><strong>Use documentation obsessively</strong>—for code, for decisions, for processes, and for actions. And make sure there is a process by which that documentation is prevented from becoming stale.<sup>5</sup> Documenting why something didn’t happen is as important as documenting why it did because it helps others understand why certain decisions were made. In practice, documenting obsessively means avoiding putting key decisions or information in emails—anything important should be in documents that are findable by default. If you’re in any kind of managerial position, you’ll know that your bandwidth can be entirely absorbed simply by your email inbox—leaving no time for deeper thought. Amazon has an interesting ban on Powerpoint decks in favour of written memos that goes in this direction; there’s a <a href="../../../blog/posts/managing-public-sector-knowledge/managing-public-sector-knowledge.html">post that mentions Amazon’s approach here</a>. As a concrete example, in my own teams, I have had some success managing code-based work via a <a href="https://en.wikipedia.org/wiki/Kanban_board">Kanban board</a> (we use <a href="https://docs.github.com/en/issues/planning-and-tracking-with-projects">GitHub projects</a> but there are lots of alternatives available.) This provides asynchronicity, transparency, it means that team meetings aren’t just a round table of updates, and (using GitHub’s <a href="https://docs.github.com/en/graphql">GraphQL API</a>) it also allows for automatic compilation of reports on what kinds of projects we’re undertaking.</li>
<li><strong>Have meetings only when they are needed</strong>. This means avoiding scheduling them regularly and holding ad hoc ones only when it would unblock progress faster than written communication. Good reasons for meetings might include:
<ul>
<li>Meetings with external parties</li>
<li>First-time meetings for team members who have not previously worked together</li>
<li>‘One-way door’ decisions (eg when stakes are high and decisions are difficult to reverse)</li>
<li>Complex project initialisations and planning (eg defining the workplan for the next quarter, scoping a major project, etc.)</li>
<li>Sensitive topics (e.g.&nbsp;discussing personal issues, career, performance, giving difficult feedback, etc.)</li>
<li>Supporting and unblocking direct reports</li>
</ul></li>
<li><strong>Meetings should have an agenda</strong>.</li>
<li><strong>Empower people to make ‘two-way door’ decisions</strong>. Most decisions are easy to reverse and not sensitive. In these cases, people should go ahead and make them without approval or needing to have a meeting.</li>
<li>Ensure there is a clear <strong>single source of truth</strong> for every important piece of information. If you have to ask someone else which of two similar pieces of information is relevant, that’s not very efficient.</li>
<li><strong>Ensure that information is easily accessible and can be searched</strong>. I wrote more about that last point <a href="../../../blog/posts/managing-public-sector-knowledge/managing-public-sector-knowledge.html">here</a> but now there’s a new kid on the block for helping to interrogate the combined stock of knowledge of an institution: retrieval augmented generation (RAG). With RAG, you can get the general benefits of a large language model focused on a specific set of documents that you choose. Even better, the LLM can cite the documents it is sourcing its answers from. This seems like a fantastic way to make the considerable stock of knowledge in most institutions more accessible.</li>
<li>When meetings are necessary, record them, or make a transcript, or better than both <strong>create a concise but complete summary of meetings in which it is clear who attended and what decisions were made, and ensure that the information is available for anyone to find afterwards</strong>. Most public sector institutions are using Microsoft Teams, and there are Teams tools that can help with this.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;More on code documentation in a subsequent post.</p></div></div></section>
<section id="have-someone-own-the-trade-off" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="have-someone-own-the-trade-off">Have someone own the trade-off</h3>
<p>This one is more about the structure of your organisation, but it’s a change that saves a ton of potentially fractious communication too.</p>
<p>It’s probably best to illustrate the idea with a hypothetical example. Let’s say that there is a person in an organisation who is responsible for IT, including software, hardware, and technology security (call them Bob.) And let’s say there’s someone else who is responsible for high quality, efficient, and impactful analysis across the same organisation (call them Alice.) Alice and Bob are far removed from each other—perhaps they only have a single manager in common who is the head of the entire institution or the permanent secretary.</p>
<p>Now Bob is incentivised to minimise costs and maximise security, because he holds the budget for software and hardware, and if there’s an IT security incident, you can bet Bob is going to be in the firing line. Alice, meanwhile, is incentivised to get things done, and likely has substantial risk appetite in order to get important things done. If there’s a major crisis of some sort looming, Alice isn’t going to be much pleased that her staff are unable to access key government websites because of zealous internet security settings, and if she doesn’t get that critical analysis out in time, <em>she’s</em> going to be in the firing line.</p>
<p>Hopefully you can see that Alice and Bob have wildly different incentives here and their communications might, very naturally, end up being fractious. We can’t blame Bob or Alice for this—they’re both doing their jobs, the jobs they have been given. But at an institutional level, the structure has created a natural clash. Co-ordination and communication will be far less good than they could be because Alice is always straining at the limits of what Bob allows her to do, and Bob is always trying to reign Alice in.</p>
<p>The solution here is to have someone who owns this productivity-security trade-off<sup>6</sup>. There are a few options for making this happen:</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;As an aside, I’m sceptical there’s as much of a productivity-security trade-off as most people think. If you have too high security, people start to find risky work arounds, which isn’t very secure. If you have very lax security and processes, mistakes can go unnoticed (including analytical mistakes). But there are definitely times when the needs of “getting things done” and “avoiding any risk” clash.</p></div></div><ul>
<li>have someone who doesn’t sit so far up the organisation own the trade-off. Maybe it could be that Alice and Bob report to the same person. This helps because, if the person invested with the trade-off decision is too high up in the organisation, then that decision is never going to be top of their list—they will simply always have bigger fish to fry. Whereas if the senior person’s role is explicitly to get that trade-off right, and they’re close to both Bob and Alice, they’re going to be well-placed to make good decisions.</li>
<li>merge Alice and Bob’s jobs. Alice-Bob now owns risk tolerance on IT security, hardware and software choices, and productivity of analysis. Alice-Bob can make the trade-off directly.</li>
<li>Bob’s job disappears, and Bob’s staff become Alice’s staff, but Alice now has more diverse teams that include technology experts as well as analysts. There’s a professional network for technology people, but they are embedded in business areas. Alice owns the trade-off and can make the decision based on what her mixed teams tell her. Some US institutions use this model.</li>
</ul>
<p>Stepping away from the Alice and Bob hypothetical, you can imagine other places where this same dynamic plays out. The choice of where to site a new office? The choice of how to refurbish an office? How complex the HR policies are for bringing new people in? In every case, if your goal is productivity, you need someone to own the trade-off with the other factors at stake.</p>
</section>
<section id="project-management" class="level3">
<h3 class="anchored" data-anchor-id="project-management">Project management</h3>
<p>I already mentioned Kanban boards in the previous section but there’s a bunch of other ideas that can help reduce communication and co-ordination costs within the nitty gritty of individual projects. One is the Amazon ‘working backwards’ method, which you can find more about in <a href="../../../blog/posts/data-science-with-impact/index.html#working-backwards">this post on data science with impact</a>. The same post also talks about the benefits of incremental delivery.</p>
<p>On communication and co-ordination specifically, though, another Amazon-favoured trick is worth mentioning: “disagree and commit”. The basic idea is that individuals can, and should, openly disagree with a decision that is on the table but—once the decision is definitively made—everyone should commit to implementing it. This allows people to speak up and challenge what they don’t agree with, without causing a fear that they will be obstructive. And it also helps avoid what’s known as the ‘consensus trap’, where the feeling of needing to reach consensus turns into a lack of progress. Both of these can be issues in the public sector or, indeed, any large organisation.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>It seems like there’s plenty of room to improve communication and co-ordination in the public sector. I’ve shared a few suggestions focused on four areas: making your analysis public by default avoids costly bilateral co-ordination, gets you free help from others, and helps avoid duplication; working asynchronously avoids bottlenecks, empowers staff, lowers onboarding costs, and promotes transparency; thinking carefully about who owns key trade-offs can prevent a lot of inefficient back-and-forth, and ensure that everyone is pulling in the same direction; and battle-tested project management practices can promote delivery and action. Got better ideas? Let me know!</p>


</section>


 ]]></description>
  <category>productivity</category>
  <category>public sector</category>
  <category>work chat</category>
  <category>management</category>
  <guid>https://www.aeturrell.com/blog/posts/public-sector-communication-efficiency/</guid>
  <pubDate>Mon, 17 Mar 2025 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/public-sector-communication-efficiency/iso_city.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>The data validation landscape in 2025</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/the-data-validation-landscape-in-2025/</link>
  <description><![CDATA[ 





<p>What’s going on in the world of data validation? For those of you who don’t know, data validation is the process of checking data quality in an automated or semi-automated way—for example, checking datatypes, checking the number of missing values, and detecting whether there are anomalous numbers. It doesn’t have to be rows in a dataframe though, it could be for validating API input or form submissions. The user provides rules for what should be flagged as an issue, for example saying that all values in a particular column should be within a certain number range. And, depending on the package, data that fail the validation either result in an outright error or in a data validation report that determines (either automatically or manually) what should happen next.</p>
<p>Note: while most of what I say in this post will be relevant in general to data validation tools, I’ll be making a few observations of how this might be useful or not for the public sector specifically. And this is not going to be a comprehensive list—it’s just going to feature some of the more widely-used packages.</p>
<section id="why-is-data-validation-useful" class="level2">
<h2 class="anchored" data-anchor-id="why-is-data-validation-useful">Why is data validation useful?</h2>
<p>In my experience, there are broadly two types of analytical work that public sector institutions undertake. One is ad hoc analysis, the other is regular production of statistics. In the latter case, data validation is extremely helpful because you want to know whether there are problems with, say, the latest data you’ve ingested <em>before</em> it goes to senior leaders or, even worse, is published externally. But even for ad hoc data analysis, if it’s on a standard dataset that is ingested, say, every month, you probably do want to have data validation checks so you’re not caught out by an anomaly that you misinterpret as a real effect.</p>
<p>Ultimately, if you want the analysis you’re doing to be accurate, then data validation is a great way to efficiently remove some of the risks of making a mistake.</p>
</section>
<section id="data-validation-tooling-landscape" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="data-validation-tooling-landscape">Data validation tooling landscape</h2>
<section id="great-expectations" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="great-expectations">Great Expectations</h3>
<p>I think the first data validation tool I came across was <a href="https://greatexpectations.io/">Great Expectations</a>. The landscape has evolved and now there are many other tools; meanwhile Great Expectations has developed into a heavy-duty production-grade data validation tool. The website pushes you quite hard in the direction of their hosted solution, but there is an open source package underlying it all that anyone can use.<sup>1</sup> Perhaps because it has become production-grade, it now seems a little more difficult to configure and get going with than some of the other options on this list, and perhaps less well-suited to teams where not everyone has advanced data science skill (this is common in the public sector; eg teams composed of economists with one data scientist.)</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;For example, you have to click through a few menus on their website to find their original open source package as they are understandably keen to get you to use their hosted GX Cloud solution.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;Hopefully one could rig up an action to send an alert on a tool that is more likely to be in use in the public sector too.</p></div></div><p>It’s well worth checking out in any case, though, as it has a number of advanced features that other packages on this list don’t have (at least not without significant further effort). For example, if validations fail, you can use nifty integrations to do things like send a message on Slack.<sup>2</sup></p>
<p>If you do use the open source element of Great Expectations, it works a bit like this:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import required modules from GX library.</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> great_expectations <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> gx</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create Data Context.</span></span>
<span id="cb1-7">context <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gx.get_context()</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import sample data into Pandas DataFrame.</span></span>
<span id="cb1-10">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(</span>
<span id="cb1-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/great-expectations/gx_tutorials/main/data/yellow_tripdata_sample_2019-01.csv"</span></span>
<span id="cb1-12">)</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Connect to data.</span></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create Data Source, Data Asset, Batch Definition, and Batch.</span></span>
<span id="cb1-16">data_source <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> context.data_sources.add_pandas(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pandas"</span>)</span>
<span id="cb1-17">data_asset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data_source.add_dataframe_asset(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pd dataframe asset"</span>)</span>
<span id="cb1-18"></span>
<span id="cb1-19">batch_definition <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data_asset.add_batch_definition_whole_dataframe(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"batch definition"</span>)</span>
<span id="cb1-20">batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> batch_definition.get_batch(batch_parameters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dataframe"</span>: df})</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create Expectation.</span></span>
<span id="cb1-23">expectation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gx.expectations.ExpectColumnValuesToBeBetween(</span>
<span id="cb1-24">    column<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"passenger_count"</span>, min_value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, max_value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span>
<span id="cb1-25">)</span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Validate Batch using Expectation.</span></span>
<span id="cb1-28">validation_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> batch.validate(expectation)</span></code></pre></div>
<p>The returned Validation Result object is a json representation of the results. There are numerous options for data sources including, importantly, databases. And there are numerous expectations too—and an ability to define custom ones.</p>
<p>I mentioned the actions that can be triggered when a validation fails. Here’s a couple and how they can be used:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">action_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This Action sends a Slack Notification if an Expectation fails.</span></span>
<span id="cb2-3">    SlackNotificationAction(</span>
<span id="cb2-4">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"send_slack_notification_on_failed_expectations"</span>,</span>
<span id="cb2-5">        slack_token<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"$</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{validation_notification_slack_webhook}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb2-6">        slack_channel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"$</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{validation_notification_slack_channel}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb2-7">        notify_on<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"failure"</span>,</span>
<span id="cb2-8">        show_failed_expectations<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb2-9">    ),</span>
<span id="cb2-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This Action updates the Data Docs static website with the Validation</span></span>
<span id="cb2-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   Results after the Checkpoint is run.</span></span>
<span id="cb2-12">    UpdateDataDocsAction(</span>
<span id="cb2-13">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"update_all_data_docs"</span>,</span>
<span id="cb2-14">    ),</span>
<span id="cb2-15">]</span>
<span id="cb2-16"></span>
<span id="cb2-17">checkpoint_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"my_checkpoint"</span></span>
<span id="cb2-18">checkpoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gx.Checkpoint(</span>
<span id="cb2-19">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>checkpoint_name,</span>
<span id="cb2-20">    validation_definitions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>validation_definitions,</span>
<span id="cb2-21">    actions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>action_list,</span>
<span id="cb2-22">    result_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"result_format"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"COMPLETE"</span>},</span>
<span id="cb2-23">)</span>
<span id="cb2-24">context.checkpoints.add(checkpoint)</span></code></pre></div>
</section>
<section id="pointblank" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="pointblank">Pointblank</h3>
<p><a href="https://posit-dev.github.io/pointblank/">Pointblank</a> is the new kid on the block, and another recent Python creation from the org previously known as RStudio, now Posit. Posit has always created really high quality R packages (including one of the same name for R) and it’s wonderful to see them now focusing their attention on creating equally high quality Python packages. The syntax is somewhat reminiscent of Great Expectations, which shows you just how influential that original package has been.</p>
<p>Here’s an example of using Pointblank with a <strong>Polars</strong> dataframe (it also works with <strong>pandas</strong>):</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pointblank <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pb</span>
<span id="cb3-2"></span>
<span id="cb3-3">validation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb3-4">    pb.Validate(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pb.load_dataset(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"small_table"</span>)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use Validate() to start</span></span>
<span id="cb3-5">    .col_vals_gt(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"d"</span>, value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># STEP 1      |</span></span>
<span id="cb3-6">    .col_vals_le(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>, value<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># STEP 2      | &lt;-- Build up a validation plan</span></span>
<span id="cb3-7">    .col_exists(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date_time"</span>]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># STEPS 3 &amp; 4 |</span></span>
<span id="cb3-8">    .interrogate() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This will execute all validation steps and collect intel</span></span>
<span id="cb3-9">)</span>
<span id="cb3-10"></span>
<span id="cb3-11">validation</span></code></pre></div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/the-data-validation-landscape-in-2025/pointblank-tabular-report.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Example output from Pointblank</figcaption>
</figure>
</div>
<p>From the documentation:</p>
<blockquote class="blockquote">
<p>The rows in the validation report table correspond to each of the validation steps. One of the key concepts is that validation steps can be broken down into atomic test cases (test units), where each of these test units is given either of pass/fail status based on the validation constraints. You’ll see these tallied up in the reporting table (in the UNITS, PASS, and FAIL columns).</p>
</blockquote>
<p>Again, a wide range of data sources are supported, including Polars, Pandas, DuckDB tables, MySQL tables, PostgreSQL tables, SQLite tables, and Parquet.</p>
<p>It’s early days for this package—it only had its first release in 2024, compared to (I think) 2017 for Great Expectations, and some functionality you’d expect isn’t quite there yet, but it looks super user-friendly so far and perhaps geared a bit more to the individual institutional user.</p>
<p>One important caveat with Pointblank is that it doesn’t have the action triggers for follow-ups to failed validations. So you may validate your data, but then you either need to code in a next action yourself, or take action manually.</p>
</section>
<section id="pandera" class="level3">
<h3 class="anchored" data-anchor-id="pandera">Pandera</h3>
<p><a href="https://pandera.readthedocs.io/">Pandera</a> also follows an API similar to that of Great Expectations! Here’s an example:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># data to validate</span></span>
<span id="cb4-2">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({</span>
<span id="cb4-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"column1"</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>],</span>
<span id="cb4-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"column2"</span>: [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.3</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.4</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.9</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">20.4</span>],</span>
<span id="cb4-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"column3"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value_1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value_2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value_3"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value_2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value_1"</span>],</span>
<span id="cb4-6">})</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># define schema</span></span>
<span id="cb4-9">schema <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pa.DataFrameSchema({</span>
<span id="cb4-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"column1"</span>: pa.Column(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, checks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pa.Check.le(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)),</span>
<span id="cb4-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"column2"</span>: pa.Column(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, checks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pa.Check.lt(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.2</span>)),</span>
<span id="cb4-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"column3"</span>: pa.Column(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, checks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb4-13">        pa.Check.str_startswith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value_"</span>),</span>
<span id="cb4-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># define custom checks as functions that take a series as input and</span></span>
<span id="cb4-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># outputs a boolean or boolean Series</span></span>
<span id="cb4-16">        pa.Check(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> s: s.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_"</span>, expand<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb4-17">    ]),</span>
<span id="cb4-18">})</span>
<span id="cb4-19"></span>
<span id="cb4-20">validated_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> schema(df)</span>
<span id="cb4-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(validated_df)</span></code></pre></div>
<pre class="text"><code>   column1  column2  column3
0        1     -1.3  value_1
1        4     -1.4  value_2
2        0     -2.9  value_3
3       10    -10.1  value_2
4        9    -20.4  value_1</code></pre>
<p>If the validation doesn’t go through, an error is thrown (in this case it passed through.)</p>
<p>One of the nice features of Pandera is that you can combine it not just with column-level validation questions but also with statistical hypothesis testing too. It might seem a bit niche but I can well imagine cases where this could pop up. Here’s an example,</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandera <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pa</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pandera <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Column, DataFrameSchema, Check, Hypothesis</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stats</span>
<span id="cb6-7"></span>
<span id="cb6-8">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb6-9">    pd.DataFrame({</span>
<span id="cb6-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"height_in_feet"</span>: [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>],</span>
<span id="cb6-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sex"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"M"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"M"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>]</span>
<span id="cb6-12">    })</span>
<span id="cb6-13">)</span>
<span id="cb6-14"></span>
<span id="cb6-15">schema <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataFrameSchema({</span>
<span id="cb6-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"height_in_feet"</span>: Column(</span>
<span id="cb6-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, [</span>
<span id="cb6-18">            Hypothesis.two_sample_ttest(</span>
<span id="cb6-19">                sample1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"M"</span>,</span>
<span id="cb6-20">                sample2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>,</span>
<span id="cb6-21">                groupby<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sex"</span>,</span>
<span id="cb6-22">                relationship<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"greater_than"</span>,</span>
<span id="cb6-23">                alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>,</span>
<span id="cb6-24">                equal_var<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb6-25">    ]),</span>
<span id="cb6-26">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sex"</span>: Column(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>)</span>
<span id="cb6-27">})</span>
<span id="cb6-28"></span>
<span id="cb6-29"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb6-30">    schema.validate(df)</span>
<span id="cb6-31"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> pa.errors.SchemaError <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> exc:</span>
<span id="cb6-32">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(exc)</span></code></pre></div>
<pre class="text"><code>Column 'height_in_feet' failed series or dataframe validator 0: &lt;Check two_sample_ttest: failed two sample ttest between 'M' and 'F'&gt;</code></pre>
<p>Just as with the other libraries we’ve seen so far, a wide range of data sources are supported, including (despite the name!) Polars, geopandas, Pyspark, dark, and modin dataframes.</p>
</section>
<section id="pydantic" class="level3">
<h3 class="anchored" data-anchor-id="pydantic">Pydantic</h3>
<p><a href="https://docs.pydantic.dev/">Pydantic</a> is a bit different from the previous examples we’ve seen as the fundamental unit to which it applies validation is not a dataframe, but a dictionary (eg from ingesting a JSON file). It’s more in the business of <em>schema validation</em> than dataframe validation. So this is less useful out-of-the-box for dataframes but more flexible and can be used for non-tabular data. The clever bit is that you define your schema via a class, and then you get a lot of desirable behaviour ‘for free’ that comes from this. On the website, it lists the UK Home Office among its users. It’s fair to say that Pydantic is production-grade too.</p>
<p>It’s easiest to illustrate how it works with an example:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datetime <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, PositiveInt</span>
<span id="cb8-4"></span>
<span id="cb8-5"></span>
<span id="cb8-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> User(BaseModel):</span>
<span id="cb8-7">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>  </span>
<span id="cb8-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'John Doe'</span>  </span>
<span id="cb8-9">    signup_ts: datetime <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>  </span>
<span id="cb8-10">    tastes: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, PositiveInt]  </span>
<span id="cb8-11"></span>
<span id="cb8-12"></span>
<span id="cb8-13">external_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb8-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'id'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>,</span>
<span id="cb8-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'signup_ts'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2019-06-01 12:22'</span>,  </span>
<span id="cb8-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tastes'</span>: {</span>
<span id="cb8-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'wine'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>,</span>
<span id="cb8-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">b'cheese'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,</span>
<span id="cb8-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cabbage'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'1'</span>,</span>
<span id="cb8-20">    },</span>
<span id="cb8-21">}</span>
<span id="cb8-22"></span>
<span id="cb8-23">user <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> User(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>external_data)  </span>
<span id="cb8-24"></span>
<span id="cb8-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(user.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span>)  </span>
<span id="cb8-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#&gt; 123</span></span>
<span id="cb8-27"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(user.model_dump())  </span>
<span id="cb8-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    'id': 123,</span></span>
<span id="cb8-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    'name': 'John Doe',</span></span>
<span id="cb8-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    'signup_ts': datetime.datetime(2019, 6, 1, 12, 22),</span></span>
<span id="cb8-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    'tastes': {'wine': 9, 'cheese': 7, 'cabbage': 1},</span></span>
<span id="cb8-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
<p>If validation fails, Pydantic will raise an error with a breakdown of what was wrong.</p>
<p>As I mentioned, a strength of Pydantic is that you can validate arbitrarily complex objects. So here, for example, is a a fruit class that has an attribute called <code>bazam</code> that is a dictionary that maps strings into lists of tuples of ints, bools, and floats.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> annotated_types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Gt</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb9-4"></span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Fruit(BaseModel):</span>
<span id="cb9-7">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>  </span>
<span id="cb9-8">    color: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>]  </span>
<span id="cb9-9">    weight: Annotated[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, Gt(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)]  </span>
<span id="cb9-10">    bazam: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>]]]  </span></code></pre></div>
<p>You’ll also notice that there’s a validation check for whether the weight is greater than zero <code>Gt(0)</code>.</p>
<p>Pydantic integrates with some other Python tools such as the extremely excellent <a href="https://fastapi.tiangolo.com/">FastAPI</a> for building APIs. But, unlike the other tools we’ve seen, it doesn’t integrate with dataframe and data source tools without further work by the user.</p>
</section>
<section id="cerberus" class="level3">
<h3 class="anchored" data-anchor-id="cerberus">Cerberus</h3>
<p>From the Cerberus docs:</p>
<blockquote class="blockquote">
<p>Cerberus provides powerful yet simple and lightweight data validation functionality out of the box and is designed to be easily extensible, allowing for custom validation.</p>
</blockquote>
<p>In many ways, Cerberus has a similar feel to Pydantic though, as far as I can tell, it’s a bit less fully featured and it returns True or False for validations rather than passing or throwing an error. Instead of using base classes and Python’s typing functionality, it defines schemas using text-based dictionaries (though these can be extended and customised).</p>
<p>It’s easiest to illustrate via an example:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">schema <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'type'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'string'</span>}}</span>
<span id="cb10-2">v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Validator(schema)</span>
<span id="cb10-3">document <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'john doe'</span>}</span>
<span id="cb10-4">v.validate(document)</span></code></pre></div>
<pre class="text"><code>True</code></pre>
</section>
<section id="jsonschema" class="level3">
<h3 class="anchored" data-anchor-id="jsonschema">jsonschema</h3>
<p>This package, <a href="https://github.com/python-jsonschema/jsonschema">jsonschema</a>, is similar to Cerberus covered above and is specifically focused on validating JSON. Here’s an example:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> jsonschema <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> validate</span>
<span id="cb12-2"></span>
<span id="cb12-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A sample schema, like what we'd get from json.load()</span></span>
<span id="cb12-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> schema <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb12-5">...     <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>,</span>
<span id="cb12-6">...     <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"properties"</span> : {</span>
<span id="cb12-7">...         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"price"</span> : {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"number"</span>},</span>
<span id="cb12-8">...         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span> : {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span>},</span>
<span id="cb12-9">...     },</span>
<span id="cb12-10">... }</span>
<span id="cb12-11"></span>
<span id="cb12-12"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If no exception is raised by validate(), the instance is valid.</span></span>
<span id="cb12-13"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> validate(instance<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Eggs"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"price"</span> : <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">34.99</span>}, schema<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>schema)</span>
<span id="cb12-14"></span>
<span id="cb12-15"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> validate(</span>
<span id="cb12-16">...     instance<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Eggs"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"price"</span> : <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Invalid"</span>}, schema<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>schema,</span>
<span id="cb12-17">... )                                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># doctest: +IGNORE_EXCEPTION_DETAIL</span></span>
<span id="cb12-18">Traceback (most recent call last):</span>
<span id="cb12-19">    ...</span>
<span id="cb12-20">ValidationError: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Invalid'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> of <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'number'</span></span></code></pre></div>
</section>
</section>
<section id="so-what-should-you-use-for-data-validation-in-the-public-sector" class="level2">
<h2 class="anchored" data-anchor-id="so-what-should-you-use-for-data-validation-in-the-public-sector">So what should you use for data validation in the public sector?</h2>
<p>That’s up to you, and will depend on your use case. For now, if you are validating a dataframe or database, and you work in a mixed team, and you’re <em>not</em> going to deploy to a production system, I think that <a href="https://pandera.readthedocs.io/"><strong>pandera</strong></a> is a strong choice but keep an eye on <a href="https://posit-dev.github.io/pointblank/"><strong>pointblank</strong></a> to see where it goes. If you’re working in a serious production environment and doing wholesale automation, you might find <a href="https://greatexpectations.io/"><strong>great expectations</strong></a> better, especially because of the built-in functionality that triggers actions. And, finally, if you’re working with validating user input, from an API or form, then <a href="https://docs.pydantic.dev/"><strong>pydantic</strong></a> is probably the strongest choice.</p>


</section>


 ]]></description>
  <category>data science</category>
  <category>data</category>
  <category>data engineering</category>
  <category>public sector</category>
  <guid>https://www.aeturrell.com/blog/posts/the-data-validation-landscape-in-2025/</guid>
  <pubDate>Wed, 05 Mar 2025 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/the-data-validation-landscape-in-2025/pointblank-tabular-report.png" medium="image" type="image/png" height="65" width="144"/>
</item>
<item>
  <title>Ultra-modern Python Cookiecutters</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/ultra-modern-python-cookiecutters/</link>
  <description><![CDATA[ 





<p>In January 2020, <a href="https://cjolowicz.github.io/">Claudio Jolowicz</a> published an extremely influential post on <a href="https://cjolowicz.github.io/posts/hypermodern-python-01-setup/">Hypermodern Python</a>. It was extremely influential on me, anyway, because it introduced me to a number of tools that I now consider essential to creating solid, high-quality and low-maintenance Python packages. As part of the article, a <a href="https://github.com/cookiecutter/cookiecutter">cookiecutter</a> template was released to help people create new packages with all of these exciting features.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Cookiecutter templates allow people to fill in a few details in the command line, like project name and Python version, to both copy a repo and populate it with their choices. It’s a simple trick that saves a lot of time in creating a basic project structure. The <a href="https://github.com/cookiecutter/cookiecutter">cookiecutter</a> Python package is used to populate the templates.</p></div></div><p>But a lot has changed since 2020, and the brilliant hypermodern python cookiecutter repo hasn’t been updated in two years. There are at least three big changes (we’ll come to these) since then that mean it’s well worth revisiting what a modern (or ultramodern) Python package cookiecutter should look like… and I’ve tried to capture them.</p>
<p>So, in this post, I’m introducing two new, ultramodern repos: a <a href="https://github.com/aeturrell/cookiecutter-python-package">Cookiecutter Python Package</a> and a <a href="https://github.com/aeturrell/cookiecutter-research-project/tree/main">Cookiecutter Research Project</a>. Neither of them are battle tested, far from it, but they do deliver the core goods they promise.</p>
<div id="fig-logos" class="quarto-layout-panel page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-logos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-logos" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-package" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-package-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.aeturrell.com/code/logos/cookiecutter_logo_package.svg" class="img-fluid figure-img" data-ref-parent="fig-logos">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-package-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Package
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-logos" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-research" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-research-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.aeturrell.com/code/logos/cookiecutter_logo_research.svg" class="img-fluid figure-img" data-ref-parent="fig-logos">
</div>
<figcaption class="quarto-float-caption-margin quarto-subfloat-caption quarto-subfloat-fig" id="fig-research-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Research
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-logos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Logos for these dev tools
</figcaption>
</figure>
</div>
<p>The <a href="https://github.com/aeturrell/cookiecutter-python-package">cookiecutter python package</a> is designed to help people (<a href="../../../code/index.html">including me!</a>) build open source software. The <a href="https://github.com/aeturrell/cookiecutter-research-project/tree/main">cookiecutter research project</a> is designed to help people (<a href="../../../research/index.html">especially me!</a>) spend more research time thinking.</p>
<section id="ultramodern-tooling" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="ultramodern-tooling">Ultramodern tooling</h2>
<p>Both of these new cookiecutters take advantage of major developments in Python tooling:</p>
<ul>
<li><p>Astral’s extremely fast linter and formatter, <a href="https://astral.sh/ruff">Ruff</a>, has burst onto the scene since 2020. And in tjhis repo, it replaces Black (which was in the hypermodern setup) as a linter and formatter, and isort for sorting imports.</p></li>
<li><p>The arrival of another tool from Astral, <a href="https://docs.astral.sh/uv/">uv</a>, which replaces a whole host of tools (including Poetry, which was part of the hypermodern setup). At a minimum, this is a blazing fast package manager and drop-in replacement for pip, but it also:</p>
<ul>
<li>resolves dependency conflicts</li>
<li>produces a lockfile</li>
<li>automatically creates virtual environments per-project, per-folder</li>
<li>can spin up an environment just to run a single script<sup>2</sup></li>
<li>builds packages</li>
<li>can install some versions of Python for some systems</li>
<li>creates a valid <code>pyproject.toml</code> file</li>
<li>can install and run tools globally with <code>uv tool install</code> and <code>uv tool run</code>.</li>
</ul></li>
<li><p>The release of <a href="https://quarto.org/">Quarto</a>, which, among many other things, can build websites, and <a href="https://machow.github.io/quartodoc/get-started/overview.html">Quartodoc</a>, which can produce automatic reference documentation based on a code base in concert with Quarto. Quarto means you can write your documentation in a Jupyter Notebook, importing your actual package so that the code and code outputs are in lockstep with the codebase. The addition of Quartodoc means that the API reference on your docs is also <em>exactly</em> what is in your code base.<sup>3</sup> Quarto requires a standalone installation, while Quartdoc is a Python package. You can find more about using Quarto in anger for research over at <a href="https://aeturrell.github.io/coding-for-economists">Coding for Economists</a>.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Yes, that’s how fast it is!</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Note that Quartodoc is only relevant for the Cookiecutter Python Package.</p></div></div></section>
<section id="cookiecutter-python-package" class="level2">
<h2 class="anchored" data-anchor-id="cookiecutter-python-package">Cookiecutter Python Package</h2>
<p>So what are the key features of the new ultramodern cookiecutter? As of the time of writing, it packs the following:</p>
<ul>
<li><a href="https://nox.thea.codes/en/stable/">Nox</a> for isolated testing</li>
<li>Modern Python dependency management with <a href="https://astral.sh/blog/uv">uv</a></li>
<li><a href="https://docs.pytest.org/en/7.4.x/">pytest</a> for testing</li>
<li>Code formatting with <a href="https://docs.astral.sh/ruff/">ruff</a> (including formatting and import sorting)</li>
<li><a href="https://github.com/Erotemic/xdoctest">xdoctest</a> to check that examples of use in docstrings work as intended</li>
<li><a href="https://github.com/agronholm/typeguard">typeguard</a> for run-time type checking</li>
<li>Git pre-commit hooks for code quality:
<ul>
<li><a href="https://docs.astral.sh/ruff/">Ruff</a> lint/format/sort imports</li>
<li>check for added large files
<ul>
<li>check TOML</li>
<li>check YAML</li>
<li>end of file fixer</li>
<li>trailing whitespace trimmer</li>
<li><a href="https://github.com/kynan/nbstripout">nbstripout</a> for ensuring notebook outputs are not committed. (Notebook outputs are included when Quarto pushes the docs website to GitHub pages, however, as you’d expect.)</li>
<li><a href="https://github.com/jsh9/pydoclint">pydoclint</a> for checking docstrings agree with function definitions</li>
</ul></li>
</ul></li>
<li>Continuous Integration/Continuous Deployment with <a href="https://github.com/features/actions">GitHub Actions</a>
<ul>
<li>covers multiple versions of Python, and all three major operating systems</li>
<li>tests with <a href="https://docs.pytest.org/en">pytest</a> + <a href="https://nox.thea.codes/en/stable/">Nox</a>
<ul>
<li>Test cover with <a href="https://coverage.readthedocs.io/">Coverage.py</a></li>
<li>Automatic <a href="https://github.com/actions/labeler">release labeler</a></li>
<li>Automatic publishing to <a href="https://pypi.org/">PyPI</a></li>
<li>Dynamic docs build and deploy using <a href="https://quarto.org/">Quarto</a> for a docs site, <a href="https://machow.github.io/quartodoc">Quartodoc</a> for automatic API documentation, and <a href="https://pages.github.com/">GitHub Pages</a> for deployment.</li>
</ul></li>
</ul></li>
</ul>
<p>For some of this, you’ll need to get API keys. But all of it is free if your repo is public and you have a paid GitHub account.</p>
<p>In the choice of what’s included, I’ve tried to strike a balance between not bloating the features and providing a serious foundation for a strong package. I took the decision <em>not</em> to include the following, for the following reasons:</p>
<ul>
<li>an automatic updating utility, like <a href="https://github.com/dependabot">dependabot</a>; mostly because I’m not sure if there’s one that works well with uv yet.</li>
<li>a static type checker, like <a href="https://github.com/python/mypy">mypy</a>, because it seemed to be of marginal value-add in other projects and its strictness can be daunting. There was a recent announcement that Astral is working on a static type checker code-named <a href="https://github.com/astral-sh/ruff/pulls?q=is%3Apr+is%3Aopen+label%3Ared-knot">red-knot</a>, and I’m inclined to see what that’s like given the quality of their other tools.</li>
</ul>
<p>Both of these features could be added in future.</p>
</section>
<section id="cookiecutter-research-project" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="cookiecutter-research-project">Cookiecutter Research Project</h2>
<p>The second new dev tool is a <a href="https://github.com/aeturrell/cookiecutter-research-project/tree/main">Cookiecutter Research Project</a> that is Python-oriented and flexible. It has a number of useful features designed to make starting, and maintaining, a research project less of a slog:</p>
<ul>
<li>a well-designed folder structure with folders for data at different stages, models, notebooks, code, and outputs.</li>
<li>sensible defaults on which of these folders are ignored by git (via a <code>.gitignore</code> file). For example, code, references, paper, and slides folders are under version control. But data, logs, outputs, and so, folders are not.</li>
<li>a .env file for storing secrets—researchers are increasingly using cloud computer to do research (see <a href="../../../blog/posts/visual-studio-code-in-the-cloud/index.html">this post</a> for doing this with VS Code and Google Cloud.)</li>
<li>pre-commit with Ruff (linting, formating, import sorting), nbstripout, end of file fixer, large file check, trailing whitespace fixer, and toml/yaml checks.</li>
<li>uv for managing the Python environment, and making it reproducible via the lockfile.</li>
<li>a Makefile with commands for installing the environment (for reproducibility), and for compiling the paper, and the slides.</li>
<li>paper and slides based on Quarto—more detail on these below.</li>
<li>a project config TOML file where global project settings can be stored. For example, you could have all your chart configurations here, or the hyperparameter settings.</li>
</ul>
<p>One of the big innovations is the use of Quarto for the paper and the slides (and for the references that get picked up in both.) <a href="https://quarto.org/">Quarto</a> is a document, slide, and website publishing tool. It uses an extended form of markdown, supports LaTeX equations, and can execute and insert code into the final document.</p>
<p>One small advantage of Quarto over using LaTeX directly is the use of citation style language files. References are in a <code>.bib</code> file as normal for a LaTeX document with a bibliography, but the style of citations is defined in a <code>.csl</code> (csl = citation style language) file, which is clearer and more flexible than other methods (at least in my view.) You can find a very long list of citation styles, including for most major journals, <a href="https://github.com/citation-style-language/styles">here</a>.</p>
<p>Another advantage, and hold your horses, because it’s a big one, is that you can <em>automatically update charts, tables, and </em>even text** when your results change. People have long <a href="https://aeturrell.github.io/coding-for-economists/auto-research-outputs.html">pointed their LaTeX document at their results folder</a> so that when the results change, their paper updates. Some people have done it for slides too, if they’re created with Beamer. But now the <em>text</em> in the document can be updated too.</p>
<p>Quarto can support execution of code <em>within</em> the document itself. So you can have a code block that reads in your results and assigns them to the variables, say, <code>number</code> and <code>big_pen</code>. Then the syntax below shows how to insert these numbers directly into the text.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Report</span></span>
<span id="cb1-2"></span>
<span id="cb1-3">We find that the heaviest penguin, out of a total of <span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">`python f"{number}"`</span> penguins, has a mass of <span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">`python f"{big_pen:.2f}"`</span> kilograms.</span></code></pre></div>
<p>Images and equations can be included using the standard markdown syntax, and LaTeX tables can be included in PDF outputs simply by reading and printing a LaTeX table <code>.tex</code> file with the <code>#| output: asis</code> option in a code block. You can see an example in the <code>paper.qmd</code> file in the <a href="https://github.com/aeturrell/cookiecutter-research-project/tree/main">repo</a>. That paper is set up to compile into something that looks like the default arXiv style. It actually compiles by creating a <code>.tex</code> file as an intermediary and there’s a Quarto config option to save that, should you need too (eg arXiv prefers you to submit a <code>.tex</code> over a PDF.)</p>
<p>Currently, the slides use Reveal.js to output a <code>.html</code> file rather than a PDF so while the code/text and charts work in the same way, the command to include LaTeX is slightly different—and I’ve only tested it for equations. The syntax is: <code>{{&lt; include path/to/equation.tex &gt;}}</code>. Anything that has a HTML output should work too, and that’s true of most regression table packages (eg <a href="https://github.com/py-econometrics/pyfixest">Pyfixest</a>.) If you prefer Powerpoint<sup>4</sup>, you can export to that with Quarto too, though I haven’t tested it with typical research outputs.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Some people might. No-one I’ve ever met. Or heard about. But it could happen. Probably.</p></div></div><p>There are a couple of features one could argue for that I have <em>not</em> implemented for the research cookiecutter:</p>
<ul>
<li>a way to re-run all of the analysis. This is quite bespoke to your project so it was hard to include anything meaningful in the template. There is a Makefile in there, so you could extend that to include a part that executes the analysis—you can see an example along these lines <a href="https://github.com/aeturrell/example-reproducible-research">here</a>.<sup>5</sup></li>
<li>a Dockerfile to run your project reliably across systems. It’s possible this will be added in future. Again, you can find an example research project that uses uv and a Dockerfile <a href="https://github.com/aeturrell/example-reproducible-research">here</a>.</li>
<li>a way to automatically generate a DAG (directed acyclic graph) of all the operations that go into producing the outputs. I find this very useful to understand research projects (even if they’re my own.) The <a href="https://github.com/aeturrell/example-reproducible-research">example I keep mentioning</a> uses <code>make2graph</code> to do this if you want to see what I mean and why it might be useful.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;For more on making your research project a reproducible analytical pipeline, check out <a href="https://aeturrell.github.io/coding-for-economists/wrkflow-rap.html">this page</a> on Coding for Economists.</p></div></div><p>Imagine how much time you will save if new results can be incorporated into your paper and slides simply by recompiling! For me, this is a huge win for the amount of time actually spent on the research question vs doing tedious updating.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>While these templates are both still wet behind the ears, they could be useful to people today—which is why I’m releasing them now. Feedback and pull requests are welcome. Finally, if you use either of them to produce your own content, let me know by raising an issue. I’ll add your work to the relevant repo—showing that these cookiecutters can be part of a recipe for success!</p>


</section>


 ]]></description>
  <category>code</category>
  <category>data science</category>
  <category>research</category>
  <guid>https://www.aeturrell.com/blog/posts/ultra-modern-python-cookiecutters/</guid>
  <pubDate>Sun, 23 Feb 2025 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/code/logos/cookiecutter_logo_package.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>TIL: How to resume sessions on virtual machines</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/til-resuming-vm-sessions/</link>
  <description><![CDATA[ 





<p>Today I learned how to resume sessions on virtual machines while using Visual Studio Code remote.</p>
<p><a href="https://code.visualstudio.com/docs/remote/remote-overview">Visual Studio Code remote</a> is incredible for SSH-ing into remote virtual machines. But sometimes you start off a long-running process in a shell on the remote machine and your connection is interrupted before it can finish; then, when you resume the connection, you’ve lost the progress you made through your code.</p>
<p>But today I learned that you can start off <em>persistent</em> shell processes using a command line tool called <strong>screen</strong> that comes pre-installed in many Linux distributions (eg Ubuntu).</p>
<p>To use it (assuming it is pre-installed), once you’ve opened the folder you’re working in on the remote via SSH from VS Code, simply type</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">screen</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-S</span> YOUR-SHELL-NAME</span></code></pre></div>
<p>to initiate a shell with screen name <code>YOUR-SHELL-NAME</code> that will persist.</p>
<p>Once you reconnect to the virtual machine run <code>screen -ls</code> to see existing running shells and <code>screen -r YOUR-SHELL-NAME</code> to reconnect to the running session! Super useful.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/til-resuming-vm-sessions/dall_e_haynes_style_screens.webp" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">DALL-E rendition of resuming a session</figcaption>
</figure>
</div>



 ]]></description>
  <category>code</category>
  <category>cloud</category>
  <category>TIL</category>
  <guid>https://www.aeturrell.com/blog/posts/til-resuming-vm-sessions/</guid>
  <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/til-resuming-vm-sessions/dall_e_haynes_style_screens.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Converting handwritten, maths-heavy lecture notes to markdown using large language models</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/converting-lecture-notes/</link>
  <description><![CDATA[ 





<p>It would be nice to have digital copies of all of those old handwritten lecture notes that I so lovingly put together. Some of them might even still be useful, though I have to admit I don’t have tons of opportunities to use quantum field theory these days.</p>
<p>Recent Large Language Models (LLMs) have stunning vision capabilities and so it occurred to me that they might be able to convert even old notes into beautifully formatted markdown and equations.</p>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<p>I’ll try out two recent models from OpenAI and Google respectively,</p>
<ul>
<li>chatgpt-4o-latest</li>
<li>gemini-exp-1206</li>
</ul>
<p>The latter has a generous free tier, the former cost $0.03 to run one image.</p>
</section>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<p>The Python APIs for both of these couldn’t really be simpler—you can find the example <a href="https://github.com/aeturrell/digitise-lecture-notes">in this repo</a>, but, to give you a sense, here is the complete code to use Google’s Gemini model:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> google.generativeai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> genai</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PIL.Image</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb1-7"></span>
<span id="cb1-8">load_dotenv()</span>
<span id="cb1-9">genai.configure(api_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"API_KEY_GOOGLE"</span>))</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Path to image</span></span>
<span id="cb1-12">image_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input/test_lecture_note_photo.jpg"</span>)</span>
<span id="cb1-13">sample_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PIL.Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(image_path)</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Choose a Gemini model.</span></span>
<span id="cb1-16">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> genai.GenerativeModel(model_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gemini-exp-1206"</span>)</span>
<span id="cb1-17"></span>
<span id="cb1-18">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The photograph shows some lecture notes. Please transcribe the text in this photograph to markdown, using latex for equations where needed."</span></span>
<span id="cb1-19"></span>
<span id="cb1-20">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate_content([prompt, sample_file])</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output/output_example_gemini.md"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"w"</span>).write(response.text)</span></code></pre></div>
</section>
<section id="results" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>This is the input file. Yes, I took a bad photograph. In some ways, that’s quite helpful, as it gives a sense of how these models do in a difficult situation. If you were doing this at scale, you’d probably want to find a consistent way of taking high quality photographs, however.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/converting-lecture-notes/test_lecture_note.webp" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="margin-caption">Example input of handwritten lecture note</figcaption>
</figure>
</div>
<p>And here are the outputs:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/converting-lecture-notes/lecture_output_gpt4o.webp" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="margin-caption">Output capture from GPT-4o</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/converting-lecture-notes/lecture_output_gemini.webp" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="margin-caption">Output capture from gemini-exp-1206</figcaption>
</figure>
</div>
<p>The GPT-4o model cost around $0.03, while the experimental Gemini model is free up to so many tokens per day. They both do a really great job given the quality of the input and you can see that this would probably work at scale with some better photographs.<sup>1</sup> They each make a couple of mistakes, and Gemini seems more keen on beautiful latex equations than it does on markdown formatting, at least relative to GPT-4o. Bear in mind, there was close to zero effort expended on designing the prompt here too—so it’s likely that this could be improved too.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Garbage in, garbage out.</p></div></div><p>All in all, this looks completely feasible. And there’s some speculation (h/t: <a href="https://simonwillison.net/">Simon Willison</a>) that vision models that can run <em>locally</em> (Llama 3.2, Qwen-VL, and Pixtral) would be able to handle it too.</p>


</section>


 ]]></description>
  <category>llm</category>
  <category>python</category>
  <category>data science</category>
  <guid>https://www.aeturrell.com/blog/posts/converting-lecture-notes/</guid>
  <pubDate>Sat, 28 Dec 2024 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/converting-lecture-notes/lecture_output_gemini.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>The false economy of bad IT</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/bad-it/</link>
  <description><![CDATA[ 





<p>Many of us will have experienced bad hardware or software at work. Applications that freeze when you try and do something. A lag when typing. Some programmes ceasing to work before crashing completely. Maybe it’s another kind of performance that makes you want to throw your laptop out of the window: the battery dies after you’ve only been to a couple of meetings, or the text on the screen screen seems teeny tiny if you’re not plugged into a monitor. All of this is very annoying. But, worst of all, it’s a waste of your most precious resource: your time.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/bad-it/dall_e_laptop_window.webp" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="margin-caption">DALL-E generated image of someone expressing their frustration with their laptop, and window(s)</figcaption>
</figure>
</div>
<p>Employers should care about this because it’s losing them money, particularly if they have staff who use computers for most of their work or their staff are relatively well-paid<sup>1</sup>, or both.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;For the sake of making this concrete, let’s take “well-paid” to mean above the current UK median of £35k.</p></div></div><p>Let’s do a back-of-the-envelope calculation to show why bad IT makes no economic sense. The mid-range hardware used in many organisations looks, at best, like a 1TB SSD, 16GB RAM, i7 touch laptop or touch surface running Windows. As examples of these sorts of machines, a Lenovo ThinkPad model <a href="https://www.lenovo.com/gb/en/p/laptops/thinkpad/thinkpadp/thinkpad-p14s-gen-4-14-inch-intel/21hf000uuk">21HF000UUK</a> and a <a href="https://www.microsoft.com/en-gb/d/surface-pro-9/93vkd8np4fvk?activetab=pivot:overviewtab">Microsoft Surface Pro 9</a> with those specifications are a good fit. The laptop has a 14-inch screen; the surface 13 inches. A quick check shows that these come in at £1600 and £2200 respectively at the time of writing. In my experience, the ThinkPad has a battery life of, at best, 2—3 hours; I’m not sure about the Surface.</p>
<p>Now let’s take a high-end laptop: a <a href="https://www.apple.com/uk/shop/buy-mac/macbook-pro/14-inch-space-grey-apple-m3-chip-with-8-core-cpu-and-10-core-gpu-8gb-memory-512gb">14-inch M3-chip MacBook Pro</a> that can run small large language models locally (!) and has 24GB of RAM plus a 1TB SSD. It’s the same size of hard drive but has 8 extra GB of RAM, which is enough to make a substantial difference to the performance (but, also, <a href="https://www.howtogeek.com/865066/its-okay-to-buy-a-mac-with-only-8-gb-ram/">each GB of RAM is more performant</a> in a Mac.) This is all-important because many of the glitches, pauses, and slowness of less good laptops come down to insufficient RAM. It isn’t simple to compare the processors of these machines, but the Mac is very approximately 30% faster. Without going back and forth on claims about battery life, Mac laptops occupy four of the top six laptops with the best battery life as <a href="https://www.tomsguide.com/best-picks/best-laptops-for-battery-life">listed in Toms Guide</a> and personal experience suggests they go for far longer than 2—3 hours. Our high-end laptop comes in at £2300, an extra £100 or £700 relative to the mid-range ones. Now Macs do not have touchscreens but my observation is that extremely few people use the touch feature on a laptop. My other observation is that high-end laptops have problems once in a blue moon—there’s a crash once every 3 months or so. This is so rare that I take it to be zero.</p>
<p>Let’s say the cheaper hardware has three incidents a day where something glitches, crashes, or goes slow enough to pause a workflow and, on average, this causes three minutes of lost time during each occurrence. This seems entirely reasonable because most people will start doing something else, perhaps making a cup of tea, if their laptop becomes unresponsive for any length of time. Now, imagine the average professional costs a business £60.0k a year (with pension, National Insurance, etc, etc)<sup>2</sup> and works 7.5 hours a day, so 51.0p per working minute. This makes the cost of that lost time around £1200.0 per year, compared to spending only £700 to £100 more to get the higher end laptop.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;To give a sense of what this is as a headline salary, a base salary of £50k and pension of 7% plus National Insurance of £5644 takes the total cost to the employer to £59k.</p></div></div><p>Switching to a higher-end laptop pays off by at least £500.0 just in the first year. For the laptop, it’s worth going high-end for <em>any</em> all-in salary cost above £35.0k (remember, the UK median headline salary cost is £35k). The benefits are likely bigger when looking at a longer period: as far as I’ve been able to tell, mid-range laptops usually last around three years while higher end laptops last more like five years–with <a href="https://www.businessinsider.com/guides/tech/how-long-do-laptops-last">some reports suggesting</a> Apple laptops last longer than this. So the “payoff” from switching might be a few times this.</p>
<p>There are a bunch of other factors here that are hard to estimate. Staff might be more motivated by better IT, and this is hard to quantify. But if staff surveys consistently rate technology as poor, the benefits may be significant. There could be better staff retention, which is worth a lot. But better IT might also discourage some bad behaviour: if people have to deal with a laptop battery that doesn’t last long enough for two meetings in a row, they will either make no notes or start using personal devices to take notes. If people are faced with a laptop or surface that’s too fiddly to use on a train, they simply won’t work when in transit.</p>
<p>On the other hand, there is likely to be a cost to maintaining two or more separate operating systems in an enterprise. Apple laptops use MacOS, a different operating system to the one often installed on ThinkPads, Surfaces, and similar devices, which is Windows. But most organisations have already crossed the Rubicon on this with their use of iPhones for mobiles, and Linux for critical systems. It’s also really poor practice to hitch your organisation to a single provider of software and hardware. You’ll be backed into a corner when negotiating contracts, and may not be able to easily change things up if the software or hardware quality degrades. (It’s notable that frontier tech firms <a href="https://www.quora.com/What-operating-system-do-the-Google-employees-use-How-much-freedom-do-they-have-with-respect-to-an-OS-usage">allow staff to choose</a> between Windows, MacOS, and Linux.) I don’t know how to estimate the cost of maintaining two or more operating systems in an organisation but there are serious downsides to having just one.</p>
<p>I’m not suggesting that organisations should just buy Apple laptops–this is about efficiency, and the best prescription for that is to <strong>allow staff to choose what works best for them</strong>. The apparently economically optimal choice won’t make sense for everyone: some staff might want to stick with mid-range laptops because they get along better with the operating system or laptop design, and that’s okay. By allowing staff to choose what they get on best with you keep them happy, and you make your organisation more productive. The bottom line is that everybody wins when staff have the option to use a higher-end laptop—except, maybe, glaziers.</p>




 ]]></description>
  <category>work chat</category>
  <category>productivity</category>
  <category>public sector</category>
  <guid>https://www.aeturrell.com/blog/posts/bad-it/</guid>
  <pubDate>Mon, 16 Sep 2024 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/bad-it/dall_e_laptop_window.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>TIL: how to create and work with a MySQL database on Azure</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/til-sql-database-azure/</link>
  <description><![CDATA[ 





<p>In this TIL, I find out how to create a new <a href="https://dev.mysql.com/">MySQL database</a> on Microsoft Azure. This is a place to store structured, tabular data. Note that the instructions below assume you are using a bash-like terminal, for example <a href="https://ohmyz.sh/">zsh</a>, rather than <a href="https://learn.microsoft.com/en-us/powershell/">Powershell</a>.</p>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">Prerequisites</h2>
<p>You’ll need to sign up for a Microsoft Azure account for this, and create a “resource group”. You’ll also need the Azure Command Line Interface (CLI), which you can find information <a href="https://learn.microsoft.com/en-us/cli/azure/">on here</a>. (Alternatively, you can do this through the <a href="https://portal.azure.com/#home">Azure Portal</a>, but it’s often useful to have the reproducible commands.)</p>
<p>It’s also helpful to understand the lingo and how different bits of the cloud-based SQL setup relate to one another:</p>
<ul>
<li>there is the resource group, which many Azure services could live under</li>
<li>there is a server, which co-ordinates resources</li>
<li>there are individual databases, which live on particular services</li>
</ul>
<p>These three are hierarchical: a database lives on a server that sits under a particular resource group.</p>
<p>You may be wondering why MySQL rather than another type of SQL database? The pricing information is quite difficult to parse, but for hobby projects, it looks like a MySQL database is a lot cheaper than an Azure SQL (MSSQL) database. A basic MySQL database (burstable, b1ms model) is around US$13.00 per month whereas a provisioned Azure SQL database is hundreds of dollars a month. The latter option has a more complex set of options too, though, so there’s more to make a mistake with. So we’ll be going with the open source MySQL in this case.</p>
</section>
<section id="instructions" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="instructions">Instructions</h2>
<section id="creating-a-mysql-server" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-mysql-server">Creating a MySQL server</h3>
<p>First set and load your configs. You’ll need to decide on a login and password for your SQL server.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">resourcegroup</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span></span>
<span id="cb1-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">server</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span></span>
<span id="cb1-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">login</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span></span>
<span id="cb1-4"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">password</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span></span>
<span id="cb1-5"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">location</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># eg "uksouth"</span></span></code></pre></div>
<p>Then to create the server (with conservative cost settings), it’s</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> mysql flexible-server create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--location</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$location</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--resource-group</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$resourcegroup</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$server</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--admin-user</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$login</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--admin-password</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$password</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--sku-name</span> Standard_B1ms <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--tier</span> Burstable <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--public-access</span> Enabled <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--version</span> 5.7 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--high-availability</span> Disabled <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--storage-auto-grow</span> Disabled</span></code></pre></div>
</section>
<section id="configure-permissions-to-use-the-sql-server" class="level3">
<h3 class="anchored" data-anchor-id="configure-permissions-to-use-the-sql-server">Configure permissions to use the SQL server</h3>
<p>The default options are cautious on two sets of permissions, the certificate and the IP addresses that are allowed to connect. We need to open these up for your computer.</p>
<p>Go on to Azure portal page for the newly created server and click “configure networking”. Then enable connections from your specific IP address through the firewall (“add current client IP address”). On the same page, there’s an option to download the SSL certificate. Do this, and put it in a secrets folder that is not under version control.</p>
</section>
<section id="connect-to-the-sql-server-using-the-command-line" class="level3">
<h3 class="anchored" data-anchor-id="connect-to-the-sql-server-using-the-command-line">Connect to the SQL server using the command line</h3>
<p>Let’s check that it worked! Assuming you saved the SSL certificate as <code>sql_cert.crt.pem</code> in the <em>same directory in which you are working</em>, you should be able to run the following on the command line:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mysql</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-h</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$server</span>.mysql.database.azure.com <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-u</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$login</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-p</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--ssl-ca=sql_cert.crt.pem"</span></span></code></pre></div>
<p>If you saved the certificate in <code>secrets/</code>, change the path in the above command appropriately.</p>
<p>Note that you may need to regenerate the <code>.pem</code> file from time to time.</p>
<p>Note also that if you are accessing this resource through a VPN or other managed network, this is where you may have difficulties. To circumvent these, you can use a normal internet connection or connect from a virtual machine.</p>
</section>
<section id="working-with-the-sql-database-from-python" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="working-with-the-sql-database-from-python">Working with the SQL database from Python</h3>
<p>Python has a number of great tools for working with SQL databases. For this, we’ll look at just two: <a href="https://dev.mysql.com/doc/connector-python/en/">MySQL Connector</a> and the wonderful <a href="https://ibis-project.org/">Ibis project</a>, which translates across a wide number of data analysis backends.</p>
<p>Just as we did before, we need to plug in our credentials. The syntax is slightly different from bash and it’s recommended to use a secrets manager like <a href="https://github.com/theskumar/python-dotenv">python-dotenv</a> to manage these and ensure they do not get mistakenly committed to version control.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">username <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&gt;</span></span>
<span id="cb4-2">password <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&gt;</span></span>
<span id="cb4-3">hostname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&lt;&gt;.mysql.database.azure.com"</span></span></code></pre></div>
<section id="connecting-and-creating-a-database-with-mysql-connector" class="level4">
<h4 class="anchored" data-anchor-id="connecting-and-creating-a-database-with-mysql-connector">Connecting and creating a database with MySQL Connector</h4>
<p>Next, we start up the connection.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">mydb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mysql.connector.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(</span>
<span id="cb5-2">  host<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hostname,</span>
<span id="cb5-3">  user<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>username,</span>
<span id="cb5-4">  password<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>password,</span>
<span id="cb5-5">  ssl_ca<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"secrets/sql_cert.crt.pem"</span>,</span>
<span id="cb5-6">)</span></code></pre></div>
<p>where it’s assumed that the certificate is in a folder called secrets.</p>
<p>If running this works, you won’t see an error message or a confirmation message, but you can check all is as it should be by running:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mydb)</span></code></pre></div>
<p>which should result in something like:</p>
<pre class="text"><code>&lt;mysql.connector.connection_cext.CMySQLConnection object at 0x3213r4g90&gt;</code></pre>
<p>Now it’s not very exciting to have a SQL server with no databases in. So, next, we’re going to create a database.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">create_db_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CREATE DATABASE online_movie_rating"</span></span>
<span id="cb8-2">mycursor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mydb.cursor()</span>
<span id="cb8-3">mycursor.execute(create_db_query)</span></code></pre></div>
<p>If you then run</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">mycursor.execute(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Show databases;"</span>)</span>
<span id="cb9-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> db <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> mycursor:</span>
<span id="cb9-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(db)</span></code></pre></div>
<p>you’ll get a list of databases that should include <code>online_movie_rating</code>.</p>
<p>But an empty database is no fun—let’s populate it. First, the table we wish to create:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">create_movies_table_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb10-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">CREATE TABLE movies(</span></span>
<span id="cb10-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    id INT AUTO_INCREMENT PRIMARY KEY,</span></span>
<span id="cb10-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    title VARCHAR(100),</span></span>
<span id="cb10-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    release_year YEAR(4),</span></span>
<span id="cb10-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    genre VARCHAR(100),</span></span>
<span id="cb10-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    collection_in_mil INT</span></span>
<span id="cb10-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">)</span></span>
<span id="cb10-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
<p>And then the execution of that create table command:</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">mydb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mysql.connector.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(</span>
<span id="cb11-2">  host<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hostname,</span>
<span id="cb11-3">  user<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>username,</span>
<span id="cb11-4">  password<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>password,</span>
<span id="cb11-5">  database<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"online_movie_rating"</span>,</span>
<span id="cb11-6">  ssl_ca<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"secrets/sql_cert.crt.pem"</span>,</span>
<span id="cb11-7">)</span>
<span id="cb11-8">mycursor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mydb.cursor()</span>
<span id="cb11-9">mycursor.execute(create_movies_table_query)</span>
<span id="cb11-10">mydb.commit()</span></code></pre></div>
<p>Note the difference with the earlier command—this one has a <code>database=</code> keyword argument in it.</p>
<p>With the table created, we can also populate it with some data:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">insert_movies_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb12-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">INSERT INTO movies (title, release_year, genre, collection_in_mil)</span></span>
<span id="cb12-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">VALUES</span></span>
<span id="cb12-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Forrest Gump", 1994, "Drama", 330.2),</span></span>
<span id="cb12-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("3 Idiots", 2009, "Drama", 2.4),</span></span>
<span id="cb12-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Eternal Sunshine of the Spotless Mind", 2004, "Drama", 34.5),</span></span>
<span id="cb12-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Good Will Hunting", 1997, "Drama", 138.1),</span></span>
<span id="cb12-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Skyfall", 2012, "Action", 304.6),</span></span>
<span id="cb12-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Gladiator", 2000, "Action", 188.7),</span></span>
<span id="cb12-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Black", 2005, "Drama", 3.0),</span></span>
<span id="cb12-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Titanic", 1997, "Romance", 659.2),</span></span>
<span id="cb12-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("The Shawshank Redemption", 1994, "Drama",28.4),</span></span>
<span id="cb12-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Udaan", 2010, "Drama", 1.5),</span></span>
<span id="cb12-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Home Alone", 1990, "Comedy", 286.9),</span></span>
<span id="cb12-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Casablanca", 1942, "Romance", 1.0),</span></span>
<span id="cb12-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Avengers: Endgame", 2019, "Action", 858.8),</span></span>
<span id="cb12-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Night of the Living Dead", 1968, "Horror", 2.5),</span></span>
<span id="cb12-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("The Godfather", 1972, "Crime", 135.6),</span></span>
<span id="cb12-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Haider", 2014, "Action", 4.2),</span></span>
<span id="cb12-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Inception", 2010, "Adventure", 293.7),</span></span>
<span id="cb12-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Evil", 2003, "Horror", 1.3),</span></span>
<span id="cb12-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Toy Story 4", 2019, "Animation", 434.9),</span></span>
<span id="cb12-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Air Force One", 1997, "Drama", 138.1),</span></span>
<span id="cb12-24"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("The Dark Knight", 2008, "Action",535.4),</span></span>
<span id="cb12-25"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Bhaag Milkha Bhaag", 2013, "Sport", 4.1),</span></span>
<span id="cb12-26"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("The Lion King", 1994, "Animation", 423.6),</span></span>
<span id="cb12-27"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Pulp Fiction", 1994, "Crime", 108.8),</span></span>
<span id="cb12-28"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Kai Po Che", 2013, "Sport", 6.0),</span></span>
<span id="cb12-29"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Beasts of No Nation", 2015, "War", 1.4),</span></span>
<span id="cb12-30"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Andadhun", 2018, "Thriller", 2.9),</span></span>
<span id="cb12-31"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("The Silence of the Lambs", 1991, "Crime", 68.2),</span></span>
<span id="cb12-32"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Deadpool", 2016, "Action", 363.6),</span></span>
<span id="cb12-33"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    ("Drishyam", 2015, "Mystery", 3.0)</span></span>
<span id="cb12-34"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb12-35">mycursor.execute(insert_movies_query)</span>
<span id="cb12-36">mydb.commit()</span></code></pre></div>
<p>Let’s see if we can retrieve some of this:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">select_movies_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SELECT * FROM movies LIMIT 5"</span></span>
<span id="cb13-2">mycursor.execute(select_movies_query)</span>
<span id="cb13-3">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mycursor.fetchall()</span>
<span id="cb13-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> result:</span>
<span id="cb13-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(row)</span></code></pre></div>
<pre class="text"><code>(1, 'Forrest Gump', 1994, 'Drama', 330)
(2, '3 Idiots', 2009, 'Drama', 2)
(3, 'Eternal Sunshine of the Spotless Mind', 2004, 'Drama', 35)
(4, 'Good Will Hunting', 1997, 'Drama', 138)
(5, 'Skyfall', 2012, 'Action', 305)</code></pre>
<p>Finally, to close the connection, use <code>mydb.close()</code>.</p>
</section>
<section id="using-ibis-to-work-with-a-cloud-based-sql-database" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="using-ibis-to-work-with-a-cloud-based-sql-database">Using Ibis to work with a cloud-based SQL database</h4>
<p>The <a href="https://ibis-project.org/">Ibis project</a> makes working with a ton of different back-end data tools easy by making the syntax consistent. Examples are: MySQL, BigQuery, DuckDB, pandas, MSSQL, and much, much more!</p>
<p>Once you’ve imported <strong>Ibis</strong> (<code>import ibis</code>), you may find it more fun and useful to use it in interactive mode, which looks more like how <strong>pandas</strong> works:</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">ibis.options.interactive <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span></code></pre></div>
<p>To see some data, we need to create a connection:</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">con <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ibis.mysql.<span class="ex" style="color: null;
background-color: null;
font-style: inherit;">connect</span>(</span>
<span id="cb16-2">    user<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>username,</span>
<span id="cb16-3">    password<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>password,</span>
<span id="cb16-4">    host<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hostname,</span>
<span id="cb16-5">    port<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3306</span>,</span>
<span id="cb16-6">    database<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"online_movie_rating"</span>,</span>
<span id="cb16-7">    ssl_ca<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sql/sql_cert.crt.pem"</span>,</span>
<span id="cb16-8">)</span></code></pre></div>
<p>And to grab our “movies” table again, but as a <strong>pandas</strong> dataframe:</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> con.table(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"movies"</span>)</span>
<span id="cb17-2">t.head().to_pandas()</span></code></pre></div>
<table class="caption-top table">
<colgroup>
<col style="width: 3%">
<col style="width: 4%">
<col style="width: 44%">
<col style="width: 16%">
<col style="width: 9%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>id</th>
<th>title</th>
<th>release_year</th>
<th>genre</th>
<th>collection_in_mil</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1</td>
<td>Forrest Gump</td>
<td>1994</td>
<td>Drama</td>
<td>330</td>
</tr>
<tr class="even">
<td>1</td>
<td>2</td>
<td>3 Idiots</td>
<td>2009</td>
<td>Drama</td>
<td>2</td>
</tr>
<tr class="odd">
<td>2</td>
<td>3</td>
<td>Eternal Sunshine of the Spotless Mind</td>
<td>2004</td>
<td>Drama</td>
<td>35</td>
</tr>
<tr class="even">
<td>3</td>
<td>4</td>
<td>Good Will Hunting</td>
<td>1997</td>
<td>Drama</td>
<td>138</td>
</tr>
<tr class="odd">
<td>4</td>
<td>5</td>
<td>Skyfall</td>
<td>2012</td>
<td>Action</td>
<td>305</td>
</tr>
</tbody>
</table>
<p>Ibis is great to explore data. It has fully fledged <strong>pandas</strong>-style <em>and</em> SQL-style APIs. So you can do:</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">t.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">filter</span>(t.release_year<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1996</span>)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/til-sql-database-azure/ibis_query_result.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Returned result from filter using Ibis</figcaption>
</figure>
</div>
<p>But you can also get this as SQL:</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">ibis.to_sql(t.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">filter</span>(t.release_year<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1996</span>))</span></code></pre></div>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb20-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">SELECT</span></span>
<span id="cb20-2">  t0.<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">id</span>,</span>
<span id="cb20-3">  t0.title,</span>
<span id="cb20-4">  t0.release_year,</span>
<span id="cb20-5">  t0.genre,</span>
<span id="cb20-6">  t0.collection_in_mil</span>
<span id="cb20-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> movies <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">AS</span> t0</span>
<span id="cb20-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WHERE</span></span>
<span id="cb20-9">  t0.release_year <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1996</span></span></code></pre></div>
<p>It’s a really powerful downstream analysis tool.</p>
<p>And that’s it! Most other SQL commands are as you’d expect and can be looked up in the MySQL documentation.</p>


</section>
</section>
</section>

 ]]></description>
  <category>code</category>
  <category>cloud</category>
  <guid>https://www.aeturrell.com/blog/posts/til-sql-database-azure/</guid>
  <pubDate>Tue, 23 Apr 2024 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/til-sql-database-azure/ibis_query_result.png" medium="image" type="image/png" height="51" width="144"/>
</item>
<item>
  <title>TIL: how to create and work with remote blob storage on Azure</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/til-blob-storage-azure/</link>
  <description><![CDATA[ 





<p>In this TIL, I find out how to create a new blob storage account on Microsoft Azure. This is a place to store unstructured data of any kind (as opposed to, say, a SQL database).</p>
<p>Note that the instructions below assume you are using a bash-like terminal, for example <a href="https://ohmyz.sh/">zsh</a>, rather than <a href="https://learn.microsoft.com/en-us/powershell/">Powershell</a>.</p>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">Prerequisites</h2>
<p>You’ll need to sign up for a Microsoft Azure account for this, and create a “resource group”. You’ll also need the Azure Command Line Interface (CLI), which you can find information <a href="https://learn.microsoft.com/en-us/cli/azure/">on here</a>. (Alternatively, you can do this through the <a href="https://portal.azure.com/#home">Azure Portal</a>, but it’s often useful to have the reproducible commands.)</p>
<p>It’s also helpful to understand the lingo Azure uses for storage.</p>
<ul>
<li>storage accounts are the high level service</li>
<li>“storage containers” are specific data-holding entities that contain blob storage, that is data of any shape and size</li>
</ul>
</section>
<section id="instructions" class="level2">
<h2 class="anchored" data-anchor-id="instructions">Instructions</h2>
<section id="creating-a-storage-account-with-the-command-line-interface" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-storage-account-with-the-command-line-interface">Creating a storage account with the command line interface</h3>
<p>First set and load your configs. Note that the storage account name must be between 3 and 24 characters in length and use numbers and lower-case letters only.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">storagename</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span></span>
<span id="cb1-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">resourcegroup</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span></span>
<span id="cb1-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">location</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># eg "uksouth"</span></span>
<span id="cb1-4"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">sku</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Standard_LRS"</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standard Locally Redundant Storage</span></span></code></pre></div>
<p>Then to create the blob, it’s</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> storage account create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$storagename</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--resource-group</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$resourcegroup</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--location</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$location</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--sku</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$sku</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--encryption-services</span> blob</span></code></pre></div>
<p>If this has worked, you’ll get a JSON structure back that looks something like this:</p>
<pre class="text"><code>{
  "accessTier": "Hot",
  "accountMigrationInProgress": null,
  "allowBlobPublicAccess": false,
  "allowCrossTenantReplication": false,
  "allowSharedKeyAccess": null,
  "allowedCopyScope": null,
  "azureFilesIdentityBasedAuthentication": null,
  "blobRestoreStatus": null,
  "creationTime": "&lt;&gt;",
  "customDomain": null,
  "defaultToOAuthAuthentication": null,
  "dnsEndpointType": null,
  "enableHttpsTrafficOnly": true,
  "enableNfsV3": null,
  "extendedLocation": null,
  "failoverInProgress": null,
  "geoReplicationStats": null,
  "id": "/subscriptions/&lt;&gt;/resourceGroups/&lt;&gt;/providers/Microsoft.Storage/storageAccounts/&lt;&gt;",
  "identity": null,
  "immutableStorageWithVersioning": null,
  "isHnsEnabled": null,
  "isLocalUserEnabled": null,
  "isSftpEnabled": null,
  "isSkuConversionBlocked": null,
  "keyPolicy": null,
  "kind": "StorageV2",
  "largeFileSharesState": null,
  "lastGeoFailoverTime": null,
  "location": "uksouth",
  "minimumTlsVersion": "TLS1_0",
  "name": "&lt;&gt;",
  "networkRuleSet": {
    "bypass": "AzureServices",
    "defaultAction": "Allow",
    "ipRules": [],
    "ipv6Rules": [],
    "resourceAccessRules": null,
    "virtualNetworkRules": []
  },
  "primaryEndpoints": {
    "blob": "https://&lt;&gt;.blob.core.windows.net/",
    "dfs": "https://&lt;&gt;.dfs.core.windows.net/",
    "file": "https://&lt;&gt;.file.core.windows.net/",
    "internetEndpoints": null,
    "microsoftEndpoints": null,
    "queue": "https://&lt;&gt;.queue.core.windows.net/",
    "table": "https://&lt;&gt;.table.core.windows.net/",
    "web": "https://&lt;&gt;.z33.web.core.windows.net/"
  },
  "primaryLocation": &lt;&gt;,
  "privateEndpointConnections": [],
  "provisioningState": "Succeeded",
  "publicNetworkAccess": null,
  "resourceGroup": "inv-day-test",
  "routingPreference": null,
  "sasPolicy": null,
  "secondaryEndpoints": null,
  "secondaryLocation": null,
  "sku": {
    "name": "Standard_LRS",
    "tier": "Standard"
  },
  "statusOfPrimary": "available",
  "statusOfSecondary": null,
  "storageAccountSkuConversionStatus": null,
  "tags": {},
  "type": "Microsoft.Storage/storageAccounts"
}</code></pre>
</section>
<section id="assign-permission-to-use-the-storage-account" class="level3">
<h3 class="anchored" data-anchor-id="assign-permission-to-use-the-storage-account">Assign permission to use the storage account</h3>
<p>Right now, you’ve created a storage account, but you don’t have permission to use it! Let’s change that by adding the current user to have the role assignment “Storage Blob Data Contributor”.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">subscriptionid</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># long combination of numbers and letters with dashes</span></span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> ad signed-in-user show <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--query</span> id <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-o</span> tsv <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">|</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> role assignment create <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb4-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--role</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Storage Blob Data Contributor"</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb4-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--assignee</span> @- <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb4-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--scope</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/subscriptions/</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$subscriptionid</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/resourceGroups/</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$resourcegroup</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/providers/Microsoft.Storage/storageAccounts/</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$storagename</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span></code></pre></div>
<p>Note that we already saved the other variables. Running this should result in another JSON file full of info.</p>
</section>
<section id="creating-a-storage-container-using-the-cli" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-storage-container-using-the-cli">Creating a storage container using the CLI</h3>
<p>Next up, we want to create a storage container.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">containername</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;&gt;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># eg "mydemocontainer"</span></span>
<span id="cb5-2"></span>
<span id="cb5-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> storage container create <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb5-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--account-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$storagename</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb5-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$containername</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb5-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--auth-mode</span> login</span></code></pre></div>
<p>Once this runs you should get a little JSON saying</p>
<pre class="text"><code>{
  "created": true
}</code></pre>
</section>
<section id="how-to-upload-a-file-to-blob-storage" class="level3">
<h3 class="anchored" data-anchor-id="how-to-upload-a-file-to-blob-storage">How to upload a file to blob storage</h3>
<p>Now we need a text file to try out “mydemocontainer” or whatever you called it in <code>containername</code>. To create one, use</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hello world"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;</span> test.txt</span></code></pre></div>
<p>this creates the file <code>test.txt</code> locally. To then upload it to your storage container as <code>test_on_blob.txt</code>, use the below:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> storage blob upload <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--account-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$storagename</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--container-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$containername</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> test_on_blob.txt <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--file</span> test.txt <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--auth-mode</span> login</span></code></pre></div>
</section>
<section id="checking-it-worked" class="level3">
<h3 class="anchored" data-anchor-id="checking-it-worked">Checking it worked</h3>
<p>Of course, you can check this in the Azure Portal. But to check it on the command line, it’s</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> storage blob list <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--account-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$storagename</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--container-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$containername</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output</span> table <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--auth-mode</span> login</span></code></pre></div>
<p>which should result in a table showing a single file, <code>test_on_blob.txt</code>.</p>
</section>
<section id="download-data-back-from-the-blob" class="level3">
<h3 class="anchored" data-anchor-id="download-data-back-from-the-blob">Download data back from the blob</h3>
<p>For this, we’ll use the <code>az storage blob download</code> command.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> storage blob download <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--account-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$storagename</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--container-name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$containername</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> test_on_blob.txt <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--file</span> back_from_blob.txt <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--auth-mode</span> login</span></code></pre></div>
<p>That’s it! The general setup is the same. For transferring lots of files, you may want to check out the <a href="https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10">azcopy</a> utility too. There are also <a href="https://learn.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python">Python libraries</a> for interacting with blob storage.</p>


</section>
</section>

 ]]></description>
  <category>code</category>
  <category>cloud</category>
  <guid>https://www.aeturrell.com/blog/posts/til-blob-storage-azure/</guid>
  <pubDate>Mon, 22 Apr 2024 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/til-blob-storage-azure/None" medium="image"/>
</item>
<item>
  <title>TIL: how to connect Visual Studio Code to Azure Virtual Machines</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/til-how-to-run-vscode-remote-azure/</link>
  <description><![CDATA[ 





<p>In a previous blog post, I looked at <a href="../../../blog/posts/visual-studio-code-in-the-cloud/index.html">how to connect desktop-based Visual Studio Code to a Google Cloud Virtual machine</a>; today, it’s how to do the same using a virtual machine running on Microsoft’s Azure platform.</p>
<section id="setting-up" class="level2">
<h2 class="anchored" data-anchor-id="setting-up">Setting Up</h2>
<p>There are two pieces to this puzzle: Visual Studio Code and the Azure Cloud Platform.</p>
<p>First, grab Visual Studio Code for your local computer (ie your non-cloud computer) and whatever extensions you fancy, but you’ll need <a href="https://code.visualstudio.com/docs/remote/ssh">the remote explorer (SSH)</a> at a minimum.</p>
<p>You’ll also need to sign up for a Microsoft Azure account and get either the free tier of services or activate a pay-as-you-go account. Be warned: if you have multiple Microsoft accounts for home and work, this can be a frustrating and circular process where you are constantly signing in and being taken to different accounts.</p>
<p>With that in place, there are two ways to proceed to create your Azure infrastructure: you can either use the Azure Command Line Interface (CLI), which you can find information <a href="https://learn.microsoft.com/en-us/cli/azure/">on here</a> or use the <a href="https://portal.azure.com/#home">Azure website</a> directly.</p>
</section>
<section id="creating-a-cloud-vm-instance" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-cloud-vm-instance">Creating a Cloud VM Instance</h2>
<section id="using-the-website" class="level3">
<h3 class="anchored" data-anchor-id="using-the-website">Using the website</h3>
<p>On the <a href="https://portal.azure.com/#home">Azure website</a>, navigate to the “Virtual Machines” resources page and hit create. There are a couple of options, but if you’re just trying this out you might like to use one of the pre-configured machines. I used one of the pre-configured D-Series computers and chose Linux (Ubuntu) as the operating system. You’ll need to set your subscription and resource group from the drop-down menu. Give the virtual machine a name, choose the region closest to you, and feel free to use the defaults for most of the other options. There is a box for a username: note that this is what your ID will be on the virtual machine once it’s created. Choose SSH as the authentication type and give the file a name. Hit review and create! Make sure to save the private key certificate, the “.pem” file, to somewhere sensible on your local machine. This file is what will let you remotely access the virtual machine from your computer via Visual Studio Code.</p>
<p>There is an important extra step here, at least on MacOS. The certificate file that you’ve just downloaded will be set so that everyone has read and write permissions. When you later try to connect via SSH, this will raise alarm bells. So you want to set it so that only the Mac’s current user, you, can read and write it. To do this, navigate to the file in the command line and then run</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">chmod</span> 600 my-certificate-name.pem</span></code></pre></div>
</section>
<section id="using-the-command-line-interface" class="level3">
<h3 class="anchored" data-anchor-id="using-the-command-line-interface">Using the command line interface</h3>
<p>Let’s now see how to do this using the <a href="https://learn.microsoft.com/en-us/cli/azure/">Azure CLI</a> instead. Follow the install instructions for your system. In the following, I’ll assume you already have a resource group set up. Use <code>az login</code> to login to your cloud account.</p>
<p>Then the command to create a virtual machine (running Ubuntu 22.04.4 LTS with 2 cores and 8GB of RAM) is:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">resourcegroup</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RESOURCE-GROUP"</span></span>
<span id="cb2-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">vmname</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"VIRTUAL-MACHINE-NAME"</span></span>
<span id="cb2-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">username</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"USERNAME"</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">az</span> vm create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--resource-group</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$resourcegroup</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$vmname</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--image</span> Ubuntu2204 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--admin-username</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$username</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--size</span> Standard_D2ds_v4 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">----generate-ssh-keys</span></span></code></pre></div>
<p>You can see a summary list of available images by running <code>az vm image list</code>. To get the full, live list of Ubuntu options it would be <code>az vm image list -f Ubuntu --all</code> but note that this could take a long time to run. For more powerful computers, select another size (you can see the available ones using <code>az vm list-sizes --location REGION --output table</code> but you’ll have to check the website for prices.</p>
<p>If the <code>create</code> command is successful, you should see something a bit like the following appear:</p>
<pre class="text"><code>{
  "fqdns": "",
  "id": "/subscriptions/YOUR-SUBSCRIPTION-ID/resourceGroups/RESOURCE-GROUP/providers/Microsoft.Compute/virtualMachines/VIRTUAL-MACHINE-NAME",
  "location": REGION,
  "macAddress": AN-ID,
  "powerState": "VM running",
  "privateIpAddress": "X.X.X.X",
  "publicIpAddress": "X.X.X.X",
  "resourceGroup": RESOURCE-GROUP,
  "zones": ""
}</code></pre>
<p>Note that you should also get a public SSH key back from this operation, which by default is saved as a .pem file in <code>~/.ssh</code> on your local machine.</p>
</section>
</section>
<section id="connecting-to-a-running-azure-virtual-machine-instance-from-visual-studio-code" class="level2">
<h2 class="anchored" data-anchor-id="connecting-to-a-running-azure-virtual-machine-instance-from-visual-studio-code">Connecting to a running Azure Virtual Machine Instance from Visual Studio Code</h2>
<p>Okay, so your Azure VM instance is running and now you’re going to connect to it with Visual Studio Code.</p>
<p>First, we need to set up the SSH connection between your computer and your running cloud VM; essentially a way for them to talk to each other. You can find out more about SSH authentication <a href="https://www.ssh.com/academy/ssh/protocol">here</a>. On the Azure website, and looking at your virtual machine, click on the “connect” button. You’ll then see two options: use “Native SSH”. When you click on Native, you’ll see a panel open up on the right-hand side (as long as your virtual machine is already running). You’ll see a command a bit like:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ssh</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> ~/.ssh/id_rsa.pem VM-USERNAME@VM-IP-ADDRESS</span></code></pre></div>
<p>Essentially, what this is saying is that to SSH into your running virtual machine from the command line, you’ll need to use the SSH command passing in as arguments both the location of your “.pem” certificate, which should only be read/write by you, and then the username you used for the VM followed by the public IP address of the VM, which you can see in the panel.</p>
<p>You could just run this on the command line and connect that way. But to get all the goodies of Visual Studio Code, it’s a slightly different process.</p>
<p>Within Visual Studio Code on your local computer, go to the remote explorer tab, which you can find on the left hand side (you’ll need to have installed the remote explorer package for SSH). Choose ‘SSH Targets’ from the drop-down menu at the top. Click the “+” button next to SSH and then paste in the SSH command. Hit refresh on the remotes panel, and you should now see a new entry for your virtual machine. Right click on it and select “Connect in New Window” to get Visual Studio Code to connect.</p>
<p>Congratulations, you should now be on your VM instance using Code! You can check because the green text in the bottom left-hand corner of Visual Studio Code should read</p>
<blockquote class="blockquote">
<p>SSH: VIRTUAL-MACHINE-NAME</p>
</blockquote>
<p>And the command prompt in the new VS Code window should say something like <code>USERNAME@VIRTUAL-MACHINE-NAME:~$</code>.</p>
<p>For more instructions, including installing Python and git, check out the <a href="../../../blog/posts/visual-studio-code-in-the-cloud/index.html">original post on this with Google Cloud</a>.</p>
</section>
<section id="finishing" class="level2">
<h2 class="anchored" data-anchor-id="finishing">Finishing</h2>
<p>Remember: best practice is to treat a cloud instance as temporary. Shunt data you want to save in and out when you use it, and use version control for code. And most of all, <strong>don’t forget to turn your VM instance off when you’ve finished using it!</strong></p>
<p>Hopefully this has been a useful summary of how to use Visual Studio Code in the (Azure!) cloud. Happy coding!</p>


</section>

 ]]></description>
  <category>code</category>
  <category>research</category>
  <category>cloud</category>
  <category>python</category>
  <category>rstats</category>
  <guid>https://www.aeturrell.com/blog/posts/til-how-to-run-vscode-remote-azure/</guid>
  <pubDate>Fri, 08 Mar 2024 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/til-how-to-run-vscode-remote-azure/None" medium="image"/>
</item>
<item>
  <title>TIL: how to create a virtual desktop from a cloud virtual machine</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/virtual-desktop-from-virtual-machine/virtual-desktop-from-virtual-machine.html</link>
  <description><![CDATA[ 





<p>Researchers frequently want to be able to access a second computer that works like a normal computer (think a virtual desktop rather than a virtual machine + command line) just to offload some computation. This post shows how.</p>
<p>The basic idea here is you don’t want to gum up your own laptop with lots of lengthy computations<sup>1</sup> but you don’t feel confident just using a virtual machine via the command line, or using <a href="../../../blog/posts/visual-studio-code-in-the-cloud/index.html">visual studio code remotely</a>, but you want a virtual desktop that feels a bit similar to using a laptop (only in a browser window). We’ll be using Google’s handy remote desktop service for this.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;And you’ve already optimised in the obvious ways.</p></div></div><section id="recipe" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="recipe">Recipe</h2>
<p>For this, you’ll need a Google Cloud (GCP) account and project with the compute engine API enabled.</p>
<ol type="1">
<li><p>Head to create instances in GCP</p></li>
<li><p>Hit create instance</p></li>
<li><p>Use your normal settings except for under “Boot disk” choose Ubuntu (a good idea to use the latest non-minimal version, I used 23.10)</p></li>
<li><p>Create the virtual machine and use Google’s handy “SSH” button to enter it on the command line</p></li>
<li><p>Run the following on the virtual machine to download the Google remote desktop package and install it</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wget</span> https://dl.google.com/linux/direct/chrome-remote-desktop_current_amd64.deb</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--assume-yes</span> ./chrome-remote-desktop_current_amd64.deb</span></code></pre></div></li>
<li><p><code>sudo apt install slim</code>, which is a display manager</p></li>
<li><p><code>sudo apt install ubuntu-desktop</code> to get an ubuntu desktop installed (we’re still on the virtual machine here)</p></li>
<li><p>Once done, use <code>sudo reboot</code>. You’ll be kicked off the VM but you can just reconnect as soon as it’s rebooted.</p></li>
<li><p>Once back on your rebooted virtual machine, hit <code>sudo service slim start</code>.</p></li>
<li><p>Back on your local computer, go to the Chrome Remote Desktop command line setup page: <a href="https://remotedesktop.google.com/headless">https://remotedesktop.google.com/headless</a></p></li>
<li><p>On the Set up another computer page, click Begin then click Next. You already installed the Chrome Remote Desktop on the remote computer.</p></li>
<li><p>Click Authorize</p></li>
<li><p>This gives you some code to run on your VM instance that will allow you to connect to it remotely. Copy the command for Debian Linux and run in on the command line of the VM.</p></li>
<li><p>When you are asked for one, enter a 6-digit PIN that you have devised. This PIN will be used when you log into the VM instance from the remote desktop browser page.</p></li>
<li><p>Head to that browser page (<a href="https://remotedesktop.google.com/headless">this link</a>) and you should be asked for your pin.</p></li>
<li><p>You should see a fully working Ubuntu desktop through your browser window!</p></li>
</ol>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/virtual-desktop-from-virtual-machine/screenshot_ubuntu.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="margin-caption">Screenshot of the desktop changer and app selection functions of Ubuntu desktop accessed through Google’s remote desktop facility</figcaption>
</figure>
</div>
<p>Remember: you will be charged for the time that your instance is running. This is usually inexpensive but you do want to turn off the virtual machine when you’re not actively using it. You can do this on the instances page with the “stop” button. And, as ever, to tear down the virtual machine completely (and lose anything on it), go to the instances page on GCP and use the delete option.</p>


</section>


 ]]></description>
  <category>code</category>
  <category>data science</category>
  <category>research</category>
  <guid>https://www.aeturrell.com/blog/posts/virtual-desktop-from-virtual-machine/virtual-desktop-from-virtual-machine.html</guid>
  <pubDate>Mon, 04 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/virtual-desktop-from-virtual-machine/screenshot_ubuntu.png" medium="image" type="image/png" height="141" width="144"/>
</item>
<item>
  <title>Data science with impact</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/data-science-with-impact/</link>
  <description><![CDATA[ 





<p>I was recently asked to give a talk at No.&nbsp;10 Downing Street on the topic of data science with impact and, in this post, I’m going to share some of what I said in that talk. The context for being asked is that the folks in 10DS, the Downing Street data team, are perhaps the most obsessed with having impact of any data science team I’ve met–so even though they’re the real experts on this topic, they’re very sensibly reaching out to others to see if there is anything extra they can learn.</p>
<p>There are plenty of caveats to the below—it’s just my take and I’m not claiming to have definitive answers; I’m sure management experts have <em>much</em> more to say on the general topic. But I’m not sure many others have talked about how to do <em>data science</em> with impact in the public sector, so hopefully that angle is useful and new. One limitation: a lot of my thinking is informed by working in the UK’s Data Science Campus as Deputy Director and then Acting Director, and so may be overly occupied with whether to undertake this or that data science project as compared with the decisions needed to be taken by data science teams in more operational areas. Throughout, I provide concrete examples and links to more detail on them. Any mistakes in referring to Campus projects, and the views expressed below, are very much my own.</p>
<section id="what-impact-is" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-impact-is">What impact is</h2>
<p>For me, to first order, data science with impact is data science for the public good. In other words, you must be able to articulate how a new project or process will benefit the public once complete.</p>
<p>Inevitably, this prompts the question “what constitutes public good?” My very high-level mental model is that it’s a simple calculation<sup>1</sup> of</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;At the risk of sounding like an effective altruist.</p></div></div><p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bnumber%20of%20people%20affected%20%7D%20%5Ctimes%20%5Ctext%7B%20impact%20on%20people%7D%0A"></p>
<p>where the impact on people is the <strong>net present value of the improvement to their life</strong>. For want of a better description, let’s call this the <em>impact equation</em>. If you’re not familiar with net present value, the equation is</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BNPV%7D%20=%20%5Cdisplaystyle%5Csum%20%5Cfrac%7BR_t%7D%7B(1+i)%5Et%7D%0A"></p>
<p>which is to say it is the sum of the “returns” at time <img src="https://latex.codecogs.com/png.latex?t"> (where <img src="https://latex.codecogs.com/png.latex?t"> is number of time steps into the future), <img src="https://latex.codecogs.com/png.latex?R_t">, discounted by rate <img src="https://latex.codecogs.com/png.latex?i"> for <img src="https://latex.codecogs.com/png.latex?t"> steps into the future.</p>
<p>What does this equation mean in practice? Don’t let the urgent crowd out the important, despite the strong temptation to only look directly in front of you when you’re working at a policymaking institution buffeted by short-term headwinds. It also means you should <em>look for the timeless angle in everything you do</em>—even while you’re solving an urgent problem.</p>
<p>To be a bit more concrete about how this applies when doing data science, open-sourcing the code you’re using is a great way to make that urgent problem you’re working on more timeless. While you may never pick that code up again, someone else just might. Likewise, blogging about what you did—even in a very matter-of-fact way—can help those who come after you with a similar problem get started more quickly. It also points to thinking carefully about the ongoing maintenance costs of what you’re producing—one reason why dashboards, one of the most requested data science products, can get down-rated when looking through this lens.<sup>2</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Everyone thought the UK Health Security Agency’s COVID-19 dashboard was fantastic, and so it was. But did you know there was a whole team behind it, ensuring it was kept usefully up to date? Dashboards need considerable resources to stay relevant, accurate, and useful.</p></div></div><p>Let’s turn to the first of our examples of delivering public good using data science.</p>
<section id="example-of-public-good-least-cost-grocery-index" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="example-of-public-good-least-cost-grocery-index">Example of public good: least cost grocery index</h3>
<p>In January 2022, food campaigner Jack Monroe put out a tweet that garnered huge press coverage. The tweet read</p>
<blockquote class="blockquote">
<p>Woke up this morning to the radio talking about the cost of living rising a further 5%. It infuriates me the index that they use for this calculation, which grossly underestimates the real cost of inflation as it happens to people with the least. Allow me to briefly explain”</p>
</blockquote>
<p>and quickly raked in 60,000 likes. Just as quickly, Jack was invited onto breakfast news programmes to talk about how price rises were hitting the poorest in society.</p>
<p>The idea she was sharing is simple and compelling, which is also probably why it caught on in the public debate, especially as the cost of living was a major concern at that time. Jack’s point was that inflation as measured by the UK’s <em>Office for National Statistics</em> (ONS) is measure of the change in average prices not a measure of the change in the <em>lowest</em> prices. She gave some examples from her own experience, like a budget bag of pasta increasing from 29p to 70p.</p>
<p>Jack had a point: as the ONS’ website puts it, “A convenient way to understand the nature of these statistics is to envisage a very large shopping basket comprising all the different kinds of goods and services bought by a typical household.” A typical household is not one that is only buying the lowest cost versions of all products—but households at the bottom of the income distribution might be. So it is possible that the very poorest households could face a different inflation rate.</p>
<p>At the time this was happening, I was working at the Data Science Campus at the ONS, and myself and some other ONS colleagues—most notably Matt Corder and Abi Casey—decided that ONS could not and should not stay silent. If we weren’t going to talk about inflation when it was on breakfast TV, when would we talk about it? Against some weak external and considerable internal resistance, we persuaded the rest of the organisation that we should create a lowest-cost grocery index. This index would speak directly to Jack Monroe’s question, a question that, by this point, was at the heart of the public debate. There was no time to lose if we were going to fill the information vacuum before poorer quality data and analysis did.</p>
<p>The traditionally collected basket of goods used in the CPI (consumer prices index) measure of inflation did not explicitly include budget items, making the analysis potentially impossible. Fortunately, some forward-looking colleagues had already laid the groundwork for us by setting up the automatic scraping of prices on supermarkets’ websites (with the blessing of those supermarkets). Working together across the Campus and Prices areas of ONS, we used the web-scraped data to create a new “least cost” grocery index.</p>
<p>The index was constructed based on a limited number of products (30) because the analysis needed to be ready quickly in order to inform the public debate: ie this work had some element of <strong>urgency</strong>. Even then it took from January to April to do. The items were chosen using data from the Department for Environment, Food and Rural Affairs (DEFRA) 2019/20 Family food datasets, which allowed us to identify the grocery items most likely to be bought by households on low incomes. The results are in the figure.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/least_cost_index_v1.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="margin-caption">Chart of how prices of least cost grocery items changed produced by the Campus and ONS.</figcaption>
</figure>
</div>
<p>How does this fit in with data science for the public good? The first way is that this story, about the cost of living, reached (and was relevant to) a large number of people. While only some households were directly affected by the inflation in the lowest cost items, many were concerned—and therefore interested. Although it wasn’t certain, we knew there was a good chance this analysis would be big news, and indeed the lowest cost grocery index was picked up by all the major news shows and newspapers. In the Campus, we knew it was a hit, because we were asked to put it on the ONS website rather than the Campus’ website (albeit with a “highly experimental” label).<sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;An example of what I like to call the Campus’ Andy Murray problem.</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/bbc_least_cost.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="margin-caption">Many news organisations, including the BBC, ran a leading story on the least cost grocery index.</figcaption>
</figure>
</div>
<p>This story reached a large number of people, and, for some, it hopefully affected them too: by validating their experience but also pointing to the items that had fallen in price. It also showed that the <em>next cheapest</em> product was often a substantially more (20%+) than the cheapest and arguably influenced supermarkets to focus more on their budget lines.</p>
<p>Thinking about that term in the impact equation that looks into the future, there’s also an element of timelessness in this urgent work: we set a precedent for producing a least cost index, and we created the code to do it. Which means that that a similar analysis can be run again whenever needed. And, indeed, in October of 2022, the <a href="https://www.ons.gov.uk/economy/inflationandpriceindices/articles/trackingthelowestcostgroceryitemsukexperimentalanalysis/april2021toseptember2022">index was run again</a>. There was a resource cost in doing this, but it was far lower than for producing the initial work.</p>
</section>
</section>
<section id="considerations-for-having-impact-with-data-science-projects" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="considerations-for-having-impact-with-data-science-projects">Considerations for having impact with data science projects</h2>
<section id="is-a-data-science-team-the-best-option" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="is-a-data-science-team-the-best-option">Is a data science team the best option?</h3>
<p>Different types of teams will be more or less productive working on different kinds of tasks. Tackling only the problems for which data science teams are uniquely well-placed is going to give more bang for the buck.</p>
<p>Economists will be familiar with the idea of comparative advantage. To put it succinctly, the idea is that it’s economically efficient to do the thing that you are uniquely best at (rather than the thing you are best at overall, or, more obviously, the thing you are bad at). I know some people who are excellent economists who are also excellent data scientists. Right now in the world, it’s easier to find excellent economists than it is excellent data scientists, so those people should probably focus on data science—even if they’re better at economics than most economists.</p>
<p>Sometimes a data science team will have a comparative advantage in doing a project or running a process. For example, if a project simultaneously requires skills in coding and analysis, data scientists are uniquely placed. If all that is needed is coding, maybe a team of software developers would be better though—by which I mean they could have more impact per unit of input of effort.</p>
<p>In the example of the least cost grocery index, there was probably no other organisation in the UK that was better placed to produce the analysis than ONS: it took a combination of already collected supermarket price data, data science skills to track budget products over time, and inflation methodology skills, not to mention all of the stakeholder management and communication skills needed to land such a high profile analytical project with the general public. Of course, it also hugely helped that ONS is an authoritative voice on all things inflation.</p>
<p>Comparative advantage can take forms other than skills. Working in government, I frequently found that there were gaps between departments’ briefs or, even more commonly, co-ordination problems because of overlapping briefs. There’s nothing inherent about a data science team that would make it well suited to solving co-ordination problems. But, in the Data Science Campus, we had an explicit mandate to look across the entire public sector. And one way we could add value relative to what departmental data science teams were doing was to solve some of those co-ordination problems and bring people working in different departments (or their data) together. Which leads to the next example.</p>
<section id="example-of-being-the-right-team-and-solving-co-ordination-problems-preference-tariff-utilisation-rates" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="example-of-being-the-right-team-and-solving-co-ordination-problems-preference-tariff-utilisation-rates">Example of being the right team and solving co-ordination problems: preference tariff utilisation rates</h4>
<p>Preferential trade agreements (PTAS) are used to promote international trade, and we know that international trade brings a bunch of benefits beyond only trading domestically. All else equal, lowering the transaction costs of international trade is helpful—and firms making use of <em>preference tariffs</em> face lower transaction costs. But, previously, there was little information on the extent to which UK firms were making use of these cheaper tariffs.</p>
<p>The problem was that these data lay across several different datasets housed by different UK government departments. I won’t go into the details here because you can read about it at length in <a href="https://datasciencecampus.ons.gov.uk/the-use-of-microdata-for-firm-level-analysis-of-preference-tariff-utilisation-in-the-uk-technical-report/">blogs on the Data Science Campus</a>, but the short version is by combining data from HM Revenue and Customs (HMRC) (on trade in goods), the Inter-Departmental Business Register, and International Trade Centre’s Market Access Map, it was possible to estimate the underuse of tariffs: essentially to work out how much money UK firms were leaving on the table.</p>
<p>The results involve significant sums that firms are, apparently, spending unnecessarily. The work did not establish whether this was simply because firms were unaware of the tariffs or were aware and but refrained because the costs associated with the bureaucracy of the preferential tariffs meant it wasn’t worth using them. But it did tell us that this was occurring for tens of thousands of firms (“people” in our impact equation) and billions of pounds (depth of effect in our equation). And, just like the least cost index, there is plenty of replay value to be had in re-running this analysis—especially following any interventions.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/purs_savings_by_size.png" class="img-fluid figure-img" style="width:55.0%"></p>
<figcaption class="margin-caption">Potential duty savings as estimated in a project bringing together disparate datasets to look at the use of preferential tariffs.</figcaption>
</figure>
</div>
</section>
</section>
<section id="portfolio-construction" class="level3">
<h3 class="anchored" data-anchor-id="portfolio-construction">Portfolio construction</h3>
<p>When creating a portfolio of data science projects, you should think about it like any other portfolio. Some projects may be more risky, but have a higher potential pay-off. Some will be dead certs but with limited upside. Rightful scrutiny of how money is spent means that very few have the luxury of only going for high risk, high reward projects. (Although you can see this is how some industries end up being more dominated with the relatively better off—they have a safety net.) Being pragmatic, you’ll need a mix of projects to keep everyone happy.</p>
<p>This applies in time too: the reality of most of the public sector is that you can’t have projects that take years to come to fruition. In some places, you might be lucky to have weeks. There’s an old joke about a department that shall remain unnamed: Q: “what do they call research?” A: “Anything that isn’t due tomorrow.” To keep everyone happy, and to ensure you really are delivering, it’s wise to have a portfolio of projects that will keep delivering wins in a steady stream so that there aren’t long fallow periods.</p>
<p>In small data science teams, this can be hard, simply because it’s hard to play a numbers game with small numbers of projects / staff / FTE. In this case, you need to think carefully about what the tolerances are around delivery. But the general principle of going for a steady stream of projects with some big, some small, some which maybe don’t work at all, holds.</p>
</section>
<section id="building-human-or-physical-capital" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="building-human-or-physical-capital">Building human or physical capital</h3>
<p>Data science is rapidly changing, with new or upgraded technologies appearing all the time. Simply staying on top of developments takes up a lot of time—but staying on top of developments is also critical for ensuring that the portfolio of projects you choose to undertake is as impactful as it can be.</p>
<p>Because of this dynamic, projects that top up or build human (or physical) capital may have strategic benefits for long-term impact. In taking on a project partly to build human capital, you’re explicitly targeting the future stream of returns in the impact equation but taking a hit on the <img src="https://latex.codecogs.com/png.latex?1/(1+i)%5Et"> part.</p>
<section id="example-of-building-human-capital-statschat" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="example-of-building-human-capital-statschat">Example of building human capital: StatsChat</h4>
<p>Artificial intelligence and machine learning are critical parts of data science, and staff at the Campus followed the developments in large language models such as ChatGPT with excitement. In the UK context, it very quickly became clear that there was huge interest across the public sector in large language models—and it would only be a matter of time before the Campus would be asked to do a project involving a large language model.</p>
<p>Rather than wait for the call, we took a decision to proactively get some experience with large language models<sup>4</sup> by creating an experimental website search function based on LLM-related technologies. Those of you familiar with the ONS website will be aware that the search functionality is, erm, less than optimal and <a href="https://datasciencecampus.ons.gov.uk/optimising-the-ons-site-search-function-with-google-analytics-and-natural-language-processing/">this isn’t the first time the Campus</a> has attempted to provide better search tools that central ONS services could use to improve the website.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;A lot of the credit for pushing this forward goes to my former colleagues in the Data Science Campus; while I was an early and enthusiastic supporter, they did all of the work. Ed Sherman and Andy Banks, plus Andy’s team, were key in making StatsChat happen.</p></div></div><p>The team built a demo app that, in examples, seems to dramatically improve the experience of using the ONS website while minimising the potential issues of LLMs, such as hallucinations. You can <a href="https://datasciencecampus.ons.gov.uk/using-large-language-models-llms-to-improve-website-search-experience-with-statschat/">read more about the project in this blog post</a>, but the basic steps were:</p>
<ul>
<li>create a document store of every publication on the ONS website with accompanying metadata</li>
<li>partition documents into chunks of roughly 1000 characters and converted these into vector embeddings using a sentence transformers model</li>
<li>run an embedding search algorithm to collect the most relevant web pages from a given user query</li>
<li>finally, use a generative question-answering (GQA) model to turn the most relevant retrieved documents into a concise and naturally phrased answer</li>
</ul>
<p>The project is very impressive. In one example, a user asks “how many people watched the kings [sic] coronation?”, and StatsChat correctly retrieves the information that “Around 6 in 10” people watched or planned to watch it.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/statschat_example.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="margin-caption">An example of StatsChat in action.</figcaption>
</figure>
</div>
<p>Following this exploratory project, the team is in a much better place to use LLMs in future. And having a ready-made, cutting-edge improvement to the ONS’ website just waiting to be implemented by the Communications department isn’t a bad side outcome either. You can find the <a href="https://github.com/datasciencecampus/statschat-app">code here</a>.</p>
</section>
</section>
</section>
<section id="the-ways-that-data-science-can-have-impact" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-ways-that-data-science-can-have-impact">The ways that data science can have impact</h2>
<p>So far, we’ve looked at what impact with data science means and at some impact-related considerations around what projects data science teams take on. Now we’re going to look at the ways that data science work can have impact. I usually think of three:</p>
<ol type="1">
<li>Saving time or money in what’s already happening.</li>
<li>Enabling higher quality in what’s already happening.</li>
<li>Enabling new things to happen.</li>
</ol>
<section id="saving-time-or-money" class="level3">
<h3 class="anchored" data-anchor-id="saving-time-or-money">Saving time or money</h3>
<p>This is pretty simple: data science can enable an organisation to do things faster, cheaper, or with less human labour. There are a bunch of examples you could pick on but automating data processing that would otherwise be done manually is the one that occurs extremely frequently in analytical functions. A typical case would be updating a forecast with the latest data: how many forecasting organisations do this via manually updated spreadsheets? With data science (cloud computing, orchestration tools, code) you can schedule data processing jobs to happen whenever a website (perhaps that of a statistical office) is updated. Instead of tying up staff time on manual updates, the updated forecast can just take care of itself—leaving more time for thinking. There’s a book about Python called “Automate the Boring Stuff”, and I think that sums it up pretty nicely: with the boring stuff automated, people can focus on where they add value the most, which is usually more about thinking and strategy.</p>
</section>
<section id="enabling-higher-quality" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="enabling-higher-quality">Enabling higher quality</h3>
<p>There are so many examples where data science might improve quality. I’ve written recently about how <a href="../../../blog/posts/why-have-a-model-registry/index.html">model registries can reduce model risk</a> for organisations. Data science tools for checking data for issues, like <a href="https://docs.greatexpectations.io/docs/">Great Expectations</a>, or for proactively finding examples that break code, like <a href="https://hypothesis.readthedocs.io/en/latest/">hypothesis</a>, have come on leaps and bounds. And switching from risky spreadsheets to easily auditable version-controlled code represents a phenomenal increase in quality (via a decrease in mistakes).<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;It’s very possible to make mistakes in code too, but the use of tests, version control, and the separation of data and logic make—in my view—analysis based on code inherently much less risky than analysis in spreadsheets. Every few months there is a massive spreadsheet-related data leak or costly mistake. Some of these are curated in the “horror stories” section of the <a href="https://eusprig.org/research-info/horror-stories/">European Spreadsheet Risks Interest Group</a>.</p></div></div><p>As a specific example, the Campus was asked to help with the NHS (National Health Service) Covid App. For those not familiar with the UK context, this app was promoted to the population at large and was very widely used during the Covid-19 pandemic. As such, it collected huge amounts of feedback (good and bad) via both the Apple App Store and the Google Play App Store. Due to the scale of use of the app, there was too much feedback for even a substantial team to read through it all.</p>
<p>A team from the Campus worked with the NHS to use a data science method, called topic modelling, and a data science tool, a dashboard, to help software developers triage the most impactful issues so that they could be fixed first.</p>
<p>You can <a href="https://datasciencecampus.ons.gov.uk/understanding-nhs-coronavirus-covid-19-app-reviews-using-topic-modelling/">read more about this project here</a>, but the bottom line is that there were limited resources to work on the app but the data scientists involved were able to ensure that these resources were focused on improving the app’s quality in the most impactful way. They did this by using data science methods to capture common themes even if the people reporting them had used quite different phrasing. One innovation that was particularly helpful to developers was the ability to spit out a ‘canonical’ feedback text for each emerging topic: this stated the problem in plain English. The pipeline was run in the cloud.</p>
<p>Without the data science, improvements to the app would still have happened, but they would have had less impact.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/nhs_app.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Screenshot of the dashboard summarising the most important issues to fix with the NHS Covid app.</figcaption>
</figure>
</div>
</section>
<section id="enabling-new-things-to-happen." class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="enabling-new-things-to-happen.">Enabling new things to happen.</h3>
<p>Data science opens up possibilities that simply did not exist before. This could be new analysis, measurement, and insight, but it could also be ways to deliver public services. I’m very taken with the example of the <a href="https://www.theguardian.com/world/2022/aug/29/french-tax-officials-use-ai-to-spot-20000-undeclared-pools">French tax authorities using satellite data to detect undeclared swimming pools</a> —something that would not have been possible before.</p>
<p>As a really good example, let’s look at how staff at the Data Science Campus developed new measurements of population mobility during the Covid-19 pandemic. At that time, policymakers were desperate for high frequency measures of mobility because mobility is a key determinant of how easily the virus is able to spread and because existing official statistics were released with a substantial lag.</p>
<p>In the UK, there are a large number of publicly-owned, publicly-accessible CCTV feeds. So Campus staff set up a cloud-based automatic data processing pipeline that:</p>
<ul>
<li>every ten minutes, woke up thousands of (virtual) cloud computers to draw down thousands of stills from CCTV cameras</li>
<li>ran an anonymisation algorithm on the images (blurring faces and vehicle number plates)</li>
<li>used a machine learning algorithm to recognise moving pedestrians, cars, vans, and cyclists and create counts of them</li>
<li>ran imputation algorithms on any missing data</li>
<li>aggregated those counts to the city level</li>
<li>put the counts into a storage database</li>
<li>periodically sent data from storage to statisticians at ONS to publish on the website (daily frequency data)</li>
</ul>
<p>Incredibly, this automatic cloud-based pipeline producing entirely new statistics with national urban coverage costs around £20 a day. To put this into context, and as best as I can determine from publicly available information, the Defra Environmental Survey costs ONS around £300 a day to run (averaged over a year). You can see the results for yourself in the figure below, <a href="https://datasciencecampus.ons.gov.uk/projects/estimating-vehicle-and-pedestrian-activity-from-town-and-city-traffic-cameras/">read about the project in more detail here</a>, <a href="https://github.com/datasciencecampus/chrono_lens">check out the code here</a>, or <a href="https://www.ons.gov.uk/economy/economicoutputandproductivity/output/datasets/trafficcameraactivity">download the stats here</a>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/cars_pandemic.svg" class="img-fluid figure-img" style="width:55.0%"></p>
<figcaption class="margin-caption">The activity of cars over the pandemic in six UK regions showing the timing of national lockdowns and the anticipatory effect.</figcaption>
</figure>
</div>
<p>It’s worth mentioning that this project would simply not have been possible without the use of cloud. Public sector institutions looking to get the most value from data science absolutely must empower their data scientists with cloud technologies. You can read more about unleashing the full productivity of data scientists with cloud <a href="../../../blog/posts/data-science-maturity/data-science-maturity.html">in this blog post</a>.</p>
<p>The traffic cameras project is a clear cut case of data science enabling something entirely new, in this case policy-relevant statistics.</p>
</section>
</section>
<section id="channels-for-data-science-to-have-impact" class="level2">
<h2 class="anchored" data-anchor-id="channels-for-data-science-to-have-impact">Channels for data science to have impact</h2>
<p>In this section, I look at exactly how the benefits of quality, savings, or new work happen, ie the channels through which data science can have impact. This is very much not comprehensive, but some main ones are:</p>
<ul>
<li><p><strong>information, to help people (the public, policymakers, whomever) make better decisions</strong>. The NHS app and the least cost grocery index are examples.</p></li>
<li><p><strong>supporting operational changes or procedures that will save money or improve welfare</strong>. Making operational changes is hard. One example, still in its early days, is improving the speed and accuracy of GDP statistics on public expenditure through the analysis of transparency declarations. You can read more about this work <a href="https://datasciencecampus.ons.gov.uk/exploring-trends-in-local-government-spending-through-transparency-declarations/">here</a>, but the bottom line is that expenditure by the public sector currently drops into the UK’s statistics office with a lag of around 9 to 12 months. By using transparency declarations, that is data on spending that is published by government departments and councils due to legislation, in addition to the usual collection methods, it might be possible to get that down to three months. The operation here is the assembly of national statistics. Other examples are helping to decide the placement of ambulances around rural areas to minimise response times, or deciding which <a href="https://arxiv.org/abs/1602.09067">buildings to prioritise for fire inspections</a> to minimise the chances of fires breaking out.</p></li>
<li><p><strong>teaching a person to understand data science so that they may go on and deliver benefits themselves</strong>. Clearly, if you teach 100 data scientists, and they all go out and do good, that’s going to be a bigger impact than if you just try and do everything yourself. At the Campus, we provided data and data science training of one form or another to 1000s of public sector workers a year. But it’s not just about teaching people to <em>do</em> data science, it’s also about helping senior leaders understand how they can use data science to achieve what they need to, and what sensible questions to ask of data or, indeed, data scientists. Many senior leaders will have heard of large language models by now, but they are far less likely to have heard of ETL (extract, transform, load) and automation tools that could have a much bigger impact, at least in the short run. My personal efforts in this space include <a href="https://aeturrell.github.io/coding-for-economists/intro.html">Coding for Economists</a> and <a href="https://aeturrell.github.io/python4DS/welcome.html">Python for Data Science</a>, aka Py4DS.</p></li>
</ul>
</section>
<section id="delivering-data-science" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="delivering-data-science">Delivering data science</h2>
<p>This is a bit more about projects in general than the previous sections: what can you do to ensure the delivery of a data science project? There are a few factors that I take into account when trying to judge.</p>
<section id="working-backwards" class="level3">
<h3 class="anchored" data-anchor-id="working-backwards">Working Backwards</h3>
<p>The first is to work backwards from the intended outcome, aka “working backwards”, as popularised by Amazon. In Amazon’s prescription, the steps are to:</p>
<ol type="1">
<li>Start by drafting the press release stating the outcomes you’ve achieved</li>
<li>Evaluate the opportunity—is it worth doing? (This goes back to the impact equation.)</li>
<li>Discover solutions and get stakeholder approval.</li>
<li>Build the high-level road map and identify themes.</li>
<li>Create the backlog and assign tasks.</li>
</ol>
<p>I think this is a good general guide but it’s also worth noting that some data science projects are highly exploratory or experimental, and it can be hard to have a roadmap or backlog up front. Uncertainty is fundamental in research. Amazon has certainly been able to use this model to innovate and deliver plenty though!</p>
</section>
<section id="talk-is-cheap" class="level3">
<h3 class="anchored" data-anchor-id="talk-is-cheap">Talk is cheap</h3>
<p>As part of evaluating the opportunity, I think it’s also good to ask: is the need plausible? Talk is cheap: quite often you’ll find folks saying they’re desperate for this or that data science project but they do have an incentive to get you to work on their thing rather than anyone else’s and you should question where those resources would really be best deployed (it could be in a project that no-one asked for). There are a few questions you can ask to sniff out how much of a priority a project really is for an instituion. Have other avenues been exhausted? Is there a maintenance plan in place? How long will it be used for? (That one goes back to the impact equation.) You need to be able to see the connection between the project and the outcome, and asking ‘how will this be used in practice?’ can illuminate the channels for the impact to happen. ‘How will it be used in practice?’ is particularly good at filtering out dashboards.</p>
</section>
<section id="feasibility" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="feasibility">Feasibility</h3>
<p>Feasibility is important too, and it’s not just a binary question—there are shades depending on what inputs will be available in addition to the core one, the labour of data scientists.</p>
<p>First, there’s often a very real question about whether the right data are available. It’s incredible what some organisations will spend on staff to then scrimp on data, even when they should in principle know about production functions. And the data don’t just need to exist, the permissions need to be in place. A data scientist’s strength is not in legal wrangling over data access, and you should clear such hurdles with the help of legal professionals in advance of a data scientist going anywhere near the project.</p>
<p>Likewise, organisations that spend huge sums on wages can skimp on capital, limiting the productivity of data scientists. <a href="https://twitter.com/TeraPauliina">Tera Allas</a>, Director of Research and Economics at McKinsey, has <a href="https://www.linkedin.com/posts/teraallas_productivityweek-dataisbeautiful-activity-7134895192649658370-DslF/">made this chart</a> showing how it’s a particular issue in the UK.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/data-science-with-impact/capital_stock_uk.jpeg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="margin-caption">Capital is important for the productivity of data scientists. Chart by Tera Allas.</figcaption>
</figure>
</div>
<p>It’s always wise to check what capital is available before agreeing to a project. For example, at the Campus, we would downrate anything that had to be done on a particular legacy system because data scientists working on it reported that everything took 20 or 30% longer as compared to the best alternative system. Lower productivity means fewer projects means less impact, not to mention frustrated staff. You can do some simple back-of-the-envelope estimates that strongly suggest that skimping on hardware for data scientists makes poor business sense.<sup>6</sup> Because of the constraints of most enterprise IT systems this effectively means that anything where data scientists are in control of their own software and hardware, eg on cloud, looks relatively much more attractive—you can simply get more done. In the case of cloud, the monetary costs could be <em>lower</em> than using traditional on-premises hardware, though it does depend on what you’re doing and how carefully you’re doing it.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;A note on that back-of-the-envelope argument for investing in better capital for data scientists. The hardware used in many public organisations looks, at best, like a 1TB SSD, 16GB RAM, i7 touch laptop or surface running Windows. A quick check shows that these come in at £1500 and £2200 respectively from a major provider. For our high-end laptop, we’ll go for a 14-inch M3-chip MacBook Pro that can run small large language models locally (!) and has 24GB of RAM plus a 1TB SSD, which costs £2300. This is more RAM but also <a href="https://www.howtogeek.com/865066/its-okay-to-buy-a-mac-with-only-8-gb-ram/">each GB of RAM is more performant in a Mac</a>. Let’s say the cheaper hardware has three incidents a day where something glitches, crashes, or goes slow enough to pause a workflow and, on average, this causes three minutes of lost time during each occurrence. Now, imagine the average data scientist costs a business £74k a year (with pension, National Insurance, etc, etc) and works 7.5 hours a day, so 65p per working minute. This makes the cost of that lost time £1480 per year, compared to spending £100 to £800 more to get the higher end laptop. That’s just one year too: as far as I can tell, mid-range laptops usually last around three years while higher end laptops last more like five years–with some <a href="https://www.businessinsider.com/guides/tech/how-long-do-laptops-last">reports suggesting Apple laptops last even longer than this</a>. So it’s worth it even before we add on the other costs of worse capital, such as poorer staff retention. At the Campus, we issued most staff with MacBooks.</p></div></div></section>
<section id="constraints-and-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="constraints-and-dependencies">Constraints and dependencies</h3>
<p>My point here about giving data scientists agency in the capital they use applies more generally too: what other constraints and dependencies are there? To state the obvious, optimisation under constraints is harder than optimisation. If there’s a constraint around using a particular system, it will be harder to have the same impact, all else equal. If there’s a critical dependency on another organisation over which you have is limited control, or if that org has limited incentives to help, it’s going to be harder to have impact than if the only dependencies are internal.</p>
<p>Dependencies can be a big problem in the public sector because there are frequently a very large number of stakeholders. Let’s say there are <img src="https://latex.codecogs.com/png.latex?N"> of them. Each big decision then needs to go through <img src="https://latex.codecogs.com/png.latex?N"> people, and a problem with a single stakeholder could hold up the entire project. If you have <img src="https://latex.codecogs.com/png.latex?M"> distinct decisions or changes in plan, you might be looking at as many as <img src="https://latex.codecogs.com/png.latex?N%20%5Ctimes%20M"> meetings simply to get a “yes” for everything in the best possible scenario. It’s even worse when there’s a web of dependencies. This simple arithmetic is one reason why it can be more efficient to gather stakeholders together at a single, regular event or even to just stick a website up and tell them to check it and report issues (if you have the luxury of talking about your project publicly while it’s still in train).</p>
<p>Apparently, Amazon worked hard to remove dependencies between teams to avoid this problem. Part of that was the Bezos Mandate that introduced APIs (find out more about APIs <a href="../../../blog/posts/the-prize-with-apis/the-prize-with-apis.html">here</a>) and service level agreements to reduce frictions in teams needing to liaise with one another just to get basic tasks done. The benefits of service interfaces go well beyond data scientists and it’s worth reading about the <a href="https://nordicapis.com/the-bezos-api-mandate-amazons-manifesto-for-externalization/">Bezos Mandate</a> if you haven’t come across it.</p>
</section>
<section id="potential-for-change" class="level3">
<h3 class="anchored" data-anchor-id="potential-for-change">Potential for change</h3>
<p>On a more strategic level, it’s important to ask: what genuine policy change or operational improvement will this result in? This is one of my great fears with dashboards. The information is beautifully presented to a decision-maker: so what? Do they have the power to actually make a change based on the new information?</p>
<p>Again, a more strategic point: will this problem still be the most important thing to work on by the time the project is complete? What we’re looking for here is some <em>time consistency</em>. The bruising nature of policy is that things move on <em>fast</em>, often faster than data science solutions can be put in place. Perhaps those solutions will be needed again in the future, and that should change the calculation. But there are going to be examples where the solution arrives too late to generate impact.</p>
</section>
<section id="incremental-delivery" class="level3">
<h3 class="anchored" data-anchor-id="incremental-delivery">Incremental delivery</h3>
<p>A major, major mistake I see repeated all the time in technology-leaning projects is trying to create a one-off, monolithic project will solve everything in one fell swoop. To see why this is a bad approach, imagine if, instead of trying to construct the world’s first computer to do basic arithmetic, the early engineers who built the ENIAC had decided to jump straight to building the latest smartphone. Inevitably, they would have failed. The knowledge of what works and what adds value in computing has been built up over decades of trial, error, and refinement.</p>
<p>The alternative that I believe delivers more impact overall is changing tack frequently in light of new information and chasing the highest value-add interventions first. To do this, projects need to be broken down into phases. You see it in software development all the time: add new feature, see if it helps, iron out bugs, repeat; You might even have developers working in separate branches of the same code base, making their contributions fully distinct and modular. At each phase, you have an opportunity to pause to re-evaluate the potential impact, to change course if necessary, or, and here’s the hardest part, to kill the project if you need to. It’s hard to stop projects before “completion” because we’re human and we get invested in the things we are doing. But sometimes it’s much better to acknowledge that it’s not going to deliver the way you thought, and to kill it in favour of moving onto more fertile ground. In particular, you want to avoid the situation where someone goes off for months and months without re-evaluating the project because the chances are that, despite their best intentions, they’ve veered off from the most impactful course.</p>
<p>There are some differences with data science that mean this approach is even more valuable. Lots of people don’t understand the strengths and weaknesses of data science, and how it can be most effectively be used: they might ask for something initially but gradually realise that another approach would serve them better. The fast paced nature of progress in data science also means it’s best to constantly re-evaluate.</p>
<p>In many ways, I’m arguing for an agile approach here, but it doesn’t have to be <a href="https://en.wikipedia.org/wiki/Agile_software_development">“Agile”</a> with a capital “A”. The point is that incremental delivery is—in most cases—the best way to wheedle your way to impact with a data science project.</p>
</section>
</section>
<section id="concluding-remarks" class="level2">
<h2 class="anchored" data-anchor-id="concluding-remarks">Concluding remarks</h2>
<p>Hopefully this has been a helpful deep dive into how best to have impact with data science but there’s a lot more that could be said on the topic, and I’d be delighted to read other thoughts if you have them!</p>


</section>


 ]]></description>
  <category>code</category>
  <category>python</category>
  <category>rstats</category>
  <category>data science</category>
  <category>public sector</category>
  <guid>https://www.aeturrell.com/blog/posts/data-science-with-impact/</guid>
  <pubDate>Mon, 13 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/data-science-with-impact/npv_cover.png" medium="image" type="image/png" height="40" width="144"/>
</item>
<item>
  <title>Why have a model registry?</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/why-have-a-model-registry/</link>
  <description><![CDATA[ 





<p>Many large institutions, including in the public sector, have a set of forecasts, predictions, or estimated statistical relationships (perhaps from a linear regression), that are key to their operations. In this post, I’ll run through how these institutions might benefit from a <em>model registry</em> of the kind that more digitally-savvy frontier firms are already using. And why, without one, an institution might be running <em>model risk</em> without even realising it.</p>
<p>If you’re not familiar with the idea of a <em>model registry</em>, it’s a service offered by all three major cloud providers (<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html">Amazon Web Services</a>, <a href="https://cloud.google.com/vertex-ai/docs/model-registry/introduction">Google Cloud Platform</a>, and <a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-models">Microsoft Azure Platform</a>) that allows you to lodge models in a (private) repository online. You can also custom build your own model registry (and much more) using the wonderful open source package <a href="https://mlflow.org/docs/latest">MLflow</a>.</p>
<section id="what-even-is-a-model" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-even-is-a-model">What even is a model?</h2>
<p>The word “model” is doing a lot of work here: it means a digital artefact that is (usually) trained on some data and which either contains coefficient estimates or can make predictions or both. A linear regression is an example of a model. In the data science world, it would usually mean a trained machine learning model that can make new predictions given new inputs. Perhaps the most commonly used file format for models is pickle, with extension <code>.pkl</code>.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Of course, I’m not naïve, I know people are out there building models in Excel. What I really mean is “the file format most commonly used by data professionals for models is pickle”. Today, almost undoubtedly, <code>.xlsx</code> is the most common file format for models but we’ll see why that’s not satisfactory.</p></div></div><p>Want to see an example of a simple model in code, and the command to save it to disk? Scroll down or click here.</p>
</section>
<section id="what-is-a-model-registry-and-why-do-i-need-it" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-is-a-model-registry-and-why-do-i-need-it">What is a <em>model registry</em> and why do I need it?</h2>
<p>If you’ve never come across one before, you can think of a model registry as a way to store, monitor, and log models and their properties. The pithiest description is that model registries do for models what GitHub and version control do for code. This metaphor goes quite far, as model registries also support a kind of <a href="https://wandb.ai/hamelsmu/model-registry/reports/What-is-CI-CD-for-Machine-Learning---VmlldzozNzk2NDg2">continuous integration</a> where performance metrics can be generated automatically on model upload.</p>
<p>You can easily imagine a situation where this could be helpful. Let’s say you’re working with a model that you’ve trained locally on your computer. Let’s also say that this model is critical to some decision, analysis, or operation that is happening in your institution. You might need to be able to collaborate with others on it: perhaps they will update it, perhaps they need to use it to make a prediction, or perhaps they just need to know that it exists because your institution is serious about keeping track of the critical models that are in use. One way of working is that the person who built the model does all of this, but then you’re squeezing everything through a key person if you do that—it could easily lead to problems. So, okay, you could share the model via a network drive or send it over email, but there are a bunch of problems with this too. Unless you’re sending it to everyone in the institution, email is pretty ineffective, and everyone is bad at manually doing version control through naming on a network drive. Plus, you have to find a way to make consistent model meta-data (eg on the pros and cons of that modelling approach) stay with the model file: good luck with that on a shared network drive!</p>
<p>Model registries solve the problem of securely storing, monitoring, tracking, and sharing models between people. The schematic below, from <a href="https://levelup.gitconnected.com/everything-you-need-to-know-about-model-registry-f7b978e84a1">this blog post</a>, gives a sense of what their components are. Note that “endpoints” are places where the model gets deployed such that it can make predictions. This could be an API, but another endpoint could simply be users downloading them and running them locally.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/why-have-a-model-registry/model_reg_img.png" class="img-fluid figure-img" style="width:100.0%" alt="Schematic of a model registry."></p>
<figcaption class="margin-caption">Schematic of a model registry.</figcaption>
</figure>
</div>
<p>Reasons you might want to use a model registry include:</p>
<ul>
<li>you want to have a central set of approved models that are logged. No more tracking models separately and inconsistently, via, say a spreadsheet—in a model registry, the log of models <em>is</em> the set of models.</li>
<li>you want to have meta-data about the model that is entwined with the model. Some basic meta-data, like the format of inputs and outputs, and even on performance, is usually included. This can be extended with information on a model’s limitations, strengths, and performance via something called a <a href="https://huggingface.co/docs/hub/model-cards">model card</a>. For example, you can <a href="https://aws.amazon.com/blogs/machine-learning/integrate-amazon-sagemaker-model-cards-with-the-model-registry/">link model cards with models in the Amazon SageMaker model registry</a>. You can <a href="https://modelcards.withgoogle.com/object-detection#overview">see an example model card for one of Google’s models here</a>. Model cards are a bit new but there is progress toward a consistent schema <a href="https://github.com/tensorflow/model-card-toolkit">in this toolkit</a>, which has an example based on classifying incomes in the census.</li>
<li>you want to be able to reproduce model results. Version controlling models in a registry buys you this.</li>
<li>you want to be able to know what you would have predicted in the past. For models, reproducibility across time can be essential to an institution: it’s not too much of a stretch to imagine there’s an enquiry or review where it is necessary to reproduce the exact model output that you had from a particular date.</li>
<li>you want to track the performance of a model over time. This is another advantage of versioning, and makes a task like assessing the quality of forecasts over time go from being a rum game of chasing down people, emails, and files to being as simple as running a short script.</li>
<li>you want others to be able to use your models. If there’s another team who rely on running your models, they no longer have to email you to ask—they just grab the latest version from the registry, and run it themselves. (Alternatively, the model <a href="../../../blog/posts/build-a-cloud-api/build-a-cloud-api.html">can be deployed to an API</a> where anyone in the institution can ping it for a prediction.)</li>
<li>you want to control access to the model. Sometimes, institutions need to provide different levels of access to different models, and model registries make this very possible, and at as granular a level as you like.</li>
<li>you want to make your models discoverable. This is a killer application. Models on network drives are not very discoverable, and their meta-data even less so. Model registries are designed to help people find the model they need.</li>
<li>you want to know how many people are using models, or do other auditing. Model registries are typically hosted, and the hosting service counts what is happening.</li>
<li>you want to automate reports about the number of models, their performance, how often they are used or updated, and so on. Once code is involved, everything becomes automatable!</li>
<li>you want to host models for free! Yes, just storing models in a registry is free for most cloud providers. (Other actions, such as deploying models to endpoints, do cost though.)</li>
<li>you want to make sure that you’re all using the same model. When you load a model from a registry, you pull it <em>directly</em> from the cloud repository—so there’s no chance of you accidentally changing a version that you’ve downloaded to your own machine and running something that’s inconsistent with the online version.</li>
</ul>
<p><em>Not</em> having some of these features comes with significant <em>model risk</em>. By model risk, I mean risks relating to models such as not knowing which model or model version was used in a particular decision or at a particular time, losing track of key models, people having access to sensitive models that they shouldn’t, not realising that a model’s performance has significantly degraded, and being unable to reproduce results that were used in critical decision making.</p>
<p>I said I would come back to models in Excel. In principle, you might (?) be able to store Excel models in a model registry and get some of these benefits (some, but definitely not all: you can’t deploy Excel to an API endpoint, for example, or use it with continuous integration). But Excel comes with so many other issues, I really don’t think you should. Some of the big ones are that they bundle code and data and model together, so you lose all the (not addressed in this post) benefits of version control, you lose control of data (very explicitly—<a href="https://www.nature.com/articles/d41586-021-02211-4">Excel changes your data</a>), and the code is repeated across cells, which makes some errors more likely.<sup>2</sup> The bottom line is that if the model is doing anything important, it shouldn’t be in a spreadsheet.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;The classic examples are not pulling a formula down to cover all rows or columns and hard-pasting numbers over formula cells.</p></div></div></section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>If your institution relies on models in any way that’s even vaguely critical, it’s hard to see why you wouldn’t want most of the functionality of a model registry or the attendant reduction in risks it can provide. Additionally, this is pretty cheap (or even free), and, because cloud services are scriptable, very automatable, so it’s plausible that the extra functionality comes along with a <em>boost</em> in productivity. Model behaviour indeed!</p>
</section>
<section id="technical-appendix" class="level2">
<h2 class="anchored" data-anchor-id="technical-appendix">Technical Appendix</h2>
<section id="a-simple-model-in-code-as-an-example" class="level3">
<h3 class="anchored" data-anchor-id="a-simple-model-in-code-as-an-example">A simple model in code as an example</h3>
<p>The simplest model you can think of is something like the below, where we feed some data on the miles per gallon of cars into a regression.</p>
<div id="46843257" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"></span>
<span id="cb1-3">mpg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(</span>
<span id="cb1-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv"</span>,</span>
<span id="cb1-5">    dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mpg"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hp"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"disp"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cyl"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"category"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wt"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>},</span>
<span id="cb1-6">)</span>
<span id="cb1-7">mpg.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rownames</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">cyl</th>
<th data-quarto-table-cell-role="th">disp</th>
<th data-quarto-table-cell-role="th">hp</th>
<th data-quarto-table-cell-role="th">drat</th>
<th data-quarto-table-cell-role="th">wt</th>
<th data-quarto-table-cell-role="th">qsec</th>
<th data-quarto-table-cell-role="th">vs</th>
<th data-quarto-table-cell-role="th">am</th>
<th data-quarto-table-cell-role="th">gear</th>
<th data-quarto-table-cell-role="th">carb</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Mazda RX4</td>
<td>21.0</td>
<td>6</td>
<td>160.0</td>
<td>110.0</td>
<td>3.90</td>
<td>2.620</td>
<td>16.46</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Mazda RX4 Wag</td>
<td>21.0</td>
<td>6</td>
<td>160.0</td>
<td>110.0</td>
<td>3.90</td>
<td>2.875</td>
<td>17.02</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Datsun 710</td>
<td>22.8</td>
<td>4</td>
<td>108.0</td>
<td>93.0</td>
<td>3.85</td>
<td>2.320</td>
<td>18.61</td>
<td>1</td>
<td>1</td>
<td>4</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Hornet 4 Drive</td>
<td>21.4</td>
<td>6</td>
<td>258.0</td>
<td>110.0</td>
<td>3.08</td>
<td>3.215</td>
<td>19.44</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Hornet Sportabout</td>
<td>18.7</td>
<td>8</td>
<td>360.0</td>
<td>175.0</td>
<td>3.15</td>
<td>3.440</td>
<td>17.02</td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now we can fit a linear model, <code>lin_model</code>.</p>
<div id="57cf7651" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.formula.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> smf</span>
<span id="cb2-3"></span>
<span id="cb2-4">lin_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> smf.ols(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mpg ~ hp + C(cyl) + wt -1"</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mpg).fit()</span></code></pre></div>
</div>
<p>This has a predict method, accessed via <code>lin_model.predict()</code>.</p>
<p>Okay, <em>here’s the important bit</em>: to save this model locally on your computer (ready to upload to a model registru), it would be <code>lin_model.save("lin_reg_model.pkl")</code>.</p>
<p>For this particular package, <strong>statsmodels</strong>, you can see a summary of the underlying model using <code>.summary()</code></p>
<div id="6f85d2b8" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">lin_model.summary()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<table class="simpletable caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<caption>OLS Regression Results</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Dep. Variable:</td>
<td>mpg</td>
<td data-quarto-table-cell-role="th">R-squared:</td>
<td>0.857</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Model:</td>
<td>OLS</td>
<td data-quarto-table-cell-role="th">Adj. R-squared:</td>
<td>0.836</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Method:</td>
<td>Least Squares</td>
<td data-quarto-table-cell-role="th">F-statistic:</td>
<td>40.53</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Date:</td>
<td>Tue, 18 Mar 2025</td>
<td data-quarto-table-cell-role="th">Prob (F-statistic):</td>
<td>4.87e-11</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Time:</td>
<td>10:43:18</td>
<td data-quarto-table-cell-role="th">Log-Likelihood:</td>
<td>-71.235</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">No. Observations:</td>
<td>32</td>
<td data-quarto-table-cell-role="th">AIC:</td>
<td>152.5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Df Residuals:</td>
<td>27</td>
<td data-quarto-table-cell-role="th">BIC:</td>
<td>159.8</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Df Model:</td>
<td>4</td>
<td data-quarto-table-cell-role="th"></td>
<td></td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Covariance Type:</td>
<td>nonrobust</td>
<td data-quarto-table-cell-role="th"></td>
<td></td>
</tr>
</tbody>
</table>


<table class="simpletable caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td></td>
<td data-quarto-table-cell-role="th">coef</td>
<td data-quarto-table-cell-role="th">std err</td>
<td data-quarto-table-cell-role="th">t</td>
<td data-quarto-table-cell-role="th">P&gt;|t|</td>
<td data-quarto-table-cell-role="th">[0.025</td>
<td data-quarto-table-cell-role="th">0.975]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">C(cyl)[4]</td>
<td>35.8460</td>
<td>2.041</td>
<td>17.563</td>
<td>0.000</td>
<td>31.658</td>
<td>40.034</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">C(cyl)[6]</td>
<td>32.4870</td>
<td>2.811</td>
<td>11.555</td>
<td>0.000</td>
<td>26.718</td>
<td>38.256</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">C(cyl)[8]</td>
<td>32.6601</td>
<td>3.835</td>
<td>8.516</td>
<td>0.000</td>
<td>24.791</td>
<td>40.530</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">hp</td>
<td>-0.0231</td>
<td>0.012</td>
<td>-1.934</td>
<td>0.064</td>
<td>-0.048</td>
<td>0.001</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">wt</td>
<td>-3.1814</td>
<td>0.720</td>
<td>-4.421</td>
<td>0.000</td>
<td>-4.658</td>
<td>-1.705</td>
</tr>
</tbody>
</table>


<table class="simpletable caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Omnibus:</td>
<td>2.972</td>
<td data-quarto-table-cell-role="th">Durbin-Watson:</td>
<td>1.790</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Prob(Omnibus):</td>
<td>0.226</td>
<td data-quarto-table-cell-role="th">Jarque-Bera (JB):</td>
<td>1.864</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Skew:</td>
<td>0.569</td>
<td data-quarto-table-cell-role="th">Prob(JB):</td>
<td>0.394</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Kurtosis:</td>
<td>3.320</td>
<td data-quarto-table-cell-role="th">Cond. No.</td>
<td>1.90e+03</td>
</tr>
</tbody>
</table>
<br><br>Notes:<br>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br>[2] The condition number is large, 1.9e+03. This might indicate that there are<br>strong multicollinearity or other numerical problems.
</div>
</div>
</section>
<section id="creating-and-working-with-a-model-registry" class="level3">
<h3 class="anchored" data-anchor-id="creating-and-working-with-a-model-registry">Creating and working with a model registry</h3>
<p>It’s simpler than you might think to get started with a model registry; you can find the instructions for <a href="https://cloud.google.com/vertex-ai/docs/start/cloud-environment">Google Cloud’s Vertex AI model registry here</a>, for <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html">Amazon’s SageMaker registry here</a>, for <a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-machine-learning-registries-mlops?view=azureml-api-2">Microsoft’s Azure Machine Learning here</a>, and for the <a href="https://mlflow.org/docs/latest/model-registry.html#">MLflow model registry here</a>.</p>
<p>Once you’ve created a model registry, you can upload a model in a number of ways. Most providers give you at least three ways:</p>
<ul>
<li>through a user interface, manually</li>
<li>via a command line interface</li>
<li>via a Python package</li>
</ul>
<p>For example, once you’ve done the initial settings, <a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-models?view=azureml-api-2&amp;tabs=python%2Cuse-local#register-your-model-as-an-asset-in-machine-learning-by-using-the-sdk">uploading a model to Azure’s model registry</a> is achieved using their Python package via</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> azure.ai.ml.entities <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Model</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> azure.ai.ml.constants <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AssetTypes</span>
<span id="cb4-3"></span>
<span id="cb4-4">file_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Model(</span>
<span id="cb4-5">    path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model.pkl"</span>,</span>
<span id="cb4-6">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>AssetTypes.CUSTOM_MODEL,</span>
<span id="cb4-7">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"local-file-example"</span>,</span>
<span id="cb4-8">    description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model created from local file."</span>,</span>
<span id="cb4-9">)</span>
<span id="cb4-10">ml_client.models.create_or_update(file_model)</span></code></pre></div>
<p>Although you can search for models in the user interface (see below for an example from Google), you can also search all models programmatically too. For example, in Azure, this is as simple as <code>client.search_registered_models(order_by=["name ASC"])</code>.</p>
<p>Loading models from the registry into your local workspace is similarly simple using, say, MLflow on Azure: <code>model = mlflow.pyfunc.load_model(f"models:/{model_name}/Staging")</code>. You can also deploy models online to an endpoint and query that too, and this is how the cloud providers typically assume you will use registered models.</p>
<section id="model-cards" class="level4">
<h4 class="anchored" data-anchor-id="model-cards">Model cards</h4>
<p>It’s fair to say that Amazon is ahead on model cards, with Google not having introduced them on their cloud service yet and Microsoft offering something that’s slightly different. You can <a href="https://aws.amazon.com/blogs/machine-learning/integrate-amazon-sagemaker-model-cards-with-the-model-registry/">find out how to link models on Amazon with model cards here for AWS</a>, and, as you’d expect, there’s a way to <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-cards-create.html">programmatically upload this info using Python</a>.</p>
</section>
</section>
</section>
<section id="an-example-of-a-model-registry" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="an-example-of-a-model-registry">An example of a model registry</h2>
<p>The image below shows a view of a model registry in Google’s model registry, Vertex AI.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/why-have-a-model-registry/list_view_google_mr.jpg" class="img-fluid figure-img" style="width:100.0%" alt="A Google model registry with some models in."></p>
<figcaption class="margin-caption">Screenshot showing the model registry page on Vertex AI.</figcaption>
</figure>
</div>
<p>You can see high level information such as the name, number of versions, default version, deployment status, and type. If you click through to one of those models, you get a more detailed view.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/why-have-a-model-registry/single_model_view_google_mr.jpg" class="img-fluid figure-img" style="width:100.0%" alt="A single model's page in a Google model registry."></p>
<figcaption class="margin-caption">Screenshot showing a single model’s page in a Google model registry.</figcaption>
</figure>
</div>
<p>This view shows the labels applied to each version of a specific model, and more. One of the great features of a model registry is that performance can be automatically assessed (“continous integration”).</p>
<p>The image below shows an example of some metrics of this that live <em>within</em> the model registry:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/why-have-a-model-registry/performance_view_google_mr.jpg" class="img-fluid figure-img" style="width:100.0%" alt="A single model's performance metrics in Google model registry."></p>
<figcaption class="margin-caption">Screenshot showing a single model’s performance metrics in Google model registry.</figcaption>
</figure>
</div>
<section id="metadata" class="level3">
<h3 class="anchored" data-anchor-id="metadata">Metadata</h3>
<p>Just as an example, here are some meta-data that might be associated with a model</p>
<pre class="text"><code>artifact_path: classifier
flavors:
  fastai:
    data: model.fastai
    fastai_version: 2.4.1
  python_function:
    data: model.fastai
    env: conda.yaml
    loader_module: mlflow.fastai
    python_version: 3.8.12
model_uuid: e694c68eba484299976b06ab9058f636
run_id: e13da8ac-b1e6-45d4-a9b2-6a0a5cfac537
signature:
  inputs: '[{"type": "tensor",
             "tensor-spec": 
                 {"dtype": "uint8", "shape": [-1, 300, 300, 3]}
           }]'
  outputs: '[{"type": "tensor", 
              "tensor-spec": 
                 {"dtype": "float32", "shape": [-1,2]}
            }]'</code></pre>


</section>
</section>


 ]]></description>
  <category>code</category>
  <category>open-source</category>
  <category>cloud</category>
  <category>data science</category>
  <guid>https://www.aeturrell.com/blog/posts/why-have-a-model-registry/</guid>
  <pubDate>Thu, 12 Oct 2023 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/why-have-a-model-registry/model_reg_img.png" medium="image" type="image/png" height="55" width="144"/>
</item>
<item>
  <title>Building an API in the cloud in fewer than 200 lines of code</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/build-a-cloud-api/build-a-cloud-api.html</link>
  <description><![CDATA[ 





<p>Cloud tools and Python packages have become so powerful that you can build a (scalable) cloud-based API in fewer than 200 lines of code. In this blog post, you’ll see how to use Google Cloud, Terraform, and FastAPI to deploy a queryable data API on the cloud.</p>
<p>The repository associated with this project <a href="https://github.com/aeturrell/deploy-api">can be found here</a> should you wish to try this for yourself.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/build-a-cloud-api/run_using_data.png" class="img-fluid figure-img" style="width:30.0%" alt="Image showing JSON returned by API."></p>
<figcaption class="margin-caption">An example of the API created in this blog post returning data.</figcaption>
</figure>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>The basic idea here is: create an image of a computer that serves up an API, stick it on a scalable cloud function, and let it rip so that anyone can query it.</p>
<p>Why might you want to deploy an API? I <a href="../../../blog/posts/the-prize-with-apis/the-prize-with-apis.html">covered this in a previous blog post</a> and the short answer is that they’re awesome at servicing data or prediction requests in an efficient way.</p>
<p>First, some caveats. I’m only counting lines of code for the API and the cloud infrastructure, not for the extraction and transform of the data we’ll be serving up. ie, this doesn’t count the code that creates the data, which is in the <code>etl</code> folder. This seems fair: I happened to pick a dataset that needed a bit of “E” and “T” love before being usable, but I could have started with any old dataset. Second: if you’re going to follow this and create your own scalable cloud API, you will need a Google Cloud account with the billing setup (or some free credits). Finally, be very careful not to share your cloud keys or your real terraform variable names if you are following this tutorial on a public repo. I’ve added the relevant files to the <code>.gitignore</code> file for those cloning the repo but you should be as cautious as ever when dealing with secrets that should not be shared publicly.</p>
<p>Okay, let’s look at the technologies we’re going to use.</p>
<section id="google-cloud-platform" class="level3">
<h3 class="anchored" data-anchor-id="google-cloud-platform">Google Cloud Platform</h3>
<p>Google Cloud Platform (GCP) provides a whole suite of cloud services, and is one of the major providers. It seems to have been made for data scientists, and has a great command line interface. The specific GCP components we’ll be using are:</p>
<ul>
<li>an image registry, to store the image of a computer than can serve up data via an API</li>
<li>Google Cloud Run, which actually serves up the computer image</li>
</ul>
<p>It’s worth nothing that Cloud Run is serverless, which means you don’t have to fiddle with back-end resources to run applications. It can scale up or down as needed. Essentially, Google are handling the back-end stuff so you don’t have to. Like any tech, it has its limitations, but it’s a great choice for a simple, pain-free API deployment based on a container.</p>
</section>
<section id="terraform" class="level3">
<h3 class="anchored" data-anchor-id="terraform">Terraform</h3>
<p>As cloud platforms have proliferated, there’s a danger of getting back to point-and-click interfaces, problems with reproducibility, vendor lock-in, and other things we try to avoid as data scientists. Terraform is a tool that helps you do “infrastructure as code”, ie to build, change, and version control cloud resources safely and efficiently. One of the advantages is, once you have specified it once, you can re-use a Terraform plan to create the same infrastructure again down the line.</p>
</section>
<section id="python-and-fastapi" class="level3">
<h3 class="anchored" data-anchor-id="python-and-fastapi">Python and FastAPI</h3>
<p>FastAPI is a Python package for building APIs that has a whole range of benefits:</p>
<ul>
<li>Very high performance.</li>
<li>Fast to code with fewer bugs, as picks up type hints and makes use of decorators.</li>
<li>Full code completion support.</li>
<li>Automatically creates interactive documentation.</li>
<li>Based on (and fully compatible with) the open standards for APIs: OpenAPI (previously known as Swagger) and JSON Schema.</li>
</ul>
<p>Let’s see an example of some of this good stuff. First, the API endpoint is incredibly simple to create. Say we have a dataframe, <code>df</code>, which has the data we’d like to serve in. To turn a Python function that serves up data according to particular cuts into an API we need only add a decorator, an <code>async</code> statement, and add type hints. Here’s a simplified version of the example that gets built through the rest of this blog post:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.get</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/year/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{year}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/geo_code/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{geo_code}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb1-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> read_item(year: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, geo_code: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb1-3">    json_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.loc[</span>
<span id="cb1-4">        (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> year) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"geo_code"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> geo_code), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"deaths"</span></span>
<span id="cb1-5">    ].to_dict()</span>
<span id="cb1-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>: year, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"geo_code"</span>: geo_code, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data"</span>: json_data}</span></code></pre></div>
<p>This simple declaration buys us a lot. If you hit the API endpoint from this repo with this query: <code>/year/notanumber/geo_code/E08000007</code>, ie a valid geographic code but year is not an integer, then <strong><a href="https://docs.pydantic.dev/latest/">pydantic</a></strong> data validation checks are automatically run and return the following error message to the user:</p>
<pre class="text"><code>{
  "detail": [
    {
      "type": "int_parsing",
      "loc": [
        "path",
        "year"
      ],
      "msg": "Input should be a valid integer, unable to parse string as an integer",
      "input": "notanumber",
      "url": "https://errors.pydantic.dev/2.4/v/int_parsing"
    }
  ]
}</code></pre>
<p>The API knows you didn’t pass a valid integer! The <code>year: int</code> part of the function declaration determines that any input to the year segment of the API must be an integer.</p>
<p>Okay, with a bit of context out of the way, let’s now walkthrough building an API. All of <a href="https://github.com/aeturrell/deploy-api">the code is available here</a>.</p>
</section>
</section>
<section id="initial-setup" class="level2">
<h2 class="anchored" data-anchor-id="initial-setup">Initial Setup</h2>
<section id="code-installs" class="level3">
<h3 class="anchored" data-anchor-id="code-installs">Code Installs</h3>
<p>Download and install <a href="https://developer.hashicorp.com/terraform/downloads"><strong>terraform</strong></a>. Do the same for <a href="https://python-poetry.org/"><strong>poetry</strong></a> and ensure you have a Python installation (this tutorial uses Python 3.10 and that version is baked into the <code>pyproject.toml</code> file that <strong>poetry</strong> uses—<a href="https://github.com/aeturrell/deploy-api/blob/main/pyproject.toml">link here</a>).</p>
</section>
<section id="create-a-google-project" class="level3">
<h3 class="anchored" data-anchor-id="create-a-google-project">Create a Google Project</h3>
<p>Get a <a href="https://console.cloud.google.com/">Google Cloud Account</a>.</p>
<p>Ensure you have the <a href="https://cloud.google.com/sdk/docs/install-sdk">Google CLI installed</a> and authenticated: once you have downloaded and installed it, run <code>gcloud init</code> to set it up. Then run <code>gcloud auth login</code> to ensure you are logged into your account. With these steps done, you can make changes to your Google Cloud account from the command line.</p>
<p>We’re now going to create a project on the command line.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">gcloud</span> projects create YOUR-PROJECT-ID</span></code></pre></div>
<p>You may wish to add some numbers to the end of the project name to ensure it is unique, as most obvious names are already taken (and, if a name is taken, project creation will fail). (Note that you will need to set the same project ID in your <code>terraform.tfvars</code> file, which we’ll come to later.)</p>
<p>Next up, switch the Google Cloud CLI to use this specific project:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">gcloud</span> config set project YOUR-PROJECT-ID</span></code></pre></div>
<p>Now we have to go to the <a href="https://console.cloud.google.com/">Google Cloud Console</a>. Navigate to the relevant project, and then create a new Service Account under IAM. The current <a href="https://console.cloud.google.com/iam-admin/serviceaccounts">URL is here</a>. A service account can be used to manage access to Google Cloud services.</p>
<p>In the new service account, click on Actions then Manage keys. Create a new key and download it as a JSON file—do not put it under version control! If you’re following this tutorial by cloning the <a href="https://github.com/aeturrell/deploy-api">associated repo</a>, you can put it in the <code>secrets</code> subdirectory with the name <code>google_key.json</code> because the contents of the <code>secrets</code> folder are not under version control—but always, always double check.</p>
<p>If you haven’t already, you’ll also need to set up billing, which can be found under Billing in the left-hand side navigation pane. For me, the cost of setting this up was less than 1 pence.</p>
</section>
<section id="terraforming-google-cloud-components" class="level3">
<h3 class="anchored" data-anchor-id="terraforming-google-cloud-components">Terraforming Google Cloud Components</h3>
<p>Terraform is a cross-cloud way of specifying resources. We’re going to use it enable a couple of cloud APIs and name an Artifact Registry. (This registry is eventually where we will push a docker image of our app.)</p>
<p><code>main.tf</code> is the main terraform file (<a href="https://github.com/aeturrell/deploy-api/blob/main/main.tf">link here</a>). It lists the API services that we’ll use from Google, gives them names, and also enables them too. There are a few distinct blocks:</p>
<ol type="1">
<li>terraform metadata</li>
<li>provider region and project information</li>
<li>a block representing the container registry API</li>
<li>(last two blocks) code that enables the registry and cloud run APIs</li>
</ol>
<p>One of the slightly confusing things about terraform is that it works out what order to apply these changes in itself, so we don’t have to worry about the fact that the blocks enabling APIs come after the blocks creating new resources under specific APIs.</p>
<p><code>.terraform.version</code> contains the version of terraform you’re using (run <code>terraform --version</code> to check).</p>
<p><code>variables.tf</code> provides meta-data on the variables needed in your project (<a href="https://github.com/aeturrell/deploy-api/blob/main/variables.tf">link here</a>).</p>
<p>In an extra file, that is not included in this repo and which shouldn’t be public, called <code>terraform.tfvars</code>, put the actual names of your Google Cloud Project variables. The contents will look like this:</p>
<pre class="text"><code>#  GCP settings
project_id = "YOUR PROJECT ID"
region = "YOUR REGION"

#  Artifact registry
registry_id = "YOUR ARTIFACT REGISTRY NAME"</code></pre>
<p>There should be an entry in this file for every variable in the <code>variables.tf</code> file.</p>
<p>Now run <code>terraform init</code>. If successful, you should see a message saying “Terraform has been successfully initialized!”.</p>
<p>Next, run <code>terraform plan</code>, which will think through what you’ve asked for in <code>main.tf</code>.</p>
<p>Finally, to create the GCP resources, it’s <code>terraform apply</code>. If successful, you will see a message saying: “Apply complete! Resources: 3 added, 0 changed, 0 destroyed.”</p>
<p>An alternative to using the last block of <code>main.tf</code> to enable the APIs is to use the Google Cloud CLI.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">gcloud</span> services enable artifactregistry.googleapis.com</span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">gcloud</span> services enable run.googleapis.com</span></code></pre></div>
<p>You can check what services you have enabled with <code>gcloud services list --enabled</code>. If you’re doing a huge project and want to filter, you can of course <code>grep</code> your way to the info you’re interested in, eg <code>gcloud services list --enabled | grep run</code> to check whether <code>run.googleapis.com</code> is on the list.</p>
</section>
</section>
<section id="python-and-the-api" class="level2">
<h2 class="anchored" data-anchor-id="python-and-the-api">Python and the API</h2>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>Run <code>poetry config virtualenvs.in-project true</code> to make virtual environments be installed in the local project folder.</p>
<p>Run <code>poetry install</code> to install the Python env. If this has worked, you’ll see a <code>.venv</code> folder appear and, if you’re using it, Visual Studio Code might ask if you want to use the newly created environment for executing Python code. (Note that <code>poetry config virtualenvs.in-project true</code> doesn’t always play nicely with conda; there’s an <a href="https://github.com/python-poetry/poetry/issues/4055">open Poetry issue about this</a> but it <em>did</em> seem to work when in the <code>base</code> environment of conda.)</p>
<p>To try and help achieve high code quality, this repository uses <code>pre-commit</code>. You can run this using <code>poetry run pre-commit run --all-files</code>. As this is not essential, and the associated specification of packages isn’t really code, I didn’t include the file that specifies the pre-commit checks, <code>.pre-commit-config.yaml</code>, in the count of the number of lines of code.</p>
</section>
<section id="prepping-the-data" class="level3">
<h3 class="anchored" data-anchor-id="prepping-the-data">Prepping the data</h3>
<p>You can choose any small dataset you like here. In this case, because it’s more fun, I stitched together some data on deaths that was scattered across Excel files in a weird format for the API to serve up. You can <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/monthlyfiguresondeathsregisteredbyareaofusualresidence">find the original data files here</a>. For larger datasets, you’d want to do a “load” (the “L” in “ETL”) step too, and have the data live in a GCP database that gets queried by the API.</p>
<p>NB: the data are not included in the repo, you’ll need to run the Python scripts yourself!</p>
<p>There are a few Python scripts in a folder called <code>etl</code>. These perform the following functions:</p>
<ul>
<li><code>etl/extract.py</code> — downloads deaths data by geography from this ONS page, which has Excel files for each year. The script downloads them all. <a href="https://github.com/aeturrell/deploy-api/blob/main/etl/extract.py">Link</a>.</li>
<li><code>etl/transform.py</code> - this takes downloaded files, opens them, finds the relevant sheets, cleans them, and stacks them in a tidy format in a parquet file. <a href="https://github.com/aeturrell/deploy-api/blob/main/etl/transform.py">Link</a>. Challenges are:
<ul>
<li>Worksheet names change over time</li>
<li>File formats change (the file extension)</li>
<li>New data may be added in a new file, if the new data refer to January, or added into an existing file, if the month they refer to is not January</li>
</ul></li>
<li><code>etl/main.py</code> — this is a script that calls the extract and transform scripts in order to create the final dataset, <code>scratch/deaths_data.parquet</code>. <a href="https://github.com/aeturrell/deploy-api/blob/main/etl/main.py">Link</a>.</li>
</ul>
<p>To create the data we’ll be serving up later, it’s</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">poetry</span> run python etl/main.py</span></code></pre></div>
</section>
<section id="launching-the-api-locally-optional" class="level3">
<h3 class="anchored" data-anchor-id="launching-the-api-locally-optional">Launching the API locally (optional)</h3>
<p>To use FastAPI locally to serve up your API and check it works, you’ll need to have installed the Python environment (via <strong>poetry</strong>)</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">poetry</span> run uvicorn app.api:app <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--reload</span></span></code></pre></div>
<p>where app is the folder, <code>api.py</code> is the script, and app is the FastAPI application defined in <code>api.py</code>. This serves up an API in the form: <code>/year/{YEAR-OF-INTEREST}/geo_code/{GEO-CODE-OF-INTEREST}</code>. For example, if FastAPI is running on <a href="http://0.0.0.0:8080">http://0.0.0.0:8080</a>, then <a href="http://0.0.0.0:8080/year/2021/geo_code/E08000007">http://0.0.0.0:8080/year/2021/geo_code/E08000007</a> would serve up the 2021 deaths data for Stockport (which has UK local authority geographic code E08000007). You can also try <a href="http://0.0.0.0:8080/docs">http://0.0.0.0:8080/docs</a> to see how you get automatic interactive docs for free with FastAPI!</p>
</section>
</section>
<section id="deploying-the-api-to-the-cloud" class="level2">
<h2 class="anchored" data-anchor-id="deploying-the-api-to-the-cloud">Deploying the API to the cloud</h2>
<p>We already enabled the Cloud Run API using terraform. The plan now is: build a docker container with everything needed to serve up the API in, build the docker file into an image, upload the image to the artifact registry we created on Google Cloud, and then serve the API on Google Cloud Run. First, we need to ensure our env is reproducible in a docker file.</p>
<section id="building-the-docker-image" class="level3">
<h3 class="anchored" data-anchor-id="building-the-docker-image">Building the docker image</h3>
<p>You can make <strong>poetry</strong> (which this project uses) work in docker files but it can go wrong, so it’s easier to run:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">poetry</span> export <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> requirements.txt <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output</span> requirements.txt</span></code></pre></div>
<p>And have the docker file use the <code>requirements.txt</code>. Note that, because of this method of prepping the docker file, <code>requirements.txt</code> has been added to the <code>.gitignore</code> file. This follows the single source of truth rule: if we keep <code>requirements.txt</code> and <code>pyproject.toml</code> under version control simultaneously, it creates confusion as to which defines the environment. In this approach, it’s clear: <code>pyproject.toml</code> sets out the Python dependencies and <code>requirements.txt</code> is downstream of that.</p>
<p>Note that the dockerfile is just 16 lines of code and only includes the absolute bare minimum required to run the API.</p>
<p>Also note that the name <code>deaths_data.parquet</code> is hard-coded in the dockerfile. There’s probably a way to get it to pull the name of the data file from the <code>config.toml</code> file where it’s defined, but let’s keep things simple.</p>
</section>
<section id="testing-the-containerised-api-locally-optional" class="level3">
<h3 class="anchored" data-anchor-id="testing-the-containerised-api-locally-optional">Testing the containerised API locally (optional)</h3>
<p>You can check that your Dockerfile works locally first if you wish. To do this, run</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">docker</span> build <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--pull</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dockerfile"</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-t</span> deploy-api:latest <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"."</span></span></code></pre></div>
<p>to build it and then</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">docker</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-it</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-p</span> 8080:8080/tcp deploy-api:latest</span></code></pre></div>
<p>to run it. You should get a message in the terminal that includes a HTTP address that you can go to (this isn’t really on the internet… it’s coming from inside the house!). Click on that and you should see your API load up. For example, if it’s on <a href="http://0.0.0.0:8080">http://0.0.0.0:8080</a> head to <a href="http://0.0.0.0:8080/docs">http://0.0.0.0:8080/docs</a> to check that the docs have loaded and try out the API.</p>
</section>
<section id="building-the-docker-image-for-google-cloud-run" class="level3">
<h3 class="anchored" data-anchor-id="building-the-docker-image-for-google-cloud-run">Building the docker image for Google Cloud Run</h3>
<p>Now we run into a complication. I’m using a Mac, which is on arm64 architecture, aka Apple Silicon. Most cloud services are Linux-based, which typically use amd64 chips. Naively building an image locally, and pushing it to Google Cloud, would result in an image that won’t actually run on Google’s architecture. So we need to use a multi-platform build, or just build to target a specific architecture. (Docker is supposed to solve this kind of problem, and it does, with a bit more effort.)</p>
<p>You need to use</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">docker</span> buildx create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> mybuilder <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--bootstrap</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--use</span></span></code></pre></div>
<p>to create a builder to take on image construction. Then, the magic command to build the image and push it to your google repo is:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">docker</span> buildx build <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--file</span> Dockerfile <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb13-2">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--platform</span> linux/amd64 <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb13-3">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--builder</span> mybuilder <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb13-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--progress</span> plain <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb13-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--build-arg</span> DOCKER_REPO=REGION-docker.pkg.dev/PROJECT-ID/REPOSITORY-NAME/ <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb13-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--pull</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--push</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb13-7">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--tag</span> REGION-docker.pkg.dev/PROJECT-ID/REPOSITORY-NAME/deploy-api:latest .</span></code></pre></div>
<p>where REPOSITORY-NAME is the name of the <code>registry_id</code> variable in <code>terraform.tfvars</code>. Note the “platform” argument.</p>
</section>
<section id="deploy" class="level3">
<h3 class="anchored" data-anchor-id="deploy">Deploy</h3>
<p>Now deploy the app with</p>
<p><code>gcloud run deploy app --image REGION-docker.pkg.dev/PROJECT-ID/REPOSITORY-NAME/deploy-api:latest --region REGION --platform managed --allow-unauthenticated</code></p>
<p>All being well, you should get a message saying</p>
<pre class="text"><code>Deploying container to Cloud Run service [app] in project [PROJECT-ID] region [REGION]
✓ Deploying new service... Done.
  ✓ Creating Revision...
  ✓ Routing traffic...
  ✓ Setting IAM Policy...
Done.</code></pre>
</section>
</section>
<section id="heres-one-i-built-earlier" class="level2">
<h2 class="anchored" data-anchor-id="heres-one-i-built-earlier">Here’s one I built earlier!</h2>
<p>You can see a running version of the app from the repo here: <a href="https://app-qdvgjvqwza-nw.a.run.app">https://app-qdvgjvqwza-nw.a.run.app</a>. You can find <a href="https://app-qdvgjvqwza-nw.a.run.app/docs">the docs here</a>. And <a href="https://app-qdvgjvqwza-nw.a.run.app/year/2021/geo_code/E08000007">here’s an example that returns data</a>. Note that one constraint of Cloud Run is that it takes a moment to start if no-one has used the link for a while.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>It’s worth noting that, if all your API is doing is serving up tabular data, there is an easier way to to this (even though building an API with FastAPI is so easy). You can use the excellent <a href="https://datasette.io/">datasette</a>. You can see a worked example of using it to <a href="https://github.com/aeturrell/datasette_particulate_matter">serve up some data here</a>. It seems like FastAPI would be much more useful with more unusually structured data, when you need to interact with data by writing as well as reading, or when you need Cloud Run to do other activities too (like pull from a Google database).</p>
<p>The commoditisation of cloud services, and the great developments in Python as a language, have made it far, far easier to create high quality APIs. Although there are a few components to get your head around here, it’s amazing how quickly you can create a working API—and how few lines of code are required.</p>


</section>

 ]]></description>
  <category>code</category>
  <category>open-source</category>
  <category>cloud</category>
  <category>data science</category>
  <category>python</category>
  <guid>https://www.aeturrell.com/blog/posts/build-a-cloud-api/build-a-cloud-api.html</guid>
  <pubDate>Wed, 27 Sep 2023 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/build-a-cloud-api/run_using_data.png" medium="image" type="image/png" height="213" width="144"/>
</item>
<item>
  <title>The explosion in time series forecasting packages in data science</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/time-series-explosion/</link>
  <description><![CDATA[ 





<p>There have been a series of sometimes jaw-dropping developments in data science in the last few years, with large language models by far the most prominent (and with good reason). But another story has been the huge explosion in time series packages.</p>
<p>Were you really a tech firm circa 2020–2023 if you didn’t release your own time series package? Looking at what’s available and from who, maybe not: Facebook/Meta got the ball rolling with Prophet, but since then we’ve seen ones from Uber, LinkedIn, Amazon, Google, and Meta again. And it’s not hard to see why time series forecasting might be so valuable at these digital-first, data-rich firms. Just as with data orchestration tools, everyone else is seeing some benefit from their labours.</p>
<p>In the rest of this post, we’ll look at the new(ish) time series packages that are around, who built them, and what they might be good for.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/time-series-explosion/pymc_example.png" class="img-fluid figure-img" style="width:60.0%" alt="Posteriors for outturn, trend, and seasonality."></p>
<figcaption class="margin-caption">An example: forecasting airline passenger numbers in Bayesian package PyMC</figcaption>
</figure>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>Of course, all of this began, at least in my mind, with Meta’s <a href="https://facebook.github.io/prophet/">Prophet</a>. This provided a quick solution to structural time series modelling out of the box. And it responded well to the needs of those with high frequency data by using Python’s <a href="https://pypi.org/project/holidays/">holidays</a> package to allow for holiday fixed effects. Being able to deal with hourly and daily data is crucial to tech firms inundated with data, so it’s easy to see why this was built in. And when the pandemic hit, and everything was changing day by day (sometimes exponentially), everyone else was suddenly interested in high-frequency data too.</p>
<p>Prophet has had some criticism, even getting <a href="https://ryxcommar.com/2021/11/06/zillow-prophet-time-series-and-prices/">some blame</a> for <a href="https://www.cnet.com/personal-finance/mortgages/what-happened-at-zillow-how-a-prized-real-estate-site-lost-at-ibuying/">Zillow’s struggles with property trading</a>. But I think it’s a bit unfair because Prophet moved data science forecasting on considerably: it performed well out of the box in a wide variety of situations and had support for high-frequency data that didn’t exist in many other packages at the time. In short, it’s actually a great package, and has become a kind of reference point for every other time series package—and it seems like it did start something.</p>
<p>Perhaps the <a href="https://mofc.unic.ac.cy/">forecasting competitions</a> and appearances of websites like papers with code, which has a <a href="https://paperswithcode.com/task/time-series-forecasting">time series forecasting</a> section, is driving innovation here too, alongside the aforementioned interest in actually using these tools in a business context.</p>
<p>Either way, data scientists are benefitting: the explosion hasn’t just been in the number of time series packages (which may not be adding much!), but in the number of methods on offer too. In particular, some of the latest machine learned-based time series forecasting methods are making it into the packages alongside classic methods such as ARIMA. This is quite a contrast from five or ten years ago when most people were relying on one or two approaches in a handful of packages, mostly <a href="https://www.statsmodels.org/"><strong>statsmodels</strong></a> in Python and <a href="https://github.com/robjhyndman/forecast"><strong>forecast</strong></a> plus a couple of others in R. Of course, new doesn’t necessarily mean better, but the innovation and choice are welcome, and it’s almost certainly easier now to find a time series forecasting tool that has good performance on your problem.</p>
<p>It’s worth saying that while these new packages bring lots that is good, like state of the art (SOTA) machine learning (ML) models, and super modern fast fitting algorithms, their understandable focus on the needs of tech firms can mean they’re less well-suited, at least out of the box, to lower frequency data.</p>
</section>
<section id="the-packages" class="level2">
<h2 class="anchored" data-anchor-id="the-packages">The packages</h2>
<p>So what does the landscape look like today? Well, of course, it depends on where we draw the line. Anything that can predict a number can be used for time series forecasting, so all of <a href="https://scikit-learn.org/">scikit-learn</a> and <a href="https://pytorch.org/">pytorch</a> would qualify. But we’re going to focus on packages that can do competent time series analysis more or less out of the box. Secondly, we’re going to focus more on forecasting than, say, classification or anomaly detection—though a lot of the libraries below offer these features too. Similarly, more time series feature discovery packages (<a href="https://github.com/alteryx/featuretools">featuretools</a>, <a href="https://github.com/blue-yonder/tsfresh">tsfresh</a>) have appeared, but we won’t cover those. Finally, I also ignored packages that didn’t seem to be under active development or being maintained.</p>
<p>Let’s dive into what’s on offer now for <em>time series forecasting</em>. The table below gives the name, organisation, and homepage of each package. The “About” column is largely drawn from the websites of these packages, with some extra context in italics.</p>
<p>As you can see from the table, we’re spoiled for choice right now. I guess you could say, for data scientists doing forecasting, times are good 😉.</p>
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 60%">
</colgroup>
<thead>
<tr class="header">
<th>Package</th>
<th>Organisation</th>
<th>About</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/Nixtla/statsforecast">statsforecast</a></td>
<td>Nixtla</td>
<td><em>This seems highly optimised for speed</em>. StatsForecast offers a collection of widely used univariate time series forecasting models, including automatic ARIMA, ETS, CES, and Theta modeling optimized for high performance using numba. It also includes a large battery of benchmarking models. Some other claimed features are: fastest implementations of a bunch of algorithms; compatibility with Spark, Dask, and Ray; confidence intervals; support for exogenous variables; 500x faster than prophet; and 20x faster than pmdarima.</td>
</tr>
<tr class="even">
<td><a href="https://facebook.github.io/prophet/">Prophet</a></td>
<td>Facebook</td>
<td><em>The OG. Has an R version too.</em> “Forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.”</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/facebookresearch/Kats">Kats</a></td>
<td>Facebook</td>
<td>A kit to analyse time series data. A lightweight, easy-to-use, generalizable, and extendable framework to perform time series analysis, from understanding the key statistics and characteristics, detecting change points and anomalies, to forecasting future trends.</td>
</tr>
<tr class="even">
<td><a href="https://www.sktime.net/">sktime</a></td>
<td>Alan Turing Institute</td>
<td>Python framework for ML and AI with time series, full list of features <a href="https://www.sktime.net/en/stable/estimator_overview.html">here</a>.</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/alkaline-ml/pmdarima">pmdarima</a></td>
<td>Alkaline ML</td>
<td>A statistical library designed to fill the void in Python’s time series analysis capabilities, including the equivalent of R’s auto.arima function.</td>
</tr>
<tr class="even">
<td><a href="https://linkedin.github.io/greykite/">greykite</a></td>
<td>LinkedIn</td>
<td>An open source Python library developed to support LinkedIn’s forecasting needs. Its main forecasting algorithm, called Silverkite, is fast, accurate, and intuitive, making it suitable for interactive and automated forecasting at scale. The Silverkite algorithm works well on most time series, and is especially adept for those with changepoints in trend or seasonality, event/holiday effects, and temporal dependencies. Its forecasts are interpretable and therefore useful for trusted decision-making and insights.</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/uber/orbit">orbit</a></td>
<td>Uber</td>
<td>A Python package for Bayesian forecasting with object-oriented design and probabilistic models under the hood. Focuses on exponential smoothing and kernel-based time-varying regression.</td>
</tr>
<tr class="even">
<td><a href="https://unit8co.github.io/darts/">Darts</a></td>
<td>Unit8</td>
<td><em>This looks like an especially high quality package</em>. A python library for user-friendly forecasting and anomaly detection on time series. Contains a variety of models, from classics such as ARIMA to deep neural networks. Huge set of models.</td>
</tr>
<tr class="odd">
<td><a href="https://github.com/timeseriesAI/tsai">tsai</a></td>
<td>timeseriesAI</td>
<td><em>Seems like the best place to get SOTA ML time series forecasting capabilities</em>. tsai is an open-source deep learning package built on top of Pytorch &amp; fastai focused on state-of-the-art techniques for time series tasks like classification, regression, forecasting, imputation.</td>
</tr>
<tr class="even">
<td><a href="https://ts.gluon.ai/stable/">gluonts</a></td>
<td>Amazon</td>
<td>Probabilistic time series modelling in Python. GluonTS is a Python package for probabilistic time series modelling, focusing on deep learning based models, based on PyTorch and MXNet.</td>
</tr>
<tr class="odd">
<td><a href="https://neuralprophet.com/">neuralprophet</a></td>
<td>Stanford University</td>
<td><em>Has a focus on interpretability</em>. An easy to learn framework for interpretable time series forecasting. NeuralProphet is built on PyTorch and combines Neural Network and traditional time-series algorithms, inspired by Facebook Prophet and AR-Net.</td>
</tr>
<tr class="even">
<td><a href="https://github.com/salesforce/Merlion">merlion</a></td>
<td>salesforce</td>
<td><em>Focus on easy-to-use interface (including a GUI), so possibly good for colleagues who can’t code but need to use the latest forecasting models.</em> Provides an end-to-end machine learning framework that includes loading and transforming data, building and training models, post-processing model outputs, and evaluating model performance. It supports various time series learning tasks, including forecasting, anomaly detection, and change point detection for both univariate and multivariate time series.</td>
</tr>
<tr class="odd">
<td><a href="https://www.pymc.io/">PyMC</a></td>
<td>PyMC</td>
<td><em>This is a bit more build your own, but they just added support for <a href="https://discourse.pymc.io/t/pymc-experimental-now-includes-state-spaces-models/12773">state-space models</a> so it’s made it onto the list, and it has some good <a href="https://www.pymc.io/projects/examples/en/latest/gallery.html#time-series">time series examples</a> in the documentation.</em> PyMC is a probabilistic programming library for Python that allows users to build Bayesian models with a simple Python API and fit them using Markov chain Monte Carlo (MCMC) methods.</td>
</tr>
<tr class="even">
<td><a href="https://github.com/Nixtla/neuralforecast">neuralforecast</a></td>
<td>Nixtla</td>
<td><em>Another entry from Nixtla, but this time implementing high-performing neural network based time series forecasting. Less popular than its other package.</em></td>
</tr>
<tr class="odd">
<td><a href="https://github.com/winedarksea/AutoTS">AutoTS</a></td>
<td>winedarksea</td>
<td>Time series package for Python designed for rapidly deploying high-accuracy forecasts at scale. Includes naive, statistical, machine learning, and deep learning models.</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>code</category>
  <category>data science</category>
  <category>python</category>
  <category>time series</category>
  <guid>https://www.aeturrell.com/blog/posts/time-series-explosion/</guid>
  <pubDate>Mon, 11 Sep 2023 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/time-series-explosion/pymc_example.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>TIL: Obsidian, and integrating it with Zotero</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/til-zotero-and-obsidian/</link>
  <description><![CDATA[ 





<p>I’ve long been interested in how best to store knowledge; so much that I wrote about it in <a href="&quot;../managing-public-sector-knowledge/managing-public-sector-knowledge.qmd&quot;">this post</a> (in the context of the public sector). Today I learned how to combine Obsidian and Zotero to make taking notes about research literature easier and more effective!</p>
<blockquote class="blockquote">
<p>Note: this is being posted under a tag called TIL or “today I learned”. These are shorter format posts that lower the barrier to blogging and capture a mini piece of learning. The idea for TILs has been inspired by Simon Willison’s own <a href="https://til.simonwillison.net/">TIL posts</a>. You can find the first TIL <a href="../../../blog/posts/til-how-to-break-xml/index.html">here</a>.</p>
</blockquote>
<section id="storing-knowledge-flexibly" class="level2">
<h2 class="anchored" data-anchor-id="storing-knowledge-flexibly">Storing knowledge flexibly</h2>
<p>One of the frustrations of the generally-excellent Microsoft OneNote, which I normally use for notes, is that it uses <em>mutually exclusive</em> pages for content. This means that you can’t have the same atomic piece of information (eg a note on a particular paper) filed under two different titles or concepts.</p>
<p>There are a couple of potential solutions to this. You could use a notes system that is label-based rather than file-based. Then an atomic piece of information can be labelled two ways. Another way to solve it is to create links between concepts, and this is the way that popular open-source note-organising software <a href="https://obsidian.md/">Obsidian</a> uses, so I thought I’d give it a try.</p>
<p>I’m new to Obsidian but have had my eye on it for a while because it uses Markdown. Apart from its simplicity, the markdown format is FAIR: findable, accessible, interoperable, and re-usable. Obsidian also happens to free and open source software, which can have benefits such as large numbers of users and creators focused on making the software as useful as possible (there are downsides too, naturally).</p>
<p>Obsidian describes itself as “the private and flexible note‑taking app that adapts to the way you think”, and indeed you have to specify where to store the notes you create. It acts as a fantastic front-end to a folder full of markdown files (called ‘vaults’), essentially. But it does additionally introduce the double-square bracket link, <code>[[concept]]</code>, which allows you to connect ideas <em>across</em> different atomic notes. Obsidian will display this in a graph too—helping you to visualise the space of ideas you’re working in. Early days, but so far I’ve been impressed.</p>
</section>
<section id="integrating-zotero" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="integrating-zotero">Integrating Zotero</h2>
<p>You might not be familiar with <a href="https://www.zotero.org/">Zotero</a>, but it’s an excellent, open-source programme for collecting and organising research literature in the form of citations (for example, .bib files) <em>and</em> the PDFs of the actual papers. It’s basically a database of your research literature, but it (very helpfully) also tracks any notes you might make on a paper <em>and</em> automatically extracts any text you highlight in a PDF into plain-text notes.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;It does some of what Mendeley did in its hey day, but is a lot better.</p></div></div><p>Now, imagine you want to use a hot key to <em>automatically</em> create an Obsidian note page that contains, for a specific paper, i) metadata on that paper, ii) notes you’ve made in Zotero on that paper, and iii) any annotations you made in Zotero on that paper. And imagine that, as well as all that, every time you need to link to a paper from your Zotero library that you already turned into an Obsidian note, you could just start typing <code>@</code> and get a drop down list of all your papers. <strong>Well, amazingly, you <em>can</em> do all of this</strong>. Honestly, it’s a revelation.</p>
<p>If you want to achieve this research-note-taking zen, you’ll need to follow a few steps. First, you’ll need to install Zotero and Obsidian, and a couple of add-ons:</p>
<ul>
<li>the better bibtex add-on for Zotero</li>
<li>the Zotero Integration plug-in for Obsidian</li>
</ul>
<p>I then configured a bunch of settings:</p>
<ul>
<li>In Zotero → Tools → Better Bibtex → Open Better Bibtex Settings, I changed the citation key formula to <code>auth.lower + '_' + shorttitle(1,1).lower + '_' + year</code> to get a paper like <em>Hörmann, Wolfgang, and Josef Leydold. “Continuous random variate generation by fast numerical inversion.” ACM Transactions on Modeling and Computer Simulation (TOMACS) 13, no. 4 (2003): 347-362.</em> to have a citekey of the form “hormann_continuous_2003”.</li>
<li>In Obsidian → Settings → Zotero Integration, I changed the ‘Note Import Location’ to a folder called <code>auto-notes-on-research</code>. This is for the built-in notes importer, which is very bare bones and I don’t expect to use, so this is mainly to ensure there’s no conflict between notes created this way and the way we’re about to create with custom settings.</li>
<li>I hit <code>Add Import Format</code> under Obsidian → Settings → Zotero Integration. I changed the name to “import-research-notes”, set the output path to <code>notes-on-research/{{citekey}}.md</code>, the bibliography style to <em>Nature</em> (which will usually be pre-installed with Zotero), and set the template to a markdown template that I’ll include at the end of the post. The markdown template is important: it controls what you’ll see when you import research as a note.</li>
<li>I went to Obsidian → Settings → Appearance → CSS snippets, opened the folder, and created a file I called <code>style.css</code>. I filled it with the contents at the end of this blog post, and then hit refresh.</li>
<li>I then went to Obsidian → Settings → Hotkeys, and typed “Zotero Integration: import-research-notes” into the search bar. I added a <kbd>⇧ Shift</kbd> + <kbd>⌃ Control</kbd> + <kbd>c</kbd> hotkey for import-research-notes.</li>
</ul>
<p>Right, if you’ve done all that you can enjoy your new setup. I realise it’s a bit confusing so I’ll spell out the workflow a bit more now:</p>
<ol type="1">
<li>In Obsidian, hit your hotkey, perhaps <kbd>⇧ Shift</kbd>+<kbd>⌃ Control</kbd>+<kbd>c</kbd> if you used the same setup as me.</li>
<li>You should see a search bar pop up in Zotero. Type in anything from the paper you’d like to include, select it with the arrow keys, then hit return.</li>
<li>In the <code>notes-on-research</code> subfolder of your Obsidian vault, you should now have a page for your paper (named with the citekey)!</li>
<li>If you want to link to this page once created, you can either use the standard double brackets or <code>@</code>, search for the paper, and then hit <kbd>⌥ Option</kbd> + <kbd>↵ Return</kbd>.</li>
</ol>
<p>If for any reason you don’t wish to use the hotkey, then you can click on the command palette and then type in Zotero, then select “Zotero Integration: import-research-notes”. Then proceed with steps 2 and 3.</p>
</section>
<section id="result" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="result">Result 🔥</h2>
<p>I’ve done an example run on a single paper, and this is the result:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.aeturrell.com/blog/posts/til-zotero-and-obsidian/obsidian-research-note-page.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Example research page from an Obsidian note</figcaption>
</figure>
</div>
<p>You can see a note that has been made on the paper overall, and an annotation (which inherits the colour you used in Zotero originally) that also has a comment.</p>
<p>The way the template is put together, future updates to the paper will be added when you re-import it.</p>
<p>Later on, if you need to link to the Obsidian note on this then just use the double-bracket format. This paper has citekey <code>devocht_conceptualising_2021</code> so we would use <code>[[devocht_conceptualising_2021]]</code> to link to it.</p>
<p>That’s it for the main post—pretty amazing tech, I think you’ll agree, though a bit fiddly to set up. If you have any tips or strategies for using Zotero and Obsidian together, let me know!</p>
</section>
<section id="templates" class="level2">
<h2 class="anchored" data-anchor-id="templates">Templates</h2>
<p>As promised, here are the templates I used, which I got from <a href="https://github.com/nocona71/obsidian-literature-note">nocona71 on github</a>, but tweaked a little (only a little) for my needs.</p>
<p>The contents of <code>zotero-import-template.md</code>, which is in a subdirectory I called <code>templates</code>.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### {{title}}</span></span>
<span id="cb1-2">{{" "}}</span>
<span id="cb1-3">year: {{date | format ("YYYY")}}</span>
<span id="cb1-4">tags: research</span>
<span id="cb1-5">authors: {{authors}}</span>
<span id="cb1-6">{{" "}}</span>
<span id="cb1-7">Abstract:  {{abstractNote}}</span>
<span id="cb1-8">{{" "}}</span>
<span id="cb1-9">{{pdfZoteroLink}}</span>
<span id="cb1-10">{{" "}}</span>
<span id="cb1-11">{#- infer latest annotation Date -#}</span>
<span id="cb1-12">{% macro maxAnnotationsDate() %}</span>
<span id="cb1-13">   {%- set tempDate = "" -%}</span>
<span id="cb1-14">    {%- for a in annotations -%}</span>
<span id="cb1-15">        {%- set testDate = a.date | format("YYYY-MM-DD#HH:mm:ss") -%}</span>
<span id="cb1-16">        {%- if testDate &gt; tempDate or tempDate == ""-%}</span>
<span id="cb1-17">            {%- set tempDate = testDate -%}</span>
<span id="cb1-18">        {%- endif -%}</span>
<span id="cb1-19">    {%- endfor -%}</span>
<span id="cb1-20">    {{tempDate}}</span>
<span id="cb1-21">{%- endmacro %}</span>
<span id="cb1-22">{# infer earliest annotation date #}</span>
<span id="cb1-23">{%- macro minAnnotationsDate() -%}</span>
<span id="cb1-24">   {%- set tempDate = "" -%}</span>
<span id="cb1-25">    {%- for a in annotations -%}</span>
<span id="cb1-26">        {%- set testDate = a.date | format("YYYY-MM-DD#HH:mm:ss") -%}</span>
<span id="cb1-27">        {%- if testDate &lt; tempDate or tempDate == ""-%}</span>
<span id="cb1-28">            {%- set tempDate = testDate -%}</span>
<span id="cb1-29">        {%- endif -%}</span>
<span id="cb1-30">    {%- endfor -%}</span>
<span id="cb1-31">    {{tempDate}}</span>
<span id="cb1-32">{%- endmacro -%}</span>
<span id="cb1-33">{# infer latest note date #}</span>
<span id="cb1-34">{%- macro maxNotesDate() -%}</span>
<span id="cb1-35">   {%- set tempDate = "" -%}</span>
<span id="cb1-36">    {%- for n in notes -%}</span>
<span id="cb1-37">        {%- set testDate = n.dateModified | format("YYYY-MM-DD#HH:mm:ss") -%}</span>
<span id="cb1-38">        {%- if testDate &gt; tempDate or tempDate == ""-%}</span>
<span id="cb1-39">            {%- set tempDate = testDate -%}</span>
<span id="cb1-40">        {%- endif -%}</span>
<span id="cb1-41">    {%- endfor -%}</span>
<span id="cb1-42">    {{tempDate}}</span>
<span id="cb1-43">{%- endmacro -%}</span>
<span id="cb1-44">{#- infer earliest note date -#}</span>
<span id="cb1-45">{%- macro minNotesDate() -%}</span>
<span id="cb1-46">   {%- set tempDate = "" -%}</span>
<span id="cb1-47">    {%- for n in notes -%}</span>
<span id="cb1-48">        {%- set testDate = n.dateAdded | format("YYYY-MM-DD#HH:mm:ss") -%}</span>
<span id="cb1-49">        {%- if testDate &lt; tempDate or tempDate == "" -%}</span>
<span id="cb1-50">            {%- set tempDate = testDate -%}</span>
<span id="cb1-51">        {%- endif -%}</span>
<span id="cb1-52">    {%- endfor -%}</span>
<span id="cb1-53">    {{tempDate}}</span>
<span id="cb1-54">{%- endmacro -%}</span>
<span id="cb1-55">{# find earliest date of two dates #}</span>
<span id="cb1-56">{%- macro minDate(min1, min2) -%}</span>
<span id="cb1-57">        {%- if min1 &lt;= min2 -%}</span>
<span id="cb1-58">            {{min1}}</span>
<span id="cb1-59">        {%- else -%}</span>
<span id="cb1-60">            {{min2}}</span>
<span id="cb1-61">        {%- endif -%}</span>
<span id="cb1-62">{%- endmacro -%}</span>
<span id="cb1-63">{# find latest date of two dates #}</span>
<span id="cb1-64">{%- macro maxDate(min1, min2) -%}</span>
<span id="cb1-65">        {%- if min1 &gt;= min2 -%}</span>
<span id="cb1-66">            {{min1}}</span>
<span id="cb1-67">        {%- else -%}</span>
<span id="cb1-68">            {{min2}}</span>
<span id="cb1-69">        {%- endif -%}</span>
<span id="cb1-70">{%- endmacro -%}</span>
<span id="cb1-71"></span>
<span id="cb1-72">{# colorCategory to hex:</span>
<span id="cb1-73">"green": "#5fb236",</span>
<span id="cb1-74">"yellow": "#ffd400",</span>
<span id="cb1-75">"red": "#ff6666",</span>
<span id="cb1-76">"blue": "#2ea8e5",</span>
<span id="cb1-77">"purple": "#a28ae5",</span>
<span id="cb1-78">"magenta": "#e56eee",</span>
<span id="cb1-79">"orange": "#f19837",</span>
<span id="cb1-80">"gray": "#aaaaaa"</span>
<span id="cb1-81">#}</span>
<span id="cb1-82"></span>
<span id="cb1-83">{%- set colorToColorCategory = {</span>
<span id="cb1-84">"#ffd400": "yellow",</span>
<span id="cb1-85">"#ff6666": "red",</span>
<span id="cb1-86">"#5fb236": "green",</span>
<span id="cb1-87">"#2ea8e5": "blue",</span>
<span id="cb1-88">"#a28ae5": "purple",</span>
<span id="cb1-89">"#e56eee": "magenta",</span>
<span id="cb1-90">"#f19837": "orange",</span>
<span id="cb1-91">"#aaaaaa": "gray"</span>
<span id="cb1-92">}</span>
<span id="cb1-93">-%}</span>
<span id="cb1-94">{%- set colorCategoryToType = {</span>
<span id="cb1-95">"yellow": "Relevant / Important",</span>
<span id="cb1-96">"red": "Disagree",</span>
<span id="cb1-97">"green": "Important to me",</span>
<span id="cb1-98">"blue": "Question / Understanding / Vocabulary",</span>
<span id="cb1-99">"purple": "Reference / Term to lookup later",</span>
<span id="cb1-100">"magenta": "margenta",</span>
<span id="cb1-101">"orange": "orange",</span>
<span id="cb1-102">"gray": "gray"</span>
<span id="cb1-103">}</span>
<span id="cb1-104">-%}</span>
<span id="cb1-105">{# lookup Zotero colors in annotations with Category #}</span>
<span id="cb1-106">{%- macro colorCategoryToName(noteColor) -%}</span>
<span id="cb1-107">{%- if colorCategory<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">noteColor</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>-%}</span>
<span id="cb1-108">{{colorCategory<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">noteColor</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>}}</span>
<span id="cb1-109">{% else %}</span>
<span id="cb1-110">{{colorCategory<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">"yellow"</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>}}</span>
<span id="cb1-111">{%endif%}</span>
<span id="cb1-112">{%- endmacro -%}</span>
<span id="cb1-113"></span>
<span id="cb1-114">{%- macro colorToName(noteColor) -%}</span>
<span id="cb1-115">{%- if colorToColorCategory<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">noteColor</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>-%}</span>
<span id="cb1-116">{{colorCategoryToType<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">colorToColorCategory[noteColor]</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>}}</span>
<span id="cb1-117">{% else %}</span>
<span id="cb1-118">{{colorCategoryToType<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">"orange"</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>}}</span>
<span id="cb1-119">{%endif%}</span>
<span id="cb1-120">{%- endmacro -%}</span>
<span id="cb1-121"></span>
<span id="cb1-122"></span>
<span id="cb1-123">{%- set calloutHeaders = {</span>
<span id="cb1-124">"highlight": "Highlight",</span>
<span id="cb1-125">"strike": "Strike Through",</span>
<span id="cb1-126">"underline": "Underline",</span>
<span id="cb1-127">"note": "Sticky Note",</span>
<span id="cb1-128">"image": "Image"</span>
<span id="cb1-129">}</span>
<span id="cb1-130">-%}</span>
<span id="cb1-131">{# lookup callout headers by type of annotation #}</span>
<span id="cb1-132">{%- macro calloutHeader(type) -%}</span>
<span id="cb1-133">{%- if calloutHeaders<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>-%}</span>
<span id="cb1-134">{{calloutHeaders<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span>}}</span>
<span id="cb1-135">{% else %}</span>
<span id="cb1-136">{{Note}}</span>
<span id="cb1-137">{%endif%}</span>
<span id="cb1-138">{%- endmacro -%}</span>
<span id="cb1-139"></span>
<span id="cb1-140">{#- handle space characters in zotero tags -#}</span>
<span id="cb1-141">{%- set space = joiner(' ') -%} </span>
<span id="cb1-142">{%- macro printTags(rawTags) -%}</span>
<span id="cb1-143">    {%- if rawTags.length &gt; 0 -%}</span>
<span id="cb1-144">        {%- for tag in rawTags -%}</span>
<span id="cb1-145">            #zotero/{{ tag.tag | lower | replace(" ","_") }} {{ space() }} </span>
<span id="cb1-146">        {%- endfor -%}</span>
<span id="cb1-147">    {%- endif -%}</span>
<span id="cb1-148">{%- endmacro %}</span>
<span id="cb1-149"></span>
<span id="cb1-150">{#- handle | characters in zotero strings used in MD -#}</span>
<span id="cb1-151">{% macro formatCell(cellText) -%}</span>
<span id="cb1-152">{{ cellText | replace("|","❕")}}</span>
<span id="cb1-153">{%- endmacro %}</span>
<span id="cb1-154"></span>
<span id="cb1-155">{%- macro formatDate(testDate, dateFormat) -%}</span>
<span id="cb1-156">{%- if testDate -%}</span>
<span id="cb1-157">{{date | format (dateFormat)}}</span>
<span id="cb1-158">{%- endif %}    </span>
<span id="cb1-159">{%- endmacro %}</span>
<span id="cb1-160"></span>
<span id="cb1-161">{#- handle | characters in zotero strings used in MD -#}</span>
<span id="cb1-162">{# {%- set comma = joiner(', ') -%} </span>
<span id="cb1-163">{%- macro generateCreators(prefix) -%}</span>
<span id="cb1-164">{%- for creatorType, creators in creators | groupby("creatorType") -%}</span>
<span id="cb1-165">{{prefix}}{{ creatorType }}:: {{ space() }} </span>
<span id="cb1-166">    {%- for creator in creators -%}</span>
<span id="cb1-167">        {{ creator.firstName }} {{ creator.lastName }} </span>
<span id="cb1-168">        {%- if not loop.last -%}</span>
<span id="cb1-169">        {{comma()}}</span>
<span id="cb1-170">        {%- endif -%}</span>
<span id="cb1-171">    {%- endfor %}</span>
<span id="cb1-172">{% endfor -%}</span>
<span id="cb1-173">{%- endmacro -%} #}</span>
<span id="cb1-174"></span>
<span id="cb1-175">{#- generate fields based on Zotero properties -#}</span>
<span id="cb1-176">{%- macro generateFields(prefix) -%}</span>
<span id="cb1-177">{%- for field, property in fields -%}</span>
<span id="cb1-178">{%- if property.length &gt; 0 -%}</span>
<span id="cb1-179">{{ generateField(prefix, field, property) }}</span>
<span id="cb1-180">{%- endif -%}</span>
<span id="cb1-181">{%- endfor %}</span>
<span id="cb1-182">{%- endmacro -%}</span>
<span id="cb1-183"></span>
<span id="cb1-184">{{printTags(tags)}}</span>
<span id="cb1-185">{{ "" }}</span>
<span id="cb1-186"></span>
<span id="cb1-187">🔥🔥🔥everything above this line might change during an update 🔥🔥🔥</span>
<span id="cb1-188"></span>
<span id="cb1-189"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Notes and Annotations</span></span>
<span id="cb1-190"></span>
<span id="cb1-191">{% persist "notes" %}</span>
<span id="cb1-192">{{ "" }}</span>
<span id="cb1-193">{%- set newNotes = notes | filterby("dateModified", "dateafter", lastImportDate) -%}</span>
<span id="cb1-194">{% if newNotes.length &gt; 0 %}</span>
<span id="cb1-195"></span>
<span id="cb1-196">⬇️*Notes imported on: {{importDate | format("YYYY-MM-DD#HH:mm:ss")}}*⬇️</span>
<span id="cb1-197">{% for note in newNotes %}</span>
<span id="cb1-198"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">### 🟨 Note</span></span>
<span id="cb1-199">Modified: {{ note.dateModified | format("YYYY-MM-DD#HH:mm:ss") }}</span>
<span id="cb1-200">{{ "" }}</span>
<span id="cb1-201">{#- change heading level -#}</span>
<span id="cb1-202">{{ note.note | replace ("# ","### ") }}</span>
<span id="cb1-203"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">Link to note</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">](zotero://select/library/items/{{note.key}})</span></span>
<span id="cb1-204">{{printTags(note.tags)}}</span>
<span id="cb1-205">{{ "" }}</span>
<span id="cb1-206">---</span>
<span id="cb1-207">{% endfor %}</span>
<span id="cb1-208">{% endif -%} </span>
<span id="cb1-209"></span>
<span id="cb1-210">{% endpersist -%}</span>
<span id="cb1-211">{{ " " }}</span>
<span id="cb1-212"></span>
<span id="cb1-213">{{ " " }}</span>
<span id="cb1-214">{% persist "annotations" %}</span>
<span id="cb1-215">{{ " " }}</span>
<span id="cb1-216">{%- set newAnnotations = annotations | filterby("date", "dateafter", lastImportDate) -%}</span>
<span id="cb1-217">{% if newAnnotations.length &gt; 0 %}</span>
<span id="cb1-218">{{ " " }}</span>
<span id="cb1-219">⬇️*Annotation imported on {{importDate | format("YYYY-MM-DD#HH:mm:ss")}}*⬇️</span>
<span id="cb1-220"></span>
<span id="cb1-221">{# {% for color, colorCategory in colorToColorCategory %} #}</span>
<span id="cb1-222">{#-Filter empty colorCategory-#}</span>
<span id="cb1-223">{%- for annotation in newAnnotations -%}</span>
<span id="cb1-224">{# {% if loop.first -%} #}</span>
<span id="cb1-225">{# #### {{colorToName(color | lower)-}} #}</span>
<span id="cb1-226">{# {% endif %} #}</span>
<span id="cb1-227"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; </span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">!annotation-{% if annotation.color %}{% if colorToColorCategory[annotation.color].length &gt; 0 %}{{colorToColorCategory[annotation.color]}}{% else %}yellow{% endif %}</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{% endif %} {{calloutHeader(annotation.type)}}</span></span>
<span id="cb1-228"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{%- if annotation.annotatedText.length &gt; 0 -%} </span></span>
<span id="cb1-229"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; {{-annotation.annotatedText | nl2br -}} (p. </span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">{{annotation.page}}</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">](zotero://open-pdf/library/items/{{annotation.attachment.itemKey}}?page={{annotation.page}}&amp;annotation={{annotation.id}})</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">){% endif %}{%- if annotation.imageRelativePath -%}</span></span>
<span id="cb1-230"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; ![</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">{{annotation.imageRelativePath}}|300</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb1-231"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{%- endif %}{%- if annotation.ocrText -%}</span></span>
<span id="cb1-232"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; {{-annotation.ocrText | nl2br-}}{%- endif -%}</span></span>
<span id="cb1-233"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{%- if annotation.comment -%} </span></span>
<span id="cb1-234"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt;</span></span>
<span id="cb1-235"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; **comment:**</span></span>
<span id="cb1-236"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; {{annotation.comment | nl2br }}{% endif %}</span></span>
<span id="cb1-237"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; {{annotation.date | format("YYYY-MM-DD#HH:mm")}}</span></span>
<span id="cb1-238"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{%- if annotation.tags.length &gt; 0 %} </span></span>
<span id="cb1-239"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">&gt; {{printTags(annotation.tags)}}</span></span>
<span id="cb1-240"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{% endif %}</span></span>
<span id="cb1-241"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{% endfor -%}</span></span>
<span id="cb1-242"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{# {% endfor %} #}</span></span>
<span id="cb1-243"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">{%- endif -%}</span></span>
<span id="cb1-244"></span>
<span id="cb1-245">{% endpersist -%}</span></code></pre></div>
<p>And the contents of <code>style.css</code>, which I put in the hidden folder that can be found by following Obsidian → Settings → Appearance → CSS snippets.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode css code-with-copy"><code class="sourceCode css"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/* See https://lucide.dev for icon codes */</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/* annotation */</span></span>
<span id="cb2-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-yellow"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-5">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">212</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-6">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-7">}</span>
<span id="cb2-8"></span>
<span id="cb2-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-red"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-10">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">102</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">102</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-11">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-12">}</span>
<span id="cb2-13"></span>
<span id="cb2-14"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-green"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-15">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">178</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">54</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-16">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-17">}</span>
<span id="cb2-18"></span>
<span id="cb2-19"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-blue"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-20">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">46</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-21">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-22">}</span>
<span id="cb2-23"></span>
<span id="cb2-24"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-purple"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-25">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">162</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">138</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">229</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-26">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-27">}</span>
<span id="cb2-28"></span>
<span id="cb2-29"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-purple"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-30">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">162</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">138</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">229</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-31">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-32">}</span>
<span id="cb2-33"></span>
<span id="cb2-34"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-magenta"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-35">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">229</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">110</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">238</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-36">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-37">}</span>
<span id="cb2-38"></span>
<span id="cb2-39"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-orange"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-40">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">241</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">152</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">55</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-41">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-42">}</span>
<span id="cb2-43"></span>
<span id="cb2-44"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"annotation-gray"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-45">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">170</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">170</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">170</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-46">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-highlighter </span></span>
<span id="cb2-47">}</span>
<span id="cb2-48"></span>
<span id="cb2-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/* note */</span></span>
<span id="cb2-50"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"note-yellow"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-51">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">212</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-52">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-sticky-note </span></span>
<span id="cb2-53">}</span>
<span id="cb2-54"></span>
<span id="cb2-55"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"note-red"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-56">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">102</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">102</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-57">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-sticky-note </span></span>
<span id="cb2-58">}</span>
<span id="cb2-59"></span>
<span id="cb2-60"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"note-green"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-61">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">178</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">54</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-62">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-sticky-note </span></span>
<span id="cb2-63">}</span>
<span id="cb2-64"></span>
<span id="cb2-65"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"note-blue"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-66">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">46</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-67">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-sticky-note </span></span>
<span id="cb2-68">}</span>
<span id="cb2-69"></span>
<span id="cb2-70"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">.callout</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">data-callout</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"note-purple"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">]</span> {</span>
<span id="cb2-71">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-color</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">162</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">138</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">229</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-72">  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">--callout-icon</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">lucide-sticky-note </span></span>
<span id="cb2-73">}</span></code></pre></div>


</section>


 ]]></description>
  <category>writing</category>
  <category>research</category>
  <category>TIL</category>
  <guid>https://www.aeturrell.com/blog/posts/til-zotero-and-obsidian/</guid>
  <pubDate>Sat, 08 Jul 2023 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/til-zotero-and-obsidian/obsidian-research-note-page.png" medium="image" type="image/png" height="253" width="144"/>
</item>
<item>
  <title>The self-storage problem meets chatGPT</title>
  <dc:creator>Arthur Turrell</dc:creator>
  <link>https://www.aeturrell.com/blog/posts/self-storage-meets-chatgpt/</link>
  <description><![CDATA[ 





<p>In a previous post, I looked at four ways we might be able to establish the way that the number of <em>self-storage facilities</em> is trending over time. You can read that post using <a href="../../../blog/posts/self-storage-mystery/self-storage-mystery.html">this link</a>. Today, we’re going one step further with one of the options—scraping the websites of the main self-storage firms—and we’re going to do it with ChatGPT, the large language model from OpenAI. I mentioned in the previous blog post that</p>
<blockquote class="blockquote">
<p>Each location [of a self-storage facility] probably has a full address somewhere [on the firm’s website], so we could just scrape the entire website and use some kind of NLP to grab locations and hope that what gets picked up corresponds to the sites that are offered. There’d be some errors, like recording their primary office, but if you kept the page that the addresses were scraped from you could do something like eliminate any pages with just a single address.</p>
</blockquote>
<p>and</p>
<blockquote class="blockquote">
<p>A new feature just introduced by OpenAI, called <a href="https://platform.openai.com/docs/guides/gpt/function-calling">function calling</a>, makes this [using LLMs for analysis of web-scraped data] possible: essentially, it allows you to generate <em>structured</em> output from an LLM—think a JSON file—by defining a schema of data fields you’d like and then feeding it the text to find those fields.</p>
</blockquote>
<p>I also referenced the code by Kyle McDonald that <a href="https://gist.github.com/kylemcdonald/dbac21de2d7855633689f5526225154c">uses an LLM to query a Washington Post article</a>.</p>
<p>Well, reader, I tried out a very slightly modified version of Kyle’s LLM code on a URL for a self-storage firm and it worked!</p>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>Here’s the code:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> openai</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> requests</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> bs4 <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BeautifulSoup</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> os <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> environ <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> env</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb1-6"></span>
<span id="cb1-7">load_dotenv()</span>
<span id="cb1-8"></span>
<span id="cb1-9">openai.api_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> env[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"API_KEY"</span>]</span>
<span id="cb1-10">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://www.safestore.co.uk/storage-near-me/'</span></span>
<span id="cb1-11">html <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> requests.get(url).content</span>
<span id="cb1-12">soup <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BeautifulSoup(html, features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lxml"</span>)</span>
<span id="cb1-13">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> soup.text.strip()</span>
<span id="cb1-14"></span>
<span id="cb1-15">functions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-16">    {</span>
<span id="cb1-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"extract_data"</span>,</span>
<span id="cb1-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"description"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Add the summary of all locations of self-storage sites to the list."</span>,</span>
<span id="cb1-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"parameters"</span>: {</span>
<span id="cb1-20">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>,</span>
<span id="cb1-21">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"properties"</span>: {</span>
<span id="cb1-22">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"addresses"</span>: {</span>
<span id="cb1-23">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"array"</span>,</span>
<span id="cb1-24">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"items"</span>: {</span>
<span id="cb1-25">                                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span></span>
<span id="cb1-26">                        },</span>
<span id="cb1-27">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"description"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"A list of any addresses that are found."</span></span>
<span id="cb1-28">                    },</span>
<span id="cb1-29">                },</span>
<span id="cb1-30">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"addresses"</span>],</span>
<span id="cb1-31">        },</span>
<span id="cb1-32">    }</span>
<span id="cb1-33">]</span>
<span id="cb1-34"></span>
<span id="cb1-35">messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-36">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a helpful assistant that extracts the addresses of self-storage facilities from the websites of self-storage firms as JSON for a database."</span>},</span>
<span id="cb1-37">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Extract all of the addresses from the following website: '</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> text}</span>
<span id="cb1-38">]</span>
<span id="cb1-39"></span>
<span id="cb1-40">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> openai.ChatCompletion.create(</span>
<span id="cb1-41">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gpt-3.5-turbo-0613'</span>, functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>functions, messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>messages)</span>
<span id="cb1-42"></span>
<span id="cb1-43"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(response.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'message'</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'function_call'</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'arguments'</span>])</span></code></pre></div>
<p>And the start of the output:</p>
<pre class="text"><code>{
  "addresses": [
    "Self Storage London and storage units near me...",
    "With over 49 stores in London and 130 storage centres nationwide",
    "Central London",
    "Battersea Park",
    "Camden Town",
    "Earls Court",
    "Kings Cross",
    "Notting Hill",
    "Paddington - Marble Arch",
    "East London",
    "Barking and Dagenham",
    "Bow",
    "Chingford - Walthamstow",
    "Crayford",
    "Ilford",
    "Orpington",
    "Romford",
    "Stoke Newington",
    ...</code></pre>
<p>You can see how ChatGPT has grabbed everything that could conceivably be an address here, which is why the first two entries aren’t what we’re looking for. But the rest of what it found absolutely is and I am impressed.</p>
</section>
<section id="practical-limitations-and-suggestions" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="practical-limitations-and-suggestions">Practical limitations and suggestions</h2>
<p>Of course, this is only part of the problem. I fed ChatGPT a URL that I had already checked contained the info on all of the locations, and finding that URL is a big task in the first place. It’s tricky for two reasons: one, we don’t know which part of a firm’s website the locations will be listed on; two, that page may change over time. Ideally, we’d have a multi-step process in which a spider or scraper would first sift through all of the pages of a given snapshot in time of a URL and pass those to a classifier that would check whether it was a page of locations. Finally, the LLM would extract the locations.</p>
<p>Even with this setup, we’re still stuck with going through the internet archive trying to find the snapshots (timestamps) of URLs to feed into the start of the pipeline. For example, from manual browsing around the log for http://www.shurgard.co.uk I found that the Internet Archive took a snapshot of the Shurgard website on 2nd August 2014, and you can find it <a href="https://web.archive.org/web/20140802153455/http://www.shurgard.co.uk">here</a>. Back in 2014, all the UK sites were found at this specific extension of the home URL of Shurgard: <a href="https://web.archive.org/web/20140802153455/http://www.shurgard.co.uk/self-storage-uk">https://web.archive.org/web/20140802153455/http://www.shurgard.co.uk/self-storage-uk</a>. Manually finding when each of the snapshots occurred would be really painful. The Wayback Machine (part of the Internet Archive, and possibly the most under-rated historical resource on the planet) has a nice user interface that lets you click on the next snapshot, but we would need a way to grab snapshots we can automate in code. Well, in this case, there’s good news: I recently discovered that the <a href="https://archive.org/web/">Wayback Machine</a> has a <a href="https://github.com/akamhy/waybackpy">Python API</a> with a function that can pull the closest snapshot to a given timestamp (no searching for snapshots manually). This means we might be able to find the relevant extension-URL with the sites on and then iterate through time programmaticaly hoping that it doesn’t change.</p>
<p>Here’s the code for retrieving the URL closest to 1st August 2014 as a test:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> waybackpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WaybackMachineCDXServerAPI</span>
<span id="cb3-2"></span>
<span id="cb3-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'http://www.shurgard.co.uk/self-storage-uk'</span></span>
<span id="cb3-4">user_agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"YOUR USER AGENT"</span></span>
<span id="cb3-5">cdx_api <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> WaybackMachineCDXServerAPI(url, user_agent)</span>
<span id="cb3-6"></span>
<span id="cb3-7">near <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cdx_api.near(year<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2014</span>, month<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, day<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, hour<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, minute<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9">near.archive_url</span></code></pre></div>
<pre class="text"><code>'https://web.archive.org/web/20140802153455/http://www.shurgard.co.uk:80/self-storage-uk'</code></pre>
<p>It’s a perfect match to the URL we already knew about! So the recipe for scaling this up without a classifier too might look something like:</p>
<ul>
<li>Get a list of likely firm names (perhaps using the Open Street Map firm names we got in the previous blog post but being fully aware that you might miss firms that no longer exist, which is a bias in this method)</li>
<li>For each firm name, work out the likely URL that takes you to the page of sites of self-storage facilities run by that firm</li>
<li>Decide on a time grid to search by, say one URL per year</li>
<li>Throw ChatGPT at each year-firm URL and ask it to get the locations (ensuring you have some spending limits in place on your OpenAI account!)</li>
<li>Clean the locations up—removing anything with more than four words seems like a good place to start, given the above; remove duplicates of year-firm information—perhaps some firms only have snapshots once every two years, for example</li>
<li>Count the number of sites over time</li>
</ul>
<p>There were nine self-storage firms that OSM data found in the previous blog post, and perhaps a ten year period seems reasonable, so we’d be asking for 90 ChatGPT hits to get all of the data. In practice, some firms may not have existed ten years ago and we’d be pretty lucky to have the extension to the sites not change at all in that time: indeed, Shurgard is an exception; the URL to the list of sites only persists back to 2020 for Big Yellow and Ready Steady Store.<sup>1</sup> There are other problems: Access Self Storage has a fancier website that makes it harder for ChatGPT to get location information out. Optimistically though, this approach might be possible for most of the firms for a small number of years, and that would still give a good indication of the trend.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Of course, the traditional way to solve problems like this in academic economics was to pay Research Assistants to do it manually, and then not put them on the paper as authors. Data collection <em>is</em> research: please put RAs on your papers!</p></div></div><p>If I get time, I might try out a more systematic data collection broadly following this recipe—then we might get a bit closer to finding an answer to the <a href="../../../blog/posts/self-storage-mystery/self-storage-mystery.html">mystery of self-storage</a> in the UK!</p>


</section>


 ]]></description>
  <category>code</category>
  <category>data</category>
  <category>analysis</category>
  <category>llm</category>
  <guid>https://www.aeturrell.com/blog/posts/self-storage-meets-chatgpt/</guid>
  <pubDate>Thu, 29 Jun 2023 23:00:00 GMT</pubDate>
  <media:content url="https://www.aeturrell.com/blog/posts/self-storage-meets-chatgpt/None" medium="image"/>
</item>
</channel>
</rss>
