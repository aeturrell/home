{
  "hash": "df375332b52ba6129da1905a641abfe6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: \"2025-10-01\"\nlayout: post\ntitle: \"TIL: merging PDFs\"\ncategories: [TIL, economics, vibe coding]\nexecute:\n  echo: false\njupyter: python3\ntoc: false\nreferences: ../files/reference.bib\nimages: \"../../transparent.png\"\n---\n\nI got the following email:\n\n> I was wondering if it is possible to get your excellent book \"coding for economists\" as a single PDF? I'm trying to improve my coding skills, and move away from just working in Stata, but I would very much prefer to read the book on my ReMarkable reader rather than on Github?\n\n> Many thanks for putting in the effort to make such a great text available for the public.\n\nWell it's always nice to get emails appreciative of your work. But I have no PDF version of the book!\n\nI had a quick look, however, and remembered that [each page of the book](https://aeturrell.github.io/coding-for-economists/intro.html) has a \"print to PDF\" button. If I could do that on each page, and merge the PDFs, then I could help out the email correspondent.\n\nThanks to Claude Sonnet 4.5, I vibe coded the following self-contained script that *worked perfectly*. It created a fairly hefty (60MB+) PDF with every page of the book in to read offline and at leisure. What's more, this approach could work on any series of webpages as it's just using the \"print to PDF\" option.\n\nTo use it in this instance it was (assuming you have [uv](https://docs.astral.sh/uv/) installed),\n\n```bash\nuv tool run playwright install chromium\nuv run download_and_merge_pdfs.py\n```\n\n```python\n#!/usr/bin/env python3\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"requests\",\n#   \"beautifulsoup4\",\n#   \"PyPDF2\",\n#   \"playwright\",\n# ]\n# ///\n\n\"\"\"\nScript to download PDFs from each page of an online book and combine them.\nSince the site uses window.print() instead of pre-generated PDFs, we use Playwright to render each page and print to PDF.\n\nFirst time setup (installs Chromium):\n    uv tool run playwright install chromium\n\nUsage with uv:\n    uv run download_and_merge_pdfs.py\n\n\n\"\"\"\n\nimport os\nimport time\nimport requests\nfrom bs4 import BeautifulSoup\nfrom PyPDF2 import PdfMerger\nfrom urllib.parse import urljoin, urlparse\nfrom playwright.sync_api import sync_playwright\n\n# Configuration\nBASE_URL = \"https://aeturrell.github.io/coding-for-economists/\"\nSTART_PAGE = \"intro.html\"\nOUTPUT_FILE = \"coding_for_economists_complete.pdf\"\nTEMP_DIR = \"temp_pdfs\"\n\ndef create_temp_dir():\n    \"\"\"Create temporary directory for PDFs\"\"\"\n    if not os.path.exists(TEMP_DIR):\n        os.makedirs(TEMP_DIR)\n\ndef get_page_links(start_url):\n    \"\"\"Extract all chapter/page links from the sidebar navigation\"\"\"\n    print(f\"Fetching page structure from {start_url}...\")\n    response = requests.get(start_url)\n    response.raise_for_status()\n    soup = BeautifulSoup(response.content, 'html.parser')\n    \n    links = []\n    \n    # Look for the sidebar navigation in Jupyter Book\n    nav = soup.select_one('nav#bd-docs-nav, nav.bd-links, div.bd-sidebar')\n    \n    if nav:\n        # Find all links in the navigation\n        for link in nav.find_all('a', href=True):\n            href = link['href']\n            # Filter for HTML pages, exclude anchors and external links\n            if href.endswith('.html') and not href.startswith('http') and not href.startswith('#'):\n                full_url = urljoin(BASE_URL, href)\n                if full_url not in links:\n                    links.append(full_url)\n                    print(f\"  Found: {href}\")\n    \n    # If we didn't find links in nav, try to find them anywhere on the page\n    if not links:\n        print(\"Nav structure not found, trying alternative method...\")\n        for link in soup.find_all('a', href=True):\n            href = link['href']\n            if href.endswith('.html') and not href.startswith('http') and not href.startswith('#'):\n                full_url = urljoin(BASE_URL, href)\n                if full_url not in links and BASE_URL in full_url:\n                    links.append(full_url)\n                    print(f\"  Found: {href}\")\n    \n    return links\n\ndef page_to_pdf_playwright(page_url, output_path):\n    \"\"\"Use Playwright to render page and save as PDF\"\"\"\n    print(f\"    Converting to PDF with Playwright...\")\n    \n    with sync_playwright() as p:\n        browser = p.chromium.launch()\n        page = browser.new_page()\n        \n        # Navigate to the page\n        page.goto(page_url, wait_until='networkidle')\n        \n        # Wait a bit for any dynamic content\n        page.wait_for_timeout(1000)\n        \n        # Print to PDF with good settings\n        page.pdf(\n            path=output_path,\n            format='A4',\n            margin={\n                'top': '20mm',\n                'right': '20mm',\n                'bottom': '20mm',\n                'left': '20mm'\n            },\n            print_background=True\n        )\n        \n        browser.close()\n    \n    return output_path\n\ndef merge_pdfs(pdf_files, output_file):\n    \"\"\"Merge multiple PDFs into one\"\"\"\n    print(f\"\\nMerging {len(pdf_files)} PDFs into {output_file}...\")\n    merger = PdfMerger()\n    \n    for pdf_file in pdf_files:\n        print(f\"  Adding: {os.path.basename(pdf_file)}\")\n        merger.append(pdf_file)\n    \n    merger.write(output_file)\n    merger.close()\n    print(f\"Successfully created {output_file}\")\n\ndef cleanup_temp_files(pdf_files):\n    \"\"\"Remove temporary PDF files\"\"\"\n    print(\"\\nCleaning up temporary files...\")\n    for pdf_file in pdf_files:\n        try:\n            os.remove(pdf_file)\n        except Exception as e:\n            print(f\"  Warning: Could not remove {pdf_file}: {e}\")\n    \n    try:\n        os.rmdir(TEMP_DIR)\n    except Exception as e:\n        print(f\"  Warning: Could not remove {TEMP_DIR}: {e}\")\n\ndef main():\n    create_temp_dir()\n    \n    # Get all page links from the table of contents\n    start_url = urljoin(BASE_URL, START_PAGE)\n    page_links = get_page_links(start_url)\n    \n    if not page_links:\n        print(\"Could not find page links. Using just the intro page...\")\n        page_links = [start_url]\n    \n    # TEST MODE: Only do first 3 pages\n    # print(f\"\\n{'='*60}\")\n    # print(f\"TEST MODE: Processing first 3 pages only\")\n    # print(f\"{'='*60}\")\n    # page_links = page_links[:3]\n    \n    print(f\"\\nWill process {len(page_links)} pages\")\n    \n    # Convert each page to PDF\n    downloaded_pdfs = []\n    for i, page_url in enumerate(page_links, 1):\n        print(f\"\\n[{i}/{len(page_links)}] Processing: {page_url}\")\n        \n        # Create a safe filename from the page URL\n        page_name = os.path.basename(urlparse(page_url).path)\n        page_name = os.path.splitext(page_name)[0]\n        filename = f\"{i:03d}_{page_name}.pdf\"\n        output_path = os.path.join(TEMP_DIR, filename)\n        \n        try:\n            page_to_pdf_playwright(page_url, output_path)\n            downloaded_pdfs.append(output_path)\n            print(f\"    ✓ Saved: {filename}\")\n        except Exception as e:\n            print(f\"    ✗ Error converting page: {e}\")\n        \n        # Be nice to the server\n        time.sleep(1)\n    \n    # Merge all PDFs\n    if downloaded_pdfs:\n        # Show info about downloaded files\n        print(f\"\\n{'='*60}\")\n        print(f\"Downloaded Files:\")\n        print(f\"{'='*60}\")\n        total_size = 0\n        for pdf in downloaded_pdfs:\n            size = os.path.getsize(pdf) / 1024  # KB\n            total_size += size\n            print(f\"  {os.path.basename(pdf)}: {size:.1f} KB\")\n        print(f\"  Total: {total_size:.1f} KB\")\n        \n        merge_pdfs(downloaded_pdfs, OUTPUT_FILE)\n        \n        cleanup_input = input(\"\\nDelete temporary PDF files? (y/n): \")\n        if cleanup_input.lower() == 'y':\n            cleanup_temp_files(downloaded_pdfs)\n        else:\n            print(f\"Temporary files kept in: {TEMP_DIR}/\")\n        \n        final_size = os.path.getsize(OUTPUT_FILE) / 1024\n        print(f\"\\n{'='*60}\")\n        print(f\"✓ Complete!\")\n        print(f\"{'='*60}\")\n        print(f\"Combined PDF: {OUTPUT_FILE} ({final_size:.1f} KB)\")\n        print(f\"\\nTo process all pages, edit the script and remove the [:3] slice\")\n    else:\n        print(\"\\n✗ No PDFs were created.\")\n\nif __name__ == \"__main__\":\n    # Check if playwright is installed\n    try:\n        from playwright.sync_api import sync_playwright\n    except ImportError:\n        print(\"Error: Playwright not found.\")\n        print(\"Install with: uv run playwright install chromium\")\n        exit(1)\n    \n    main()\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}